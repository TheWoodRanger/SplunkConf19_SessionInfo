[
  {
    "Event": ".conf19",
    "Title": "2623 - First Timer Orientation"
  },
  {
    "Event": ".conf19",
    "Title": "BA1130 - Demonstrating The Value Of A Business Flow Use Case",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": ["Splunk Business Flow", "Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Dirk Beerbohm , Senior Sales Engineer, Splunk",
      "Martin Senebald , COCUS AG"
    ],
    "Industry": "Not industry specific",
    "Description": "As organizations look to extend Splunk to new datasets for business process insights, it is crucial to have the right data to work with. However Splunk teams can get stuck demonstrating the value of new solutions without having data available. Some very intelligent approaches to data sampling, data preparation, and query optimization can dramatically accelerate your ability to create value from more data.¬† In this session, you will learn some of these techniques so you can quickly make a business case and demonstrate the value for Splunk Business Flow in your organization.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1130.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1130.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1188 - See What‚Äôs New With Splunk Business Flow",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Business Flow",
    "Speakers": "Lizzy Li , Product Manager, Business Flow, Splunk",
    "Industry": "Online Services",
    "Description": "Business operations and process improvement teams have relied on Splunk for analyzing their business processes.¬† Earlier this year, Splunk launched Business Flow as a new solution for interactive discovery and investigation of any business process. ¬†In this session, hear and see all of Splunk's latest innovations for business operations and process improvement professionals.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1188.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1188.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1191 - Driving More Sales at Deutsche Bahn-  DB Systel‚Äôs Journey Mapping With Splunk Business Flow",
    "SkillLevel": "Beginner",
    "Track": "Business Analytics",
    "Products": ["Splunk Business Flow", "Splunk Enterprise"],
    "Speakers": [
      "Ilario Angilletta , Consultant, Deutsche Bahn",
      "Oliver Kempf , Founder & Product Owner Process Mining, Deutsche Bahn"
    ],
    "Industry": "Not industry specific",
    "Description": "As one of the largest transportation providers in the world, Deutsche Bahn is eager to understand the customer experience of its passengers interacting with its agents. Driving greater sales requires highly efficient engagement with call center agents. However, efficiencies can be hard to understand and measure with so many call center interactions. DB Systel Gmbh, the IT services arm of Deutsche Bahn, uses Splunk Business Flow to quickly map thousands of customer experiences to understand opportunities for improving efficiencies. In this session, learn how Deutsche Bahn is able to operate a more efficient call center and drive greater passenger sales using the fast and flexible insights of Splunk Business Flow.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1191.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1191.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1204 - Improving the Medical Claims Process with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Speakers": "Nate Kwong , Staff Sales Engineer, Splunk",
    "Industry": "Healthcare",
    "Description": "A large healthcare provider can process thousands of medical claims per day and millions of claims per month. The claims process involves multiple steps and many moving parts and can take weeks to complete. With the use of Splunk, a healthcare customer has been able to increase its visibility and insights into the medical claims process. The result is time savings in the claims process, improved customer experience, and increased productivity. Learn how a healthcare customer is leveraging Splunk to perform near real-time and historical analysis to continuously improve the claims process.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1204.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1204.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1321 - 40 Ways to Use Splunk in Financial Services",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Duncan Ash , AVP Global Financial Services, Splunk",
      "Haider Al-Seaidy , Financial Services Industry Specialist, Splunk"
    ],
    "Industry": "Financial Services",
    "Description": "In this session we will show you how Splunk customers around the world are using Splunk in creative ways to solve a range of challenges, from Trading Strategies to Market Abuse, and from Customer On-boarding to Customer Churn. There are no limits to what Splunk can be used for, and this session will help you get new ideas for how to deploy Splunk in your business.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1321.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1321.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1428 - Business Flow vs The Real World. Cutting Through Complexity in Big Retail to Deliver Broad and Deep Assurance",
    "SkillLevel": "Intermediate",
    "Track": "Business Analytics",
    "Products": "Splunk Business Flow",
    "Speakers": "Paul Adams , Octamis",
    "Industry": "Retail",
    "Description": "At a major UK retail organization, we developed so many great dashboards over the years for every conceivable business area. This once sufficed, but it fuelled greater expectation in an ever harsher trading environment. Enter Peak Trade periods and the need for outcome-centered visibility across the order fulfillment process 'just got real'.n Could Splunk Business Flow help us to uncover the actual flow, given the teams who built it are long disbanded? Could we talk 'flow' when support teams align to 'steps'? ¬†n What we found was data that cannot agree what an Order is. Processes which tackle different aspects of an order, sometimes in parallel or batch. Processes which fork and then merge later on. Processes which go into planned deep-freeze for days or weeks before reawakening. Data formats which are hostile. The list goes on.n We take you through the thought process, share mistakes and learnings, and outline considerations/techniques to help you win in the arena of real-world data.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1428.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1428.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1512 - Just a normal day in the office ‚Äì Data driven business process improvements for a global supply chain company.",
    "SkillLevel": "Beginner",
    "Track": "Business Analytics",
    "Products": [
      "Splunk Cloud",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Holger Diekhoff , Manager Operational Intelligence, Arvato Supply Chain Solutions",
      "Ralf  Walkenhorst , ITOA Specialist, Splunk"
    ],
    "Industry": "Travel & Transportation",
    "Description": "'Our IT-powered business processes are too slow.' Does this sound familiar? If so, that is usually the perfect starting point to dig in and start improving them. Unfortunately, specific data that could help with that effort are not available ‚Äì normally. In this session we will show you how we at Arvato Supply Chain Solutions got the data we needed and used it to improve the collaboration between IT and business. You will learn how we connected different IT systems such as SAP and conveyor line to Splunk Cloud, and how this helped us to analyze business processes with IT Service Intelligence (ITSI). And, as the icing on the cake, we give you a sneak peak of the machine learning algorithm we implemented to continuously improve our business processes.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1512.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1512.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1529 - Splunk Business Flow + Splunk Connect for Kubernetes = Happy Containers",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Business Flow",
    "Speakers": [
      "Matt Modestino , ITOA Practitioner, Splunk",
      "Tom Martin , Staff Practitioner, Splunk"
    ],
    "Industry": "Financial Services",
    "Description": "Managing container deployment is the new thing for IT and Splunk is making it easier to monitor your container deployment processes. In this theater session, see how Splunk Business Flow combined with Splunk Connect for Kubernetes can help IT administrators get immediate visibility into Kubernetes deployments to spot delays and failures.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1529.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1529.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1593 - Monitoring the order fulfilment process within an automated warehouse using Splunk Business Flow",
    "SkillLevel": "Beginner",
    "Track": "Business Analytics",
    "Products": ["Splunk Business Flow", "Splunk Enterprise"],
    "Speakers": "Jamie Frost , Business Improvement Analyst, TGW Limited",
    "Industry": "Not industry specific",
    "Description": "Attendees will see how Splunk Enterprise and Splunk Business Flow are used to monitor the order fulfilment process within an automated warehouse in real time. You also will see how proactive alerts inform the warehouse that a Key Performance Indicator (KPI) is under performing. Then, using process mining to investigate, find the root cause to solve issues before they become problems. This presentation will initially describe the workings of an automated warehouse and the data generated. It then will cover the process of ingesting this data into Splunk and configuring Splunk Business Flow to monitor processes and KPIs. Finally, the session will review the benefits to TGW and its customers from deploying Splunk Enterprise and Splunk Business Flow. Come to the session to see how the monitoring, alerting, and process mining functionality in Splunk Enterprise and Splunk Business Flow provides a deep insight into what is happening inside an automated warehouse.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1593.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1593.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1623 - Introduction to monitoring business operations with Acceleris‚Äô party dashboard",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Martin Gerber , Crunching Master, Acceleris AG",
      "OJ Stapleton , Data / Tech Master, Data Mavericks by Acceleris"
    ],
    "Industry": "Not industry specific",
    "Description": "Why should running a business feel any different than throwing a party? To demonstrate how Splunk can be used to monitor and manage business operations, the DATA Mavericks team at Acceleris has iteratively perfected its Party Dashboard. It started out as a gimmick at the inauguration party of the company's new headquarters, but now the Party Dashboard demonstrates how Splunk‚Äôs dashboarding helps any team get real-time visibility into any operation. Join this session to learn why they chose the relevant metrics, how they collected and fed the data to Splunk, and what meaningful insights were generated as a fun introductory example of using Splunk to get visibility into your business operations.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1623.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1623.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1710 - Splunk Business Flow for IT Operations Workflows",
    "SkillLevel": "Beginner",
    "Track": "Business Analytics",
    "Products": ["Splunk Business Flow", "Splunk Enterprise"],
    "Speakers": "Tom Martin , Staff Practitioner, Splunk",
    "Industry": "Technology",
    "Description": "Everyone knows Splunk can give you visibility into incidents ‚Äì but imagine if Splunk could provide visibility into your CI/CD processes before you go live too! In this session, get a quick overview of how Splunk Business Flow can help anyone in IT operations identify opportunities to optimize and accelerate their organization‚Äôs IT operational workflows.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1710.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "BA1853 - From a dataful life to unlocking difference- building a data fabric to drive customer and business value in just 60 days",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Industry": "Communications"
  },
  {
    "Event": ".conf19",
    "Title": "BA1868 - Delivering real-time sales journey analytics and IT operational health with IT Service Intelligence",
    "SkillLevel": "Intermediate",
    "Track": "Business Analytics",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Stuart Robertson , Consulting Director, iDelta",
    "Industry": "Financial Services",
    "Description": "Splunk and ITSI are already loved by IT Operations and Application Support teams - but can you help¬†your Business Operations teams¬†love¬†them too?n n Splunk‚Äôs unique approach to AIOps and monitoring empowers every organization in your enterprise ‚Äì from IT to Apps to Business ‚Äì to utilise the same data for multiple use cases and user communities. ¬†Through this session, you‚Äôll learn how to implement a logging framework that delivers across multiple channels.¬† Key concepts will include¬†ingesting¬†AWS data, ITSI KPI base searches, entity filtering, and APM techniques. ¬†Join this session to learn how to extend¬†your Splunk usage with business KPIs and perform sales journey analytics to grow your list of stakeholders.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1868.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1868.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1920 - Splunking the Shopfloor- Improving the Manufacturing Process with Splunk",
    "SkillLevel": "Beginner",
    "Track": "Business Analytics",
    "Products": ["Splunk Business Flow", "Splunk Enterprise"],
    "Speakers": [
      "Coty Pastene , DevOps Engineer, Shaw Industries",
      "Logan Templeton , Senior Technical Process Engineer, Shaw Industries"
    ],
    "Industry": "Manufacturing",
    "Description": "The sophisticated environment of a modern manufacturing plant demands that workers and management constantly synthesize data sources from different systems to optimize use of raw materials, work in process levels, and track inventory. This session will show how Splunk software can be used to collect, analyze, and report this information in real time to drive continuous improvement and business metrics.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1920.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1920.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1959 - Case Study- Call Center Agent Performance Monitoring",
    "SkillLevel": "Advanced",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Jeremy Lemley , Lead Operations Analyst, CenturyLink",
      "Russ White , Operations Analyst II, CenturyLink"
    ],
    "Industry": "Communications",
    "Description": "Do you want to monitor call-center employee performance in Splunk? We all know Splunk does a great job with web logs and IoT devices, but could it be used to provide a meaningful Scorecard for 3000+ employees and their management? We think it can, and we would like to share our successful implementation of a Splunk Employee Metrics Dashboard. Some of the concepts include: data preparation, summary indexes, tokens, custom CSS and JavaScript, drilldowns to the details, security, and more!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1959.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1959.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA1966 - Product Overview-  Business Analytics with Business Flow",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Brian Hoover , Sales Specialist, Business Analytics, Splunk",
      "Charles Adriaenssens , EMEA Specialist Lead Business Analytics, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Eager to get started with Splunk Business Flow? Splunk Business Flow is Splunk‚Äôs process mining solution for interactively exploring business processes to drive operational efficiencies. In this session, learn all the key concepts and terminology in Splunk Business Flow. You also will get a walkthrough of the major capabilities of Splunk Business Flow that will allow you to view a process flow, understand some basic metrics, explore and filter with attributes, and then dig into specific cases to diagnose potential anomalies.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA1966.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA1966.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA2082 - Healthcare and Splunk ‚Äì Leading the Way in Patient Care!",
    "SkillLevel": "Beginner",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Industry": ["Healthcare", "Non-Profit"]
  },
  {
    "Event": ".conf19",
    "Title": "BA2130 - What's New in Business Analytics and Business Flow",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": ["Splunk Business Flow", "Splunk Enterprise"],
    "Speakers": [
      "Faya Peng , Senior Director, Product Management, Splunk",
      "Lizzy Li , Product Manager, Business Flow, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Business operations teams have relied on Splunk for operational intelligence, helping them to discover bottlenecks, fallout, and other issues in order to deliver more efficient business processes and customer experiences with higher conversions. In this session, learn about Splunk's latest innovations for business operations professionals.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA2130.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BA2130.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BA2642 - Technical Overview- How We Used Splunk Business Flow at Splunk for IT Service Delivery",
    "SkillLevel": "Advanced",
    "Track": "Business Analytics",
    "Products": "Splunk Business Flow",
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "BAS2765 - Ideas to Data to Outcomes",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Rick Pina , WWT",
    "Industry": "Public Sector",
    "Description": "WWT integrates Splunk in enterprise architectures for our joint customers.  Rick Pina from WWT is going to describe how Splunk, when part of a larger architecture, is providing true mission and operational outcomes.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BAS2765.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BAS2765.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BAS2766 - Machine Data Alchemy- Transforming Digital Exhaust into Campus Gold",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Matt Portnoy , Senior Sales Engineer, Splunk",
      "Nitin Madhok , Executive Director Business Intelligence & Advanced Data Analytics, Clemson University"
    ],
    "Industry": "Public Sector",
    "Description": "Students, faculty and staff increasingly rely on technology for all aspects of campus activity. Universities must learn how to capture campus-wide data and transform it into value for everyone‚Äôs benefit. Clemson University will describe how they use data insights to deliver on student experience in a secure and connected setting. Clemson analyzed data from their Learning Management System (Canvas) using Splunk, so student and instructor activity is available in near real time which offers valuable feedback to the University. Learn how they drove additional speed and efficiency into other campus areas providing greater visibility of issues that consumed time and resources. Customer Support, IT security, and IT operations have also leveraged the Splunk platform to significantly expand and improve Clemson‚Äôs ability to make impactful decisions. We‚Äôll share more details about these use cases so reserve your seat now for insights of your own!n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BA2766.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BAS2766.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BAS2793 - Classifying Evil ‚Äì Combating Human Trafficking with the power of Data & Analytics",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Monark Vyas , Digital Strategy Senior Manager, Accenture",
      "Sherrie Caltagirone , Executive Director, Global Emancipation Network"
    ],
    "Industry": "Not industry specific",
    "Description": "Human trafficking is one of the most egregious and lucrative crimes of modern society. Traffickers use both lawful and illicit infrastructure to conduct business, making it difficult for defenders to identify trafficking on their services.n n In our next innovative leap, Global Emancipation Network partnered with Splunk4Good and Accenture to develop the world‚Äôs first trafficking content classifier. We are using a Splunk powered data & analytics platform tocreate a risk scoring engine that assigns values to indicators and patterns and provides action options on flagged results to allow better decision-making for law enforcement, government, and private sector users. Learn how Splunk can turn data into robust classifiers to help save lives.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BAS2793.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BAS2793.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BAS2794 - Applied Intelligence - Powered Pivot to the Future",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Speakers": "John Matchette , Managing Director, Accenture",
    "Industry": "Not industry specific",
    "Description": "AI and automation are fueling a new norm of digital disruption and breeding new forms of competition. To stay ahead, businesses must continuously innovate with speed and agility like never before. Learn how major companies are using Splunk powered intelligent warehouses with machine learning led inventory optimization, end to end supply chain visibility and chatbot integrations to create unprecedented business outcomes. Check out the secrets of 'Rotation Masters' and how they are using AI to do things differently and drive double-digit growth.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BAS2794.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BAS2794.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BAS2795 - Applying Artificial Intelligence - Making It Real by Empowering Our Businesses and Communities",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": "Splunk Enterprise",
    "Speakers": "Arnab Chakraborty , Managing Director, Applied Intelligence ‚Äì US West, Accenture",
    "Industry": "Not industry specific",
    "Description": "Data is disrupting every industry, and tapping into dark data with applied intelligence is empowering businesses & communities to make real world impact. From enhanced consumer experiences to intelligent enterprises, the use of digital technologies powered by analytics and artifical intelligence are creating new business avenues. Learn how amanufacturing giants are using AI powered digital twins to improve their product journey from design to maintenance. Leveraging Splunk to create smart, connected products, platforms and business models that live both physically and digitally.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/BAS2795.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/BAS2795.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "BAS2981 - Accelerating Business Decisions across end-to-end process",
    "SkillLevel": "Good for all skill levels",
    "Track": "Business Analytics",
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Industry": "Financial Services"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1114 - Vagrant and Splunk Development- Building Splunk Apps for any Environment",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Enterprise",
    "Speakers": "Jason Rauen , Senior Lead Technologist, Booz Allen Hamilton",
    "Industry": "Not industry specific",
    "Description": "Vagrant is virtualization technology that builds portable, virtual software development environments. Leveraging this technology for Splunk development allows agile and DevOps teams to easily collaborate in Splunk development in as way that tightly mirrors their production environment, even when working with a mix of environments such as Mac and Windows. Vagrant‚Äôs multi-machine environments can perfectly replicate any Splunk architecture, including complicated clustering and networking configurations, using a single Vagrantfile that can be shared directly or committed to a version control system. From the Forwarder to a search head cluster member, see how your configurations and code work in your environment across the entire data pipeline right on your machine, or test your Splunkbase app on every possible architecture from single server to distributed multi-site clusters, all with a single command: vagrant up.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1114.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1114.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1139 - Detecting Anomalies in DSP Pipelines Using Real Time Machine Learning",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Harsha Wasalathanrige Don , Software Engineer, Splunk",
      "Ram Sriharsha , Sr Principal Scientist, Head of Applied Research, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Machine Learning on the stream is useful for a few important reasons: scenarios where we want to dramatically reduce the resource utilization while providing high fidelity results and in use cases where we need algorithms to adapt to changing patterns and drifts in distributions real time.  In this talk, we will discuss ongoing work in the area of streaming machine learning and show how we leverage Flink and DSP to build real time machine learning systems that allow us to perform adaptive thresholding and anomaly detection online.  As an application of these principles, we will showcase how real time machine learning is used to detect anomalies in DSP pipelines.  The talk will introduce relevant background in streaming machine learning as well as the problem of anomaly detection on Kubernetes logs. Machine Learning on the stream is useful for a few important reasons: scenarios where we want to dramatically reduce the resource utilization while providing high fidelity results and in use cases where we need algorithms to adapt to changing patterns and drifts in distributions real time.Machine Learning on the stream is useful for a few important reasons: scenarios where we want to dramatically reduce the resource utilization while providing high fidelity results and in use cases where we need algorithms to adapt to changing patterns and drifts in distributions real time.Machine Learning on the stream is useful for a few important reasons: scenarios where we want to dramatically reduce the resource utilization while providing high fidelity results and in use cases where we need algorithms to adapt to changing patterns and drifts in distributions real time.Machine Learning on the stream is useful for a few important reasons: scenarios where we want to dramatically reduce the resource utilization while providing high fidelity results and in use cases where we need algorithms to adapt to changing patterns and drifts in distributions real time.In this talk, we will discuss ongoing work in the area of streaming machine learning and show how we leverage Flink and DSP to build real time machine learning systems that allow us to perform adaptive thresholding and anomaly detection online.In this talk, we will discuss ongoing work in the area of streaming machine learning and show how we leverage Flink and DSP to build real time machine learning systems that allow us to perform adaptive thresholding and anomaly detection online.In this talk, we will discuss ongoing work in the area of streaming machine learning and show how we leverage Flink and DSP to build real time machine learning systems that allow us to perform adaptive thresholding and anomaly detection online.In this talk, we will discuss ongoing work in the area of streaming machine learning and show how we leverage Flink and DSP to build real time machine learning systems that allow us to perform adaptive thresholding and anomaly detection online.As an application of these principles, we will showcase how real time machine learning is used to detect anomalies in DSP pipelines.As an application of these principles, we will showcase how real time machine learning is used to detect anomalies in DSP pipelines.As an application of these principles, we will showcase how real time machine learning is used to detect anomalies in DSP pipelines.As an application of these principles, we will showcase how real time machine learning is used to detect anomalies in DSP pipelines.The talk will introduce relevant background in streaming machine learning as well as the problem of anomaly detection on Kubernetes logs.The talk will introduce relevant background in streaming machine learning as well as the problem of anomaly detection on Kubernetes logs.The talk will introduce relevant background in streaming machine learning as well as the problem of anomaly detection on Kubernetes logs.The talk will introduce relevant background in streaming machine learning as well as the problem of anomaly detection on Kubernetes logs.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1139.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1139.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1140 - Next Generation Data Ingestion and Preparation with Splunk",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["Splunk Developer Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Asmita Puri , Sr. Software Engineer, Splunk",
      "Eric Sammer , Distinguished Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "You think data ingestion into Splunk is cumbersome today? Don‚Äôt enjoy writing Technology Add-ons (TA) for specific use cases? Then this talk is for you!¬† We will walk through data ingestion using the data sources supported by the new Splunk Investigate wizard. This allows users of all levels to configure their data source and perform various manipulation functions on the ingested data to make sure it meets their use case. We will also go over the guiding principles of the underlying Data Stream Processing (DSP) pipeline which empowers the user to add their own customizations and send data to a variety of destinations. ¬† We will compare this with current Splunk Enterprise data ingestion process by configuring a TA for a specific use case and then alter the ingested data to the desired format before sending it to an index. The user will be able to draw a contrast between the two approaches and see how it does not have to take up to 6 weeks to acquire and prepare data for analytics in Splunk. We hope this session leaves the user excited about data ingestion and prep.¬† ¬† ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1140.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1140.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1141 - Building applications with Splunk UI and Splunk React Visualizations ",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Developer Cloud",
    "Speakers": [
      "Patrick Wied , Senior Software Engineer, Splunk",
      "Ziyan Wang , Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "In this session we will walk you through the process of creating a highly customized application experience using React and Splunk's UI and visualization libraries. In this session we will walk you through the process of creating a highly customized application experience using React and Splunk's UI and visualization libraries.In this session we will walk you through the process of creating a highly customized application experience using React and Splunk's UI and visualization libraries.In this session we will walk you through the process of creating a highly customized application experience using React and Splunk's UI and visualization libraries.In this session we will walk you through the process of creating a highly customized application experience using React and Splunk's UI and visualization libraries.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1141.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1141.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1173 - Python 3 Compatibility Dive- Don't Let Strings Byte You in the Apps",
    "SkillLevel": "Advanced",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Cory Burke , Principal Software Engineer, Splunk",
      "Samat Jain , Senior Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "You knew it had to happen, Splunk is migrating to Python 3! We want this migration to be as painless as possible for apps and scripts developers, but it necessitates some compatibility requirements. This talk will dive into what parts of your apps and scripts will have to become Python 3 compatible. You‚Äôll explore approaches to using Python community supplied backporting libraries as well as Python 2/3 compatible native syntax. By examining common and uncommon gotchas we found while migrating Splunk Enterprise, we will make sure you are prepared to run your code in the future generations of Splunk Enterprise!n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1173.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1173.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1252 - Getting your FIX- Developing an add-on for the Financial Information eXchange Protocol",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Enterprise",
    "Speakers": "Josef Kuepker , Staff Security Specialist, Splunk",
    "Industry": "Financial Services",
    "Description": "The Financial Information eXchange (FIX) Protocol is one of the most pervasive electronic communications protocols used for real-time exchange of information related to securities transaction and market data. The protocol is used to move massive quantities of money per day.n n ¬†With over 1600 fields (tags) and 115 message types, the protocol presents some unique challenges to consider when developing an add-on for Splunk. Come see and discuss the protocol and how Splunk can help you make sense of the data it contains to improve your trading, business analytic, security, fraud, and compliance operations.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1252.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1252.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1270 - ‚ÄòGit‚Äô Splunk App Management with Visual Studio Code",
    "SkillLevel": "Beginner",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Erica Pescio , Forward Deployed Software Engineer, Splunk",
      "Joe Welsh , Sr. Manager, FDSE, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "How would you like a lightweight, fast, cross-platform source code editor that provides syntax highlighting for all Splunk configuration files? Want to edit your remote Splunk configuration files directly from your laptop or desktop? Ever make changes to your Splunk configuration files you wish you could easily undo? All of this can be done from Microsoft Visual Studio (VS) Code installed locally on your favorite operating system. This hands on lab will teach you how to use VS Code for Splunk App Management, including remote file editing, Splunk application best practices, and using GitLab for configuration file version control.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1270.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1270.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1293 - Check-Out SPL Rehab- A new way to debug your searches",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["Splunk Cloud", "Splunk Developer Cloud", "Splunk Enterprise"],
    "Speakers": "James Odom , Head of Service Delivery, Converging Data",
    "Industry": "Not industry specific",
    "Description": "Wouldn't it be great if SPL had a debug mode?! We think so too, which is why we created SPL Rehab. This new app allows you to step through your search on a per-command basis, visualize key figures from the job inspector and search log, and show you how your overall output is affected! We will also show you how the tool works under the covers and how you can apply some useful dashboarding tricks to your own apps! Wouldn't it be great if SPL had a debug mode?! We think so too, which is why we created SPL Rehab. This new app allows you to step through your search on a per-command basis, visualize key figures from the job inspector and search log, and show you how your overall output is affected! We will also show you how the tool works under the covers and how you can apply some useful dashboarding tricks to your own apps!Wouldn't it be great if SPL had a debug mode?! We think so too, which is why we created SPL Rehab. This new app allows you to step through your search on a per-command basis, visualize key figures from the job inspector and search log, and show you how your overall output is affected! We will also show you how the tool works under the covers and how you can apply some useful dashboarding tricks to your own apps!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/Dev1293.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1293.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1299 - The A to Z of building Add-Ons",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Enterprise",
    "Speakers": "James Odom , Head of Service Delivery, Converging Data",
    "Industry": "Not industry specific",
    "Description": "Building Splunk add-ons using API's and Python is easy! In fact we reckon it's is so easy that we're going to build one from scratch in less than 20 minutes... LIVE. Come and see whether we manage to pull it off, or whether we fail in front of hundreds of people! You do not need to be a Python expert, however a basic understanding will help.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1299.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1299.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1308 - A Timely Development- I Built a Splunk App To Save Security Analysts Time - And So Can You!",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Enterprise",
    "Speakers": "Joe Kovacic , Founder, Perseus",
    "Industry": "Not industry specific",
    "Description": "Have you ever had an idea that would improve incident response? I did. I knew I could save security analysts time by providing a tool that enabled analysts to determine if an endpoint had persistent malware present in seconds. However, it would need to integrate seamlessly into their incident response workflow and have a quality user interface. Frankly, that felt like an insurmountable hurdle for someone with little front-end development experience. I was pleasantly surprised to find that even as a solo developer, I was able to create a full-featured Splunk App with an interface that looks like it was designed by someone far more talented. Through a demonstration of my incident response app and a discussion of my experience building it, I‚Äôll show you how Splunk makes it easier and, more importantly, realistic to bring your own ideas to life. I‚Äôll also share a few pain-points I encountered so you can avoid some of the mistakes I made.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1308.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1308.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1317 - Data Stream Processor- Architecture and SDKs",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Data Fabric Search and Data Stream Processor",
    "Speakers": [
      "Max Feng , Software Engineer, Splunk",
      "Sharon Xie , Sr. Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Popular stream processing frameworks (such as Apache Spark Streaming, Apache Flink, and Apache Kafka Streams) make stream processing accessible to developers with language bindings typically in Java, Scala, and Python. These frameworks also include some variant of streaming SQL support to further expand the accessibility of large-scale, low-latency, high-throughput stream processing. What's missing is bringing the world of stream processing to the Business Intelligence user. At Splunk we've built a tool called Splunk Data Stream Processor (DSP) to fill this gap.  In this session, Max and Sharon will present the design and architecture of DSP. We will compare it with other stream processing frameworks to show you how DSP allows users to visually author and preview stream processing pipelines and instantly deploy them at scale. We will also present our developer SDKs, allowing third-party custom functions to be developed and integrated for data processing. With its high level abstractions for business users and extensible framework for developers, Data Stream Processor makes stream processing accessible to the widest possible audience. Popular stream processing frameworks (such as Apache Spark Streaming, Apache Flink, and Apache Kafka Streams) make stream processing accessible to developers with language bindings typically in Java, Scala, and Python. These frameworks also include some variant of streaming SQL support to further expand the accessibility of large-scale, low-latency, high-throughput stream processing. What's missing is bringing the world of stream processing to the Business Intelligence user. At Splunk we've built a tool called Splunk Data Stream Processor (DSP) to fill this gap.  In this session, Max and Sharon will present the design and architecture of DSP. We will compare it with other stream processing frameworks to show you how DSP allows users to visually author and preview stream processing pipelines and instantly deploy them at scale. We will also present our developer SDKs, allowing third-party custom functions to be developed and integrated for data processing. With its high level abstractions for business users and extensible framework for developers, Data Stream Processor makes stream processing accessible to the widest possible audience.Popular stream processing frameworks (such as Apache Spark Streaming, Apache Flink, and Apache Kafka Streams) make stream processing accessible to developers with language bindings typically in Java, Scala, and Python. These frameworks also include some variant of streaming SQL support to further expand the accessibility of large-scale, low-latency, high-throughput stream processing. What's missing is bringing the world of stream processing to the Business Intelligence user. At Splunk we've built a tool called Splunk Data Stream Processor (DSP) to fill this gap.  In this session, Max and Sharon will present the design and architecture of DSP. We will compare it with other stream processing frameworks to show you how DSP allows users to visually author and preview stream processing pipelines and instantly deploy them at scale. We will also present our developer SDKs, allowing third-party custom functions to be developed and integrated for data processing. With its high level abstractions for business users and extensible framework for developers, Data Stream Processor makes stream processing accessible to the widest possible audience.Popular stream processing frameworks (such as Apache Spark Streaming, Apache Flink, and Apache Kafka Streams) make stream processing accessible to developers with language bindings typically in Java, Scala, and Python. These frameworks also include some variant of streaming SQL support to further expand the accessibility of large-scale, low-latency, high-throughput stream processing. What's missing is bringing the world of stream processing to the Business Intelligence user. At Splunk we've built a tool called Splunk Data Stream Processor (DSP) to fill this gap.  In this session, Max and Sharon will present the design and architecture of DSP. We will compare it with other stream processing frameworks to show you how DSP allows users to visually author and preview stream processing pipelines and instantly deploy them at scale. We will also present our developer SDKs, allowing third-party custom functions to be developed and integrated for data processing. With its high level abstractions for business users and extensible framework for developers, Data Stream Processor makes stream processing accessible to the widest possible audience.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1317.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1317.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1377 - Not your parent's Splunk, an SDC journey",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["Splunk Cloud", "Splunk Developer Cloud"],
    "Speakers": [
      "Kyle Champlin , Senior Product Manager, Splunk",
      "Raanan Dagan , Principal SE Architect, Splunk"
    ],
    "Industry": "Technology",
    "Description": "Come join two old school Splunkers as we talk about our journey building our first app on Splunk Developer Cloud. We'll discuss the fun parts and the foibles, and hopefully show you that you can teach an old Pony new tricks. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1377.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1377.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1396 - Get your head into the clouds with Splunk Cloud Platform",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Developer Cloud",
    "Speakers": [
      "Andy Nortrup , Sr. Product Manager, Splunk",
      "Cecelia Redding , Engineering Manager, Splunk",
      "Clif Gordon , Principal Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "What is Splunk Cloud Platform (SCP), and how can it be leveraged in new ways current Splunk Cloud cannot? In this session you'll learn what Splunk Cloud Platform has to offer, the core concepts to be successful, and how to use Splunk Developer Cloud (SDC) tools to explore the services and features. Getting started couldn't be easier, and we'll show you how to go from sign-up to running in just a few clicks. You'll be dropped right in the middle of Splunk Investigate where you can access the services and features SCP has to offer (like ingest and search and collaboration tools). But that's not all, because using SDC tools you'll see how easy it is to create your own app to utilize the same SCP features as Splunk Investigate for your own use cases. Come join us for this end-to-end look at Splunk Cloud Platform, and get your head into the clouds! ¬† ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1396.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1396.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1440 - How Splunkbase identifies, resolves, and reviews incidents using Splunk-Investigate.",
    "SkillLevel": "Beginner",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Developer Cloud",
    "Speakers": [
      "Amr Saad , Engineering Manager, Splunk",
      "Heather Hunsinger , Senior Software Engineer, Splunk",
      "Matthew  Erbs , Senior Software Engineer, Splunk"
    ],
    "Industry": "Technology",
    "Description": "As a service that has many different integration points, Splunkbase needs to ensure as much uptime as possible. This means that when an incident occurs the root cause needs to be identified, resolved, reviewed and communicated to all relevant parties in a timely manner. Fortunately, Splunk>Investigate has served us very well in achieving these objectives. In this session, we‚Äôll demonstrate how the use of the Splunk>Investigate app on Splunk Cloud Platform (SCP) enables teams to access the same data pool with appropriate authorization to collaborate using shared workbooks. This workflow enables teams to quickly reach a solution when an incident occurs.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1440.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1440.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1476 - Build Apps Fast with SDC Developer Tools",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["AI/ML", "Splunk Developer Cloud"],
    "Speakers": [
      "Eric Cheng , Senior Software Engineer, Splunk",
      "Tedd  Hellmann , Sr. Product Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Learn how to build powerful apps with the Splunk Developer Cloud.¬† ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1476.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1476.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1667 - Converting a Traditional Splunk App to a Splunk Cloud App with Splunk Developer Cloud",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["Splunk Developer Cloud", "Splunk Enterprise"],
    "Speakers": ["Ashish Bhutiani , CEO, Function1", "Kevin Chu , Function1"],
    "Industry": "Not industry specific",
    "Description": "Unveiled at .conf2018, Splunk Developer Cloud (SDC) gives developers the ability to integrate Splunk data services into their own applications. If you‚Äôve been curious about getting started with SDC, this session is for you. Attendees will discover how to convert a traditional Splunk App to an SDC App, eliminating potential infrastructure resource roadblocks, leveraging more flexible scaling options, and building better visualizations with a modern, React-based framework. We'll also take a deep dive into the differences in the application design and development process between a traditional Splunk App and SDC as we walk you through our internal process of converting one of our homegrown Splunk Apps.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1667.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1667.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV1881 - Insider Guidance For Approaching Splunk Cloud Vetting Process",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Cloud",
    "Speakers": [
      "Samuel Ni , Principal Software Engineer, Splunk",
      "Yinqing Hao , Software engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "If you are a customer, when you want an app installed in Splunk Cloud, it is required for the app to pass cloud vetting process. Why does Splunk enforce this? What is in it for you as our customer? Who triggers cloud vetting process for an app and how are cloud vetting requests prioritized?  If you are an app developer, it is frustrating receiving messages from customers saying that the app that you developed fails Splunk cloud vetting, and they want you to help to fix. How to fix? How to develop an app that has the biggest chance of passing cloud vetting? What are the common failures that Splunk cloud vetting engineers saw in history and what are the best practices?  Come to this session, you will get answers to all the questions above. If you are a customer, when you want an app installed in Splunk Cloud, it is required for the app to pass cloud vetting process. Why does Splunk enforce this? What is in it for you as our customer? Who triggers cloud vetting process for an app and how are cloud vetting requests prioritized?If you are a customer, when you want an app installed in Splunk Cloud, it is required for the app to pass cloud vetting process. Why does Splunk enforce this? What is in it for you as our customer? Who triggers cloud vetting process for an app and how are cloud vetting requests prioritized?If you are a customer, when you want an app installed in Splunk Cloud, it is required for the app to pass cloud vetting process. Why does Splunk enforce this? What is in it for you as our customer? Who triggers cloud vetting process for an app and how are cloud vetting requests prioritized?If you are an app developer, it is frustrating receiving messages from customers saying that the app that you developed fails Splunk cloud vetting, and they want you to help to fix. How to fix? How to develop an app that has the biggest chance of passing cloud vetting? What are the common failures that Splunk cloud vetting engineers saw in history and what are the best practices?If you are an app developer, it is frustrating receiving messages from customers saying that the app that you developed fails Splunk cloud vetting, and they want you to help to fix. How to fix? How to develop an app that has the biggest chance of passing cloud vetting? What are the common failures that Splunk cloud vetting engineers saw in history and what are the best practices?If you are an app developer, it is frustrating receiving messages from customers saying that the app that you developed fails Splunk cloud vetting, and they want you to help to fix. How to fix? How to develop an app that has the biggest chance of passing cloud vetting? What are the common failures that Splunk cloud vetting engineers saw in history and what are the best practices?Come to this session, you will get answers to all the questions above.Come to this session, you will get answers to all the questions above.Come to this session, you will get answers to all the questions above.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV1881.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV1881.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV2165 - Deep Dive on The New Dashboarding & Content Export Experience",
    "SkillLevel": "Intermediate",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["Splunk Cloud", "Splunk Developer Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Michael Luo , Principal Software Engineer, Splunk",
      "Yuxiang Kou , Senior Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "This session provides detailed guidance on how to use the new dashboard framework into Splunk apps. It first goes over the basic get started tutorial, which helps developers to build a dashboard in just a few minutes. Then it dives deep into the overall architecture, technology stacks, and individual components that can be customized, including layouts, visualizations, data sources, inputs, event handlers. By attending this session, Splunk app developers will be able to integrate dashboards into the apps flexibly and reliably. This session will also walk through the best practices that can help developers to build the optimal dashboards. This session is targeted to both new Splunk app developers and existing Splunk app developers. For people who already know about the existing Splunk technology stack such as Backbone, SimpleXML, SplunkJS, this session will also go through how to migrate to the new framework. As a bonus, this session will also talk about how to export dashboards as beautiful images and PDFs that 100% matches the original ones! ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV2165.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV2165.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV2178 - Build your own custom data visualization on dashboard",
    "SkillLevel": "Advanced",
    "Track": ["Developer", "Splunk Developer"],
    "Products": ["Splunk Developer Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Pete Peterson , Principal Software Engineer, Splunk",
      "Xianlin Hu , Principal Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Ever had the necessity to have fine-grain control over visualizations on your Splunk dashboards? This talk will show you everything you need to know about how to build your own custom data visualization experience. Work through real-world examples by customizing the very popular Buttercup games dashboard. By the end of this talk, you will be inspired to have your dashboard with your own visualizations and share them with the Splunk community. Ever had the necessity to have fine-grain control over visualizations on your Splunk dashboards? This talk will show you everything you need to know about how to build your own custom data visualization experience. Work through real-world examples by customizing the very popular Buttercup games dashboard. By the end of this talk, you will be inspired to have your dashboard with your own visualizations and share them with the Splunk community.Ever had the necessity to have fine-grain control over visualizations on your Splunk dashboards? This talk will show you everything you need to know about how to build your own custom data visualization experience. Work through real-world examples by customizing the very popular Buttercup games dashboard. By the end of this talk, you will be inspired to have your dashboard with your own visualizations and share them with the Splunk community.Ever had the necessity to have fine-grain control over visualizations on your Splunk dashboards? This talk will show you everything you need to know about how to build your own custom data visualization experience. Work through real-world examples by customizing the very popular Buttercup games dashboard. By the end of this talk, you will be inspired to have your dashboard with your own visualizations and share them with the Splunk community.Ever had the necessity to have fine-grain control over visualizations on your Splunk dashboards? This talk will show you everything you need to know about how to build your own custom data visualization experience. Work through real-world examples by customizing the very popular Buttercup games dashboard. By the end of this talk, you will be inspired to have your dashboard with your own visualizations and share them with the Splunk community.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV2178.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV2178.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV2236 - Introduction to Collect Service",
    "SkillLevel": "Beginner",
    "Track": ["Developer", "Splunk Developer"],
    "Products": [
      "Splunk Data Fabric Search and Data Stream Processor",
      "Splunk Developer Cloud"
    ],
    "Speakers": [
      "Jove Zhong , Director, Engineering, Splunk",
      "Poornima Devaraj , Technical Product Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Collect Service is a new scalable method with high availability to collect data for Splunk Cloud Platform or Splunk Enterprise with Data Stream Processor(DSP). This session will cover the basic principles to show you how the Collect Service operates and why you need to use it, how the service is different from modular inputs, and how to leverage Collect Service‚Äôs REST API to automate data collection jobs efficiently.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/Dev2236.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV2236.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV2518 - Triggers & Alerts in the Splunk Cloud Platform",
    "Track": ["Developer", "Splunk Developer"],
    "Speakers": [
      "Declan Shanaghy , Architect Developer Platform, Splunk",
      "Miranda Luna , Product Management, Splunk"
    ],
    "Description": "In the new Splunk Cloud Platform, we‚Äôre reimagining the way we enable monitoring and alerting. Configure triggers to identify changes and anomalies in your data as they occur and determine the right action(s) that should be taken as a result ‚Äì email, Slack, VictorOps, etc. Leverage machine learning to bring your attention to the right insights and roll that back into your core monitoring strategy.¬† Come to this session to learn more about both the long-term vision and what‚Äôs immediately available. In the new Splunk Cloud Platform, we‚Äôre reimagining the way we enable monitoring and alerting. Configure triggers to identify changes and anomalies in your data as they occur and determine the right action(s) that should be taken as a result ‚Äì email, Slack, VictorOps, etc. Leverage machine learning to bring your attention to the right insights and roll that back into your core monitoring strategy.¬† Come to this session to learn more about both the long-term vision and what‚Äôs immediately available.In the new Splunk Cloud Platform, we‚Äôre reimagining the way we enable monitoring and alerting. Configure triggers to identify changes and anomalies in your data as they occur and determine the right action(s) that should be taken as a result ‚Äì email, Slack, VictorOps, etc. Leverage machine learning to bring your attention to the right insights and roll that back into your core monitoring strategy.¬† Come to this session to learn more about both the long-term vision and what‚Äôs immediately available.In the new Splunk Cloud Platform, we‚Äôre reimagining the way we enable monitoring and alerting. Configure triggers to identify changes and anomalies in your data as they occur and determine the right action(s) that should be taken as a result ‚Äì email, Slack, VictorOps, etc. Leverage machine learning to bring your attention to the right insights and roll that back into your core monitoring strategy.¬† Come to this session to learn more about both the long-term vision and what‚Äôs immediately available.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEV2518.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEV2518.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "DEV3288 - DataPaaS ‚Äì Simplifying Complexity with Automation and CI-CD",
    "Track": "Developer"
  },
  {
    "Event": ".conf19",
    "Title": "DEVS4G2287 - Splunking the 2018 Midterm Election!",
    "SkillLevel": "Advanced",
    "Track": ["Developer", "Splunk Developer"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Corey Marshall , Director, Splunk",
      "Satoshi Kawasaki , Splunk for Good Ninja, Splunk"
    ],
    "Industry": ["Non-Profit", "Public Sector"],
    "Description": "The Federal Election Commission (FEC) is an independent regulatory agency whose purpose is to enforce campaign finance law in US federal elections. The FEC provides a REST API to query all campaign data of every candidate. By collecting and analyzing the direct and indirect (Super PAC) contributions, Splunk can show the relative influence of each candidate of the midterm. Also learn how Splunk powers the Splunk for Good midterm website using Splunk's REST API, HEC, and Amazon S3 hosting. This talk is an update of the 2016 Presidential Election talk from .conf16.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/DEVS4G2287.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/DEVS4G2287.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1003 - Fields, Indexed Tokens and You",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1003.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/FN1003.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1045 - Saving Thousands of Hours Per Month at Paychex with Robotic Process Automation (RPA) and Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Brian Dudiak , Manager, RPA Program, Paychex",
    "Industry": "Not industry specific",
    "Description": "Robotic Process Automation (RPA) allowed Paychex to quickly eliminate over 18,000 hours of manual effort annually with only the first workflow, which was developed from start to finish in one month. Does your company have manual processes that could easily be automated through RPA efforts? If so, you could be saving thousands of hours and upwards of millions of dollars. In this session, we will show you how you can use RPA to deliver ROI and business value to your business units and executive-level management, and how Splunk can help monitor robot and workflow health and errors in real-time to developers. Robotic Process Automation (RPA) allowed Paychex to quickly eliminate over 18,000 hours of manual effort annually with only the first workflow, which was developed from start to finish in one month. Does your company have manual processes that could easily be automated through RPA efforts? If so, you could be saving thousands of hours and upwards of millions of dollars. In this session, we will show you how you can use RPA to deliver ROI and business value to your business units and executive-level management, and how Splunk can help monitor robot and workflow health and errors in real-time to developers.Robotic Process Automation (RPA) allowed Paychex to quickly eliminate over 18,000 hours of manual effort annually with only the first workflow, which was developed from start to finish in one month. Does your company have manual processes that could easily be automated through RPA efforts? If so, you could be saving thousands of hours and upwards of millions of dollars. In this session, we will show you how you can use RPA to deliver ROI and business value to your business units and executive-level management, and how Splunk can help monitor robot and workflow health and errors in real-time to developers.Robotic Process Automation (RPA) allowed Paychex to quickly eliminate over 18,000 hours of manual effort annually with only the first workflow, which was developed from start to finish in one month. Does your company have manual processes that could easily be automated through RPA efforts? If so, you could be saving thousands of hours and upwards of millions of dollars. In this session, we will show you how you can use RPA to deliver ROI and business value to your business units and executive-level management, and how Splunk can help monitor robot and workflow health and errors in real-time to developers.Robotic Process Automation (RPA) allowed Paychex to quickly eliminate over 18,000 hours of manual effort annually with only the first workflow, which was developed from start to finish in one month. Does your company have manual processes that could easily be automated through RPA efforts? If so, you could be saving thousands of hours and upwards of millions of dollars. In this session, we will show you how you can use RPA to deliver ROI and business value to your business units and executive-level management, and how Splunk can help monitor robot and workflow health and errors in real-time to developers.Robotic Process Automation (RPA) allowed Paychex to quickly eliminate over 18,000 hours of manual effort annually with only the first workflow, which was developed from start to finish in one month. Does your company have manual processes that could easily be automated through RPA efforts? If so, you could be saving thousands of hours and upwards of millions of dollars. In this session, we will show you how you can use RPA to deliver ROI and business value to your business units and executive-level management, and how Splunk can help monitor robot and workflow health and errors in real-time to developers.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1045.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1045.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1054 - Best Practices and Better Practices for Admins",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1054.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1054.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1061 - Lesser Known Search Commands",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Kyle Smith , Integration Developer, Aplura, LLC",
    "Industry": "Not industry specific",
    "Description": "Come learn some lesser known search commands! Amaze your co-workers, dazzle employers, learn something new! We will cover various commands that you might know about, but have never tried! ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1061.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1061.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1081 - Index Impasse- Limiting Data Access on a Per Event Basis",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Jeff Champagne , Director, Global SE Programs, Splunk",
      "Yisroel Bongart , Senior Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Is managing your growing list of indexes like herding cattle? Is your Master Node struggling against a stampede of buckets? Are you ducking bullets to satisfy data access requirements at the expense of usability or search performance? This session will demonstrate the advanced, role-based data access approach being used by several large Splunk customers. You will learn alternative methods to satisfy complex data access requirements without having to allocate hundreds or thousands of indexes. This method will allow you to focus on usability and search performance as your primary criteria for designing and managing your indexing strategy.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1081.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1081.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1096 - Public Data Exploration With Splunk",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Phil Meyerson , Security Analyst, EFSI @NASA",
    "Industry": "Not industry specific",
    "Description": "Splunk is known as an excellent platform for exploring machine-generated data. We'll explore how the platform can be used on open datasets to search for insight on real world issues such as election participation, public health, and other topics. Takeaways will include considerations for data acquisition and ingest, domain expertise, and successes and challenges from the perspective of a civic-minded individual. Lets see how far Splunk can take us!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1096.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1096.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1097 - App Sorcery 2- Building Better Splunk Apps with Best Practice",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Matt Eglin , Senior Professional Services Consultant, Splunk",
    "Industry": "Not industry specific",
    "Description": "Let's build a Splunk App and take it further! What makes a Splunk App tick? How do we build them? How do they make your Splunk life easier? How do they work in clusters? How can your app be approved for Splunk Cloud deployments, and how can your tried-and-tested, on-premises apps be migrated? All these questions will be answered in this session with real world examples direct from Splunk Professional Services. This is about Splunk app creation, from barebones to enterprise deployment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1097.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1097.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1098 - Harnessing Natural Curiosity for exploring data",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Kam Amir , Cloud Architect, Splunk",
    "Industry": "Not industry specific",
    "Description": "In a world full of AI, wouldn't it be nice to foster some Natural Curiosity?  Coming from a Humanities background, I tend to look at data a little differently than most engineers and data scientists. Using Splunk I'm able to freely navigate through the data and explore different use cases. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1098.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1098.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1137 - Forecasting Disk Usage with Machine Learning ‚Äì So easy, even a cave-person can do it!",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Steve Koelpin , Splunk Advisor, TransUnion",
    "Industry": "Not industry specific",
    "Description": "This presentation will walk users through how to use the machine learning toolkit to accurately forecast disk usage across their entire environment, giving them the exact day, month, and year when a server will run out of disk space. No more being awakened at 3:00 am for a bridge call due to a drive running out of disk. This process also can be used by capacity planning teams to select a future date and get a clear view of capacity across the business for all servers. Using machine learning to remove tech debt in an organization does not require a data scientist. You can do it if you have the right server metrics and the MLTK installed. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1137.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1137.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1172 - Splunk Python 3 Migration- What it Means for Your Deployment & Apps",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Aditya Tammana , Product Manager, Splunk",
    "Industry": "Not industry specific",
    "Description": "Stressed about Python 2.7 end-of-life? Terrified about how your Splunk deployment or apps will be impacted? Don‚Äôt be...we got you covered. It‚Äôs out with the old and in with the new, because Splunk is migrating to Python 3.7. As part of this migration, Splunk is also removing a handful of deprecated features. What‚Äôs the best way to learn if and what is changing for your Splunk? This session! Learn how to identify what‚Äôs impacted in your deployment or app and let us share our Python migration best practices. Soon, you too will be able to take advantage of the benefits of Python 3.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1172.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1172.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1190 - Running Splunk in an Air-gapped environment ",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Steve Schohn , Staff Sales Engineer, Splunk",
    "Industry": "Public Sector",
    "Description": "Many government agencies and for-profit companies require that you run Splunk on a network disconnected from the outside Internet. This presents many challenges, including how to cross air gaps and one-way transfers, how to operate indexers in an air-gapped environment, and how to automate backwards. This session will cover lessons learned from a variety of air-gapped deployments.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1190.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1190.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1200 - Data Onboarding Methodologies",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1200.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/FN1200.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1206 -  The path to operational enlightenment. An introduction to wire data with Splunk Stream.",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Simon O‚ÄôBrien , Principal Sales Engineer, Splunk",
      "Vinu Alazath , Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Have you ever wondered what Joe meant when he referred to 'Wire Data'? Today, you'll see the applicability of wire data in your organization, and you'll be amazed. Solve fraud, cybersecurity, ops, and business challenges, all with one single source of data. Wire data is the information that passes over computer and telecommunications networks to define communications between client and server devices. It is the result of decoding wire and transport protocols containing the bi-directional data payload. We will cover the use of wire data to solve security, IT operations, and business use cases, and see how the Splunk Stream platform is easily integrated into your existing data flows. The Splunk Essentials for Wire Data app from Splunkbase will be used to showcase dozens of examples using wire data to solve common business and technical issues. We will cover how to deploy and configure Splunk Stream in a distributed environment, including a demonstration.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1206.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1206.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1213 - The Two Most Common Machine Learning Solutions Everyone Needs to Know",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Amir Malekpour , Principal Software Engineer, Machine Learning, Splunk",
      "Eurus Kim , Staff ML Architect, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Tired of relying on static threshold-based alerts that don‚Äôt seem to provide much value? Do you typically end up finding outliers in your data by staring at lines on your dashboards? We are told machine learning is going make alerts and dashboards smarter, but how? We will help demystify machine learning and provide a practical guide to apply machine learning techniques for numeric outlier detection, and forecasting to make alerts and dashboards smarter and easier to use for actionable results. We will show you the basics of how you can understand your data, get them ready for machine learning, and get the machine to start working for you! You will leave the session beginning to think like a data scientist and knowing how to apply purpose-driven machine learning to your searches in Splunk! ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1213.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1213.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1263 - Harnessing the Power of Splunk and Google Cloud- Deploy, Ingest, and Beyond",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Alex Cain , Sr. Product Manager | Getting Data In, Splunk",
      "Roy Arsan , Cloud Partner Engineer, Google"
    ],
    "Industry": "Not industry specific",
    "Description": "Want to run Splunk on Google Cloud Platform (GCP)? Have a GCP environment you aren‚Äôt monitoring in Splunk? In this joint Google & Splunk session, you‚Äôll learn how to architect, build and scale a Splunk environment on GCP according to best practices for availability, performance and cost. We‚Äôll walk you through the setup of a real-world Splunk environment on GCP, as well as the various options available for ingesting valuable Google Cloud data in any Splunk environment. We‚Äôll leverage streaming services from Google Cloud like Pub/Sub and Dataflow to capture in near real-time operational, audit, billing, inventory data, and more. We‚Äôll then demonstrate how to analyze this wealth of data and get immediate insights for several use cases from IT Ops to Security.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1263.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1263.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1266 - Metrics- Past, Present, and Future",
    "SkillLevel": "Beginner",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "ILAM Siva , Product Management, Splunk",
      "Steve Zhang , Chief Scientist, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Curious about how to efficiently onboard and analyze metric data in Splunk? This talk will teach you the basic design and best practices for Splunk's Metric Indexes. Since they were introduced two years ago, Splunk's metric capabilities have quickly evolved. Now there is support for rollups, richer logs-to-metrics conversion capabilities, and a more efficient data representation formats. We also will discuss planned future enhancements and how you may best prepare for them today.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1266.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1266.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1288 - Migrating Splunk to AWS- lessons learned (or how recover from being a victim of your own success)",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Igor Alekseev , Amazon Web Services",
      "Shane Newman , RedHat, Inc. "
    ],
    "Industry": "Not industry specific",
    "Description": "At Red Hat, we‚Äôve been using Splunk since 2014. Since then, usage has grown significantly, from utilizing Splunk Enterprise, to introducing Splunk Enterprise Security, all the way to having more than 600 TB of data residing in Splunk, with the daily data ingestion expected to grow beyond 2.x terabytes per day. At this level, the on-premises infrastructure was reaching its limits, so we started to look for alternatives. Our first reaction was, 'Let‚Äôs throw some more hardware at it,' but we quickly came to the realization that if we were to continue on the path of implementing traditional infrastructure we wouldn‚Äôt solve our scalability problem. What did we do? Attend this talk to find out. We‚Äôll describe our journey as we moved our Splunk environment to Amazon Web Services (AWS), share details about the architecture, review data migration tactics, and overview some of the pain and lessons we learned along the way.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1288.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "FN1298 - Driving Adoption of Splunk in Your Enterprise",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Chris  Liddy , Director of Application Development, FIS",
      "Matt Collicoat , Head of Global Payments Innovation and Strategy, FIS"
    ],
    "Industry": "Not industry specific",
    "Description": "So, you have Splunk in your enterprise but people aren't using it. What do you do? After working with many organizations in financial services, we have heard the response 'yes, we use Splunk.' However, there is a large gap between the organizations that have a Splunk license and those that are truly using Splunk. What is the key to successful adoption of Splunk as an enterprise tool? In this session hear how FIS has driven an uptakein Splunk adoption across multiple business lines and external clients. Using Splunk, FIS have supported off-prescription solutions including system parameter inquiry, operator fraud, financial invoicing, client conference data analytics, staff resource allocations, and status reporting.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1298.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1298.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1300 - SPLendid uses for SPL in SPLunk",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1300.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/FN1300.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1315 - Cover Your Assets- Protect Your Knowledge Objects from Yourself (and Others) - A Paychex story",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Dustin Marling , Splunk App Developer, Paychex",
      "Eric Favreau , Service Health Operations Analyst, Paychex"
    ],
    "Industry": "Not industry specific",
    "Description": "'Did we just lose ALL our knowledge objects? Do you know how much time and energy that was?' After a destructive resync, Paychex lost two months of its knowledge object creations/modifications. We learned to be prepared if it were to ever happen again. How? It's easier than you might think, and you don't have to be an admin. You‚Äôll learn how to proactively save your work (dashboards, reports, data models, MLTK experiments, ITSI glass tables, macros, views, etc.) and audit changes when they occur. You will leave the session knowing how to manage the ever-increasing amount of things you create. You'll also have solutions that can save you time and effort from having to recreate lost/modified objects, including how to restore service faster. You also will come away with peace of mind knowing that you can take control of safeguarding and protecting your work, thereby covering your assets when a disaster happens.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1315.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1315.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1325 - DB Connect- Automating the H-E-Double Hockey Sticks Out of it",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Enterprise Security"
    ],
    "Speakers": "Ryan Moss , Principal Security Engineer, Verizon",
    "Industry": "Not industry specific",
    "Description": "Have you ever thought to yourself, 'Man, I love manually inputting new connections and inputs in DB Connect. It makes my life so much more fulfilling!' Yeah, neither have we. We will show you some simple ways to automate this process by utilizing cron schedules and bash scripts. We will focus on the technical side of automating DB Connect using real world examples to show you how we were able to overcome this hurdle, and how you can become the next Ninja Warrior of DB Connect.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1325.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1325.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1328 - Show and Tell- Prescriptive Use Cases for Azure and Office 365",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Jason Conger , Solution Architect, Splunk",
      "Ry Lait , Senior Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Let's face it, sometimes you don't know what you don't know. With vast amounts of cloud data coming in at cloud-speed, it can be difficult to see through the noise and know what to look for. Are malicious adversaries attempting to comprise the environment? Is my environment under- or over-provisioned? Do I have an insider possibly exfiltrating company data? Are employees actually using the services? What is all of this costing per service, department, business unit? Don't worry, we will help you figure all this out in a prescriptive manner by showcasing these and other use cases. Then, we will show you the 'how' by exposing the searches, the data needed, and showing you how to onboard that data. You will walk away with use cases that can be implemented immediately in your own environment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1328.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1328.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1350 - Splunk Performance-  making hardware and platform choices",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Brian Wooden , Director, Sales Engineering GSA, Splunk",
      "Simeon Yep , AVP, Sales Engineering Global Partners, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Splunk Enterprise is powerful. Don't cheat yourself of its power. When making decisions as to how to expand or standup Splunk‚Äôs footprint, you need to know what matters when making platform decisions. Considering compute, storage, virtualization, cloud infrastructure is a lot. There isn‚Äôt one place to review all the options you have. We will share the Splunk way to think of performance and how it relates to the underlying system resources. This means getting into the real nuts and bolts of performance. If you want to know how search affects indexing and what resources get consumed, this is the session to attend. If you also want to know how it affects what you purchase as a platform choice, this also is the session to attend. We also will review how partners have built architectures to simplify this process.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1350.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1350.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1352 - Blockchain is entering the enterprise, see what Splunk is doing and how you can leverage it.",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Jeff Wu , Senior Product Manager, Blockchain, Splunk",
      "Nate McKervey , Head of Blockchain and DLT, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Blockchain applications and infrastructure are new, complex, and generate a variety of data. Splunk is a perfect match for ingesting, analyzing, and gaining insights from data on-chain, off-chain, and even cross-chain. Organizations can now monitor the health, performance, and security of blockchain infrastructure as well gain insights by analyzing transactions and correlate with external data. In this session you will get to see it all in action (live demos!) and even participate yourself, there might even be some free cryptocurrency given away.  Blockchain applications and infrastructure are new, complex, and generate a variety of data. Splunk is a perfect match for ingesting, analyzing, and gaining insights from data on-chain, off-chain, and even cross-chain. Organizations can now monitor the health, performance, and security of blockchain infrastructure as well gain insights by analyzing transactions and correlate with external data. In this session you will get to see it all in action (live demos!) and even participate yourself, there might even be some free cryptocurrency given away. Blockchain applications and infrastructure are new, complex, and generate a variety of data. Splunk is a perfect match for ingesting, analyzing, and gaining insights from data on-chain, off-chain, and even cross-chain. Organizations can now monitor the health, performance, and security of blockchain infrastructure as well gain insights by analyzing transactions and correlate with external data. In this session you will get to see it all in action (live demos!) and even participate yourself, there might even be some free cryptocurrency given away. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1352.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1352.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1366 - Enhanced Anomaly Detection- Join T-Mobile and Splunk as we Deep Dive an Enterprise-IT Operational Use Case",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Iman Makaremi , Principal Product Manager ‚Äì Machine Learning and AI, Splunk",
      "Scott Garcia , MTS - Member Technical Staff, T-Mobile"
    ],
    "Industry": "Technology",
    "Description": "Is confidence in your ability to disassociate real alerts from noise at an all-time low? Are alerts becoming ineffective because they‚Äôre excessive? Many organizations across many industries wrestle with these questions daily. Even so, the prevalence of alert noise persists. Join us to understand how T-Mobile is using Splunk Enterprise with the Splunk Machine Learning Toolkit to identify and narrow the point of origin of service-impacting events across our suite of enterprise applications. Using the DensityFunction algorithm to highlight anomalous behavior, we‚Äôre able to focus an investigation on a small subset of the applications which in turn leads to faster resolution of the issues we‚Äôre confronted with.  ¬† Is confidence in your ability to disassociate real alerts from noise at an all-time low? Are alerts becoming ineffective because they‚Äôre excessive? Many organizations across many industries wrestle with these questions daily. Even so, the prevalence of alert noise persists. Join us to understand how T-Mobile is using Splunk Enterprise with the Splunk Machine Learning Toolkit to identify and narrow the point of origin of service-impacting events across our suite of enterprise applications. Using the DensityFunction algorithm to highlight anomalous behavior, we‚Äôre able to focus an investigation on a small subset of the applications which in turn leads to faster resolution of the issues we‚Äôre confronted with.Is confidence in your ability to disassociate real alerts from noise at an all-time low? Are alerts becoming ineffective because they‚Äôre excessive? Many organizations across many industries wrestle with these questions daily. Even so, the prevalence of alert noise persists. Join us to understand how T-Mobile is using Splunk Enterprise with the Splunk Machine Learning Toolkit to identify and narrow the point of origin of service-impacting events across our suite of enterprise applications. Using the DensityFunction algorithm to highlight anomalous behavior, we‚Äôre able to focus an investigation on a small subset of the applications which in turn leads to faster resolution of the issues we‚Äôre confronted with.Is confidence in your ability to disassociate real alerts from noise at an all-time low? Are alerts becoming ineffective because they‚Äôre excessive? Many organizations across many industries wrestle with these questions daily. Even so, the prevalence of alert noise persists. Join us to understand how T-Mobile is using Splunk Enterprise with the Splunk Machine Learning Toolkit to identify and narrow the point of origin of service-impacting events across our suite of enterprise applications. Using the DensityFunction algorithm to highlight anomalous behavior, we‚Äôre able to focus an investigation on a small subset of the applications which in turn leads to faster resolution of the issues we‚Äôre confronted with.Is confidence in your ability to disassociate real alerts from noise at an all-time low? Are alerts becoming ineffective because they‚Äôre excessive? Many organizations across many industries wrestle with these questions daily. Even so, the prevalence of alert noise persists. Join us to understand how T-Mobile is using Splunk Enterprise with the Splunk Machine Learning Toolkit to identify and narrow the point of origin of service-impacting events across our suite of enterprise applications. Using the DensityFunction algorithm to highlight anomalous behavior, we‚Äôre able to focus an investigation on a small subset of the applications which in turn leads to faster resolution of the issues we‚Äôre confronted with.Is confidence in your ability to disassociate real alerts from noise at an all-time low? Are alerts becoming ineffective because they‚Äôre excessive? Many organizations across many industries wrestle with these questions daily. Even so, the prevalence of alert noise persists. Join us to understand how T-Mobile is using Splunk Enterprise with the Splunk Machine Learning Toolkit to identify and narrow the point of origin of service-impacting events across our suite of enterprise applications. Using the DensityFunction algorithm to highlight anomalous behavior, we‚Äôre able to focus an investigation on a small subset of the applications which in turn leads to faster resolution of the issues we‚Äôre confronted with.¬†¬†",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1366.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1366.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1373 - Drive effective Splunk enablement and adoption & build user cohorts using internal logs and machine learning ",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Anand Ladda , Staff Solutions Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Wouldn‚Äôt it be a great if we had Splunk‚Äôs version of Moneyball; an application where everyone comes out ahead by leveraging data to drive effective Splunk enablement and adoption? Splunk‚Äôs internal logs have a wealth of information about how Splunk is being used within your organization. Let‚Äôs take drinking the 'Splunk Champagne' to the next level by applying statistics and machine learning to Splunk‚Äôs internal logs! This session will cover segmenting users based on their search profiles - number of searches run, average response times, and recency of searches executed, among other criteria. We‚Äôll use techniques such as clustering to classify users from novice to experts, and use TF-IDF and text analytics techniques to understand commands used in search strings. Enriching this data with completed and planned Splunk Education courses, lunch & learn sessions, and other training activities will enable your users to achieve the Splunk Ninja status they‚Äôre looking for! ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1373.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1373.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1380 - Improving Live Musical Performances with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Machine Learning Toolkit"],
    "Industry": "Technology"
  },
  {
    "Event": ".conf19",
    "Title": "FN1390 - Using Machine Learning to Detect Traffic Anomalies",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["AI/ML", "Splunk Machine Learning Toolkit"],
    "Speakers": "Jim Goodrich , Senior Sales Engineer, Splunk",
    "Industry": ["Non-Profit", "Technology"],
    "Description": "Finding anomalies in network data is no easy task, especially when you have terabytes of logs per day to analyze. But have no fear, we‚Äôre going to teach you how. In this session we will perform a technical deep dive into how a global content delivery network provider is using Splunk‚Äôs Machine Learning Toolkit to discover anomalies in network traffic. We‚Äôll take you on a data science journey and show you how we tested multiple anomaly detection techniques, overcame challenges, fine-tuned detections, and ultimately arrived at meaningful alerts based on machine learning.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1390.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1390.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1402 - Best practises for forwarder hierarchies",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1402.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/FN1402.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1407 - Master Search Speed",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Andrew Landen , Sr Splunk Developer, Chevron",
    "Industry": "Not industry specific",
    "Description": "Imagine improving the speed of your searches over 500k times faster and breathe new life into your Splunk environment without more hardware investment. ¬†Learn how to use both time and segmentation with fast subsearches to quickly filter events for fast, advanced data correlation. ¬†Based on the .conf17 talk 'Fields, Indexed Tokens, And You'n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1407.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1407.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1408 - Agent Based Modeling for CryptoFinance in Splunk",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Machine Learning Toolkit"],
    "Speakers": [
      "Nick Gans , Research and Development Lead, Inca Digital Securities",
      "Zach Finzi , Research & Software Director, Inca Digital Securities"
    ],
    "Industry": "Technology",
    "Description": "Cryptocurrency ecosystems are highly complex, distributed, and rapidly evolving, rendering many existing financial models ineffective. By aggregating the heterogeneous data streams that are produced by distinct groups within crypto (blockchains, mining pools, exchanges, etc.), we have built a unified analytical platform called Nakamoto Terminal (NTerminal) using Splunk. By leveraging NTerminal, we are creating an adapted agent-based modeling (ABM) system; agents monitor the state of the ecosystem by consuming real time updates from the individual data sources that modulate their state and connectivity. Different heuristic models are called upon to facilitate data transformations and agent interactions. Within this ecosystem, collective agent activity reveals emergent properties and patterns of behavior. With Splunk as the centerpiece, integrated reports, dashboards, or searches allow you to better navigate the ecosystem of interest.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1408.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1408.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1409 - Advances in Deep Learning with the MLTK Container for TensorFlow 2.0, PyTorch and Jupyter Notebooks",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Anthony Tellez , Staff Data Scientist, Splunk",
      "Philipp Drieger , Staff Machine Learning Architect , Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Deep Learning frameworks like TensorFlow and PyTorch let you extend Splunk's Machine Learning Toolkit with custom algorithms that provide you with an edge for advanced AI and ML use cases in Security, IT Operations, IoT or for any advanced custom analytics. In this talk you learn about the latest evolution to streamline the usage of TensorFlow 2.0 and PyTorch with the MLTK Container extension. Integrated Jupyter Notebooks help data scientist to accelerate their custom model development, deployment and operationalization. The MLTK Container can leverage GPUs for parallel computing and accelerate model training for big complex datasets. This session is suitable for all python-minded data scientists and developers who want to tap into deep learning use cases with Splunk. n  ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1409.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1409.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1425 - Analyzing and Visualizing Streaming Telemetry Data with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Jianning Guo , Solution Architect, Cisco Systems",
    "Industry": "Technology",
    "Description": "Streaming telemetry is a new approach supported by major networking companies such as Cisco,  as well as service providers. It provides better real time data of routing/switching devices without the performance impact that comes with SNMP. Network operators who turn to streaming telemetry often have sophisticated goals in mind and are not simply looking to collect data and throw it onto a graph. Instead, they are looking at advanced use cases where further processing is performed on the data (e.g., analytics or machine learning) and intelligent action is triggered based on this analysis. This presentation. will discuss how to get telemetry data into Splunk to search, analyze, visualize, and create alerts including examples from an existing deployment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1425.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1425.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1435 - Sizing Splunk SmartStore- Spend Less and Get More Out of Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Bharath Aleti , Director, Product Management, Splunk",
      "Jane Jokl , Offering Manager, IBM",
      "Jon Rust , Splunk Architect, ADP"
    ],
    "Industry": "Not industry specific",
    "Description": "Data is growing exponentially; however IT budgets are not.¬† Growth in internal use cases and additional data sources can put organizations under intense pressure to manage spiraling costs. The good news is that help is on the way. We will show how to size and configure Splunk SmartStore to yield significant cost savings, for both current and future data growth. In addition, learn how to configure the Splunk deployment for optimal search performance. Spare a few minutes of your time at .conf19 and see it yield big returns for your organization.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1435.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1435.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1445 - 7 Super Solutions- Growing, Developing and Administering Splunk@Murex",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Robert Lynch , Head of Splunk@Murex, Murex",
    "Industry": "Technology",
    "Description": "The 2017 'Splunk Ninja Winner' and 2019 'Commander Award' finalist will tell the story of‚Ä¶ n n Moving from 1 to 100 global users the issues faced and solutions produced! This talk discusses the technical and human challenges when working for a major financial software company Murex. By using 7 examples, the talk will illustrate‚Ä¶.n 1.¬†¬†¬†¬†Where is my Data! (Growing)n 2.¬†¬†¬†¬†Fast Forwarder Deployment (Admin)n 3.¬†¬†¬†¬†Data is only ¬Ω the Battle (Growing)n 4.¬†¬†¬†¬†A Snapshot in Time (Dev)n 5.¬†¬†¬†¬†Different user‚Äôs different roles (Admin)n 6.¬†¬†¬†¬†Improving Debugging X10 (Dev)n 7.¬†¬†¬†¬†Code Versioning (Dev)n The 2017 'Splunk Ninja Winner' and 2019 'Commander Award' finalist will tell the story of‚Ä¶ The 2017 'Splunk Ninja Winner' and 2019 'Commander Award' finalist will tell the story of‚Ä¶ Moving from 1 to 100 global users the issues faced and solutions produced! This talk discusses the technical and human challenges when working for a major financial software company Murex. By using 7 examples, the talk will illustrate‚Ä¶.n 1.¬†¬†¬†¬†Where is my Data! (Growing)n 2.¬†¬†¬†¬†Fast Forwarder Deployment (Admin)n 3.¬†¬†¬†¬†Data is only ¬Ω the Battle (Growing)n 4.¬†¬†¬†¬†A Snapshot in Time (Dev)n 5.¬†¬†¬†¬†Different user‚Äôs different roles (Admin)n 6.¬†¬†¬†¬†Improving Debugging X10 (Dev)n 7.¬†¬†¬†¬†Code Versioning (Dev)Moving from 1 to 100 global users the issues faced and solutions produced! This talk discusses the technical and human challenges when working for a major financial software company Murex. By using 7 examples, the talk will illustrate‚Ä¶.n 1.¬†¬†¬†¬†Where is my Data! (Growing)n 2.¬†¬†¬†¬†Fast Forwarder Deployment (Admin)n 3.¬†¬†¬†¬†Data is only ¬Ω the Battle (Growing)n 4.¬†¬†¬†¬†A Snapshot in Time (Dev)n 5.¬†¬†¬†¬†Different user‚Äôs different roles (Admin)n 6.¬†¬†¬†¬†Improving Debugging X10 (Dev)n 7.¬†¬†¬†¬†Code Versioning (Dev)Moving from 1 to 100 global users the issues faced and solutions produced! This talk discusses the technical and human challenges when working for a major financial software company Murex. By using 7 examples, the talk will illustrate‚Ä¶.Moving from 1 to 100 global users the issues faced and solutions produced! This talk discusses the technical and human challenges when working for a major financial software company Murex. By using 7 examples, the talk will illustrate‚Ä¶.Moving from 1 to 100 global users the issues faced and solutions produced! This talk discusses the technical and human challenges when working for a major financial software company Murex. By using 7 examples, the talk will illustrate‚Ä¶.Moving from 1 to 100 global users the issues faced and solutions produced! This talk discusses the technical and human challenges when working for a major financial software company Murex. By using 7 examples, the talk will illustrate‚Ä¶.1.¬†¬†¬†¬†Where is my Data! (Growing)1.¬†¬†¬†¬†Where is my Data! (Growing)1.¬†¬†¬†¬†Where is my Data! (Growing)1.¬†¬†¬†¬†Where is my Data! (Growing)2.¬†¬†¬†¬†Fast Forwarder Deployment (Admin)2.¬†¬†¬†¬†Fast Forwarder Deployment (Admin)2.¬†¬†¬†¬†Fast Forwarder Deployment (Admin)2.¬†¬†¬†¬†Fast Forwarder Deployment (Admin)3.¬†¬†¬†¬†Data is only ¬Ω the Battle (Growing)3.¬†¬†¬†¬†Data is only ¬Ω the Battle (Growing)3.¬†¬†¬†¬†Data is only ¬Ω the Battle (Growing)3.¬†¬†¬†¬†Data is only ¬Ω the Battle (Growing)4.¬†¬†¬†¬†A Snapshot in Time (Dev)4.¬†¬†¬†¬†A Snapshot in Time (Dev)4.¬†¬†¬†¬†A Snapshot in Time (Dev)4.¬†¬†¬†¬†A Snapshot in Time (Dev)5.¬†¬†¬†¬†Different user‚Äôs different roles (Admin)5.¬†¬†¬†¬†Different user‚Äôs different roles (Admin)5.¬†¬†¬†¬†Different user‚Äôs different roles (Admin)5.¬†¬†¬†¬†Different user‚Äôs different roles (Admin)6.¬†¬†¬†¬†Improving Debugging X10 (Dev)6.¬†¬†¬†¬†Improving Debugging X10 (Dev)6.¬†¬†¬†¬†Improving Debugging X10 (Dev)6.¬†¬†¬†¬†Improving Debugging X10 (Dev)7.¬†¬†¬†¬†Code Versioning (Dev)7.¬†¬†¬†¬†Code Versioning (Dev)7.¬†¬†¬†¬†Code Versioning (Dev)7.¬†¬†¬†¬†Code Versioning (Dev)",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1445.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1445.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1452 - Splunk Autobahn - SaaS proof of value program- from 0 to HERO",
    "SkillLevel": "Beginner",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Ken Tallman , Sr Sales Engineer, Splunk ",
    "Industry": "Not industry specific",
    "Description": "You already know Splunk is amazing, but now you have to prove this to someone in your organization before you get the keys to your Splunky Supercar. Good news - we've got a solution that gets your data - not fake data - into Splunk Cloud, and makes it immediately accessible, useable and valuable to everyone in your organization. You'll be able to kick-the-tires on your new data analytics engine for 30 days at no cost. Attend this session to learn more.... Let me introduce you to the Autobahn, Splunk-style.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1452.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1452.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1455 - ELK vs. Splunk",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Kate Lawrence-Gupta , Platform Architect, Splunk",
    "Industry": "Not industry specific",
    "Description": "This session will present a side-by-side, high-level comparison of the features, assumptions, and architectures of a Splunk and ELK deployment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1455.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1455.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1470 - Machine Learning & Splunk 2019- The Splunk Machine Learning Toolkit in Action",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Harsh  Keswani , Product Manager: Machine Learning, Splunk",
      "Iman Makaremi , Principal Product Manager ‚Äì Machine Learning and AI, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Anomaly Detection, Predictive Analytics, and Clustering ‚Äî oh my! Splunk customers want answers from their data, and machine learning is here to help. This session will help demystify the machine learning process, show how common machine learning themes are used for different outcomes at customers around the world, and give you next steps for achieving success at home by implementing machine learning! We aren‚Äôt talking about just science projects. We'll be giving examples and public details about Splunk‚Äôs Machine Learning Advisory successes over the years. Expect to leave with tangible examples you can implement back in the real world - if you can Escape from Vegas! ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1470.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1470.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1486 - Visualizing and Augmenting Your Data with Splunk AR on Your Mobile Device",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Sulabh Agarwal , Network Consulting Engineer, Cisco Systems",
    "Industry": "Technology",
    "Description": "How about having an immersive data experience on your mobile device via augmented reality? Think about being in a data center where you just need to scan the QR code/NFC tag on your stacked devices to know the critical device metrics on your mobile. This session will show you how Splunk AR can be used to visualize the dashboard data that users create on the Splunk platform. Visit this session and you will learn how to create apps, dashboards and immersively reflect the data on your mobile using Splunk AR.¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1486.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1486.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1540 - You Only Learn Once (YOLO)",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Machine Learning Toolkit"],
    "Speakers": [
      "Ankit Bhagat , Forward Deployed Software Engineer, Splunk",
      "Karthika Krishnan , Senior Forward Deployed Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Want to use your custom model with the data already in Splunk? Want to contribute to an open library for Machine Learning Toolkit (MLTK) algorithms? Want to use your favorite Machine Learning library? This session will help you to create custom algorithms and leverage the power of any ML algorithm you have ever wanted to use for your application. Traverse the entire process from building a custom algorithm, fitting the model to your data, testing your application, to contributing to the MLTK Algorithms library on Github.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1540.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1540.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1553 - The New Experiment Experience in the Splunk Machine Learning Toolkit",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Gyanendra Rana , Senior Product Manager, Splunk",
      "Ryan Oriecuia , Principal Software Developer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Hey mad scientist, why so angry? Learn how Splunk is rethinking experiments in the Machine Learning Toolkit (MLTK) to make your life easier. Find out how we're changing the experiment workflow to reflect real-world usage of the MLTK, and make it easier for people new to the MLTK to get up and running. Strap on your safety goggles and let's get experimenting! ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1553.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1553.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1561 - Data Onboarding- Where do I begin-",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Enterprise Security"
    ],
    "Speakers": "Luke Netto , Staff Professional Services Consultant, Splunk",
    "Industry": "Not industry specific",
    "Description": "How do I get data into Splunk? What is a sourcetype? Does Splunk already know how to handle my data? What app do I use? What if all my data is syslog? If you are asking these questions, then this session is for you. After all, data quality is the foundation of becoming a data-driven organization. This session will walk through onboarding fundamentals. We will discuss the importance of a timestamp and what to do if your data may not have one. We will explain when to use an existing or create a new sourcetype. We will review the process of examining an app from Splunkbase and determining what sourcetype the app expects. By the end of this session you will no longer use syslog as a sourcetype, but as a means of collecting data.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1561.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1561.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1568 - Splunk in a Blockchain world- Development--Monitoring--Alerting--Repeat",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Augustine Opoku , Director of Production Engineering, Axoni",
      "Michael Michaelides , VP of Engineering, Applications, Axoni"
    ],
    "Industry": "Financial Services",
    "Description": "Are you looking into Blockchain/DLT solutions but not sure how you plan to monitor and alert your internal teams? What are the components and areas on which my team should be focused? How do I turn my team from reactive to proactive? Is monitoring an afterthought that becomes the responsibility of your support teams? In this session we will deep dive into the components of DLT , dashboards, and how to embed a monitoring mindset into your teams.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1568.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1568.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1570 - How to troubleshoot blocked ingestion pipeline queues with Indexers and Forwarders",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Harendra Rawat , Senior Principal Software Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "How many of you have experienced pipeline queues blocking? Almost everyone. This session will provide an overview of Splunk Indexing pipelines and a deep dive into detecting blocked queues, troubleshooting tips to identify the root cause and how to resolve them. How many of you have experienced pipeline queues blocking? Almost everyone. This session will provide an overview of Splunk Indexing pipelines and a deep dive into detecting blocked queues, troubleshooting tips to identify the root cause and how to resolve them.How many of you have experienced pipeline queues blocking? Almost everyone. This session will provide an overview of Splunk Indexing pipelines and a deep dive into detecting blocked queues, troubleshooting tips to identify the root cause and how to resolve them.How many of you have experienced pipeline queues blocking? Almost everyone. This session will provide an overview of Splunk Indexing pipelines and a deep dive into detecting blocked queues, troubleshooting tips to identify the root cause and how to resolve them.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1570.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1570.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1586 - A novel introduction to Machine Learning",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Magnus Johansson , Solution Architect, IKEA",
      "Simon Ogden , Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "It‚Äôs time to demystify Machine learning:n - ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†Do you typically ask your friends what they will order, before you decide what you will order? Did you know that already the ancient Greeks clued out that numbers rules the universe?n -¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† What makes machine learning so powerful considering the human brain is way smarter.... but maybe not always?n -¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† This session will walk you through the basics of machine learning, what is it, what it is not. How to avoid pitfalls.n -¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† After this session you will have knowledge around the concept of Machine Learning,¬† what the pre-built Splunk ML products are as well as IKEAs exploration of Splunk`s different ML techniques.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1586.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1586.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1588 - Feeding the Beast- The fine art of self-service knowledge object and search management",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Tim Clancy , Engineering Manager, Atlassian",
    "Industry": "Not industry specific",
    "Description": "The joys, freedoms, and advantages of running a Splunk 'data democracy' at scale are numerous and well documented. However, as with many aspects of life, where there is huge upside a dark downside often lurks. How do I mange thousands of knowledge objects, or help users make their searches faster and more efficient, or deal with a myriad of small, but still time-consuming operational challenges? For answers, come and listen to this presentation by Atlassian, the world leader in software collaboration tools. Hear how the Atlassian team not only tackled such problems head on, but also how they showed users how to manage these issues in the most effective and innovative ways. From clearing out unused dashboards, to scheduling searches and lookups, to exposing the performance of searches in a developer-friendly way, we have tips, tricks, and advice for all comers, irrespective of where you are on your Splunk journey.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1588.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1588.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1590 - Putting the Seamless into SSO",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Sam Wilson , Senior Systems Engineer, Atlassian",
    "Industry": "Not industry specific",
    "Description": "Ever wanted to create a seamless sign-on experience for your Splunk users, irrespective of when, where, who, or how many? If so come and listen to how Atlassian, the world leader in software collaboration tools, did just that. Atlassian‚Äôs in-house Splunk Enterprise cluster runs on Amazon Web Services and we wanted to take advantage of the latest and greatest authentication features released for the Application Load Balancer to provide that much-sought-after, seamless SSO experience for all our Splunk users. Join us as we share the technical wrangling required to make this magic happen and expand on how we leveraged the Splunk scripted authentication mechanism to introduce support for JSON web toke- based authentication. The cherry on top will be the chance to discover some of the unexpected things we learned along the way, because no tale is complete without a war story and everyone loves a great war story!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1590.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1590.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1628 - From hell to heaven- growing Splunk Cloud from 1TB to 13TB a day",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Cloud",
    "Speakers": [
      "David Ashe , Senior Site Reliability Engineer, Paddy Power Betfair",
      "Gerard Healy , SRE, Paddy Power Betfair"
    ],
    "Industry": "Technology",
    "Description": "The true story of how Paddy Power Betfair, the international, multi-channel sports betting and gaming operator went from sending two terabytes to 13 terabytes of data to Splunk each day. The massive, self-inflicted performance issues we encountered originated from not tuning to Splunk to keep pace. This talk explains all the great work that was undertaken to properly fine tune Splunk back into shape.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1628.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1628.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1631 - User Experience Modeling with the Splunk Machine Learning Toolkit",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["AI/ML", "Splunk Machine Learning Toolkit"],
    "Speakers": "Ken Tupper , Lead Performance Engineer, Paychex",
    "Industry": "Financial Services",
    "Description": "Paychex‚Äôs goal of providing the best user experience for our clients has led to a significant investment in performance testing and monitoring of our applications. Currently all Paychex applications record the execution time for every task and subtask to logs. These are indexed by Splunk, allowing us to identifying areas where changes to code and database queries will have a positive impact on the overall user experience. This presentation will focus on combining this user experience data with client demographic data (such as the number of active employees) and using the Splunk Machine Learning Toolkit to build predictive models of user experience based on client demographic data. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1631.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1631.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1635 - What's on your bucket list-  Scalability and high volume performance of indexer clustering at Splunk.",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Brent Davis , Principal Performance Engineer, Splunk",
      "Cher-Hung Chang , Principle Software Engineer, Splunk",
      "Justin Lin , Performance Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "As customers add more and more data to Splunk, indexer clusters with large volumes of indexers, indexes, and buckets are becoming commonplace. In Splunk labs we run intensive tests to explore the boundaries of the largest indexer clusters. This session will discuss the lifecycle of a Splunk bucket, why it is a key metric in indexer scalability, and which indicators and tunables to monitor in a very large cluster. We'll also share how we do performance testing, the latest performance results, and best practices for scaling your Splunk Enterprise cluster to 20 million unique buckets and beyond.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1635.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1635.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1647 - Splunk Cloud's Silver Lining",
    "SkillLevel": "Beginner",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Kam Amir , Cloud Architect, Splunk",
      "Kyle Hourihan , Principal Cloud Architect, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you considering moving to Splunk Cloud? This session will show you the benefits of migrating to Splunk Cloud and letting Splunk do all the heavy lifting so you can focus on getting value from your data. We also will go into what makes the Splunk Cloud service unique. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1647.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1647.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1651 - Take Control of Port 514!- Taming the Syslog Beast",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Data Fabric Search and Data Stream Processor",
      "Splunk Enterprise"
    ],
    "Speakers": [
      "Mark Bonsack , Staff Sales Engineer, Splunk",
      "Ryan Faircloth , Security Product Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you frustrated with the task of configuring syslog servers yourself to properly ingest data into Splunk? Take control of the syslog beast once and for all and point your '514' traffic to the new Splunk Connect for Syslog! This new Splunk-supported connector makes quick work of past struggles with syslog servers, sourcetyping, data enrichment, and scale. In this session we will dive into the configuration of the Splunk Connect for Syslog to properly filter, sourcetype, and format your data. We will demonstrate several out-of-the-box examples, highlighting new functionality such as HEC and Kafka transport for resiliency and scale, simple extensions for new device types, and data enrichment that extends far beyond simple sourcetyping of the raw message. Lastly, we will look forward to the integration of syslog with Splunk's new Data Stream Processor, and highlight appropriate use cases for each solution. By the time we wrap up, you will know how to tame the syslog beast!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1651.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1651.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1655 - Auto-Monitoring of search workloads with Workload Management",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Bhavin Thaker , Director of Engineering, Splunk",
      "Jeremiah Cutting , Sr Staff IT Engineer, Qualcomm",
      "Shalabh Goyal , Principal Product Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "How do you ensure that business-critical searches are not impacted by non-critical searches? How do you divvy up Splunk search capacity among internal teams? How do you assign appropriate resources for ingestion and search? Do you want to monitor runaway/rogue searches in real time and prevent adverse impact on the rest of your users? If you are struggling with these questions, this is the session for you! Splunk Workload Management puts you in control. It allows you to define resource pools, access to them, limit the maximum number of concurrent searches in a pool, and monitor rogue searches. Using Linux cgroups to allocate CPU and memory to different pools, Workload Management allows you to create separate pools for ingestion and search. You can create sub-pools within search to isolate incoming searches. The rules can be defined based on search type, user, roles, application etc. Even better, you can monitor for rogue searches and automatically abort or throttle them.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1655.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1655.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1679 - Splunking Crime Part II - Analysing Bias in Police Actions",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Machine Learning Toolkit"],
    "Speakers": "Shashank Raina , Professional Services Consultant, NCC Group",
    "Industry": "Non-Profit",
    "Description": "Last year at .conf18 we used Splunk and Machine Learning Toolkit (MLTK) to analyze and predict the crime in London. This year we are taking a step forward and analyzing the bias in the police actions in the U.K. We will use police, population, religion, and race data to understand how police use their powers in different areas on people from different racial backgrounds. We will use open data sources and index them in Splunk. Using advanced visualizations we will analyze the data and understand more about police actions. Then using MLTK we will create a predictive model for crimes and then analyze the model for any bias due to the data provided. Machine bias is a real issue nowadays when machine learning algorithms are increasingly being used by government agencies to predict crime and even pass sentences on convicts. We need to understand that along with having positive impact of predicting crime, it can have a long-lasting negative impact as well.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1679.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1679.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1698 - Winning in Starcraft 2; An Analysis of Skill Using SPL & MLTK",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Industry": "Technology",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1698.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/FN1698.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1716 - How we understand your intent - Splunk Natural Language Platform (NLP)",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise", "Splunk Mobile"],
    "Speakers": [
      "Anand Srinivasabagavathar , Senior Software Engineer, Splunk",
      "Aungon Nag Radon , Sr. Data Scientist, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Understanding the intent of a natural language search is a major component of any natural language processing system. Although there are numerous machine learning and deep learning techniques to solve complex problems in natural language processing, such as understanding intent also known as natural language understanding, very few of them discuss the challenges in production. In this session we take you on a journey from development to production of natural language understanding component of Splunk Natural Language Platform. We will discuss several engineering and data science challenges, and also provide holistic approaches to overcome those challenges. Attendees of the session should walk away with a deeper understanding of different state-of-the-art techniques, such as understanding the intent of a natural language search query, that can help them build their own applications in the natural language processing domain. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1716.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1716.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1727 - Tailoring Your Data Fabric to Custom Fit Your (SOCs-NOCs) Data Needs- ",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Manuel Martinez , Software Engineer: Federated Search, Splunk",
      "Niti Halakatti , Software Engineer: Federated Search, Splunk "
    ],
    "Industry": "Not industry specific",
    "Description": "Data Fabric Search (DFS) is a paradigm shift from native Splunk and introduces several new innovative concepts such as core scaling and federated search. This sparks questions regarding: How to maximize search performance using DFS conf parameters? How to size the DFS Spark cluster? and What search time speed ups can I expect with DFS? This discourse aims to answer these questions and presents DFS best practices in the context of improving and discovering business use cases.¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1727.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1727.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1735 - What‚Äôs next in Geo for Splunk ",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Developer Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Aditi Nath , Software Development Engineer, Splunk",
      "Geoffrey hendrey , Sr Principal Engineer, splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "This session will be all about exciting Foundations/Platform-related content that we'll announce at .conf19. We can't tell you about it now, but trust us ‚Äî it's awesome.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1735.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1735.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1740 - What's new in SPL2-",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Cloud",
    "Speakers": [
      "Alex James , Sr. Principal Architect, Splunk",
      "Andrew Peters , Senior Principal Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "This session will be all about exciting Foundations/Platform related content that we'll announce .conf19. We can't tell you about it now, but trust us ‚Äî it's awesome.n n ¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1740.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1740.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1746 - Getting the Most Out of Splunk Natural Language Platform",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Cynthia Li , Sr. Product Manager, Splunk",
      "Yow Han Moo , Senior Engineering Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Do you get overwhelmed with writing Splunk queries for your users all the time? Wouldn‚Äôt a world where your executives and other casual Splunk users could get the answers they want without knowing SPL be nice? With Splunk Natural Language Platform (NLP), your users can talk to their data‚Äìliterally‚Äìand get their answers right from their smartphones or AppleTV.n In this session, we‚Äôll walk through how to set up NLP, create user intents, and optimize the accuracy of the results. We‚Äôll also show you how to re-create the NLP experiences seen onstage and other tips for how to get the most out of Splunk NLP for your organization.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1746.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1746.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1749 - Beyond the Desktop- Making the Most out of Mobile",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Ben Weaver , Senior iOS Engineer, Splunk",
      "Simon Tam , Senior Principal Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "With Splunk Mobile and Splunk TV, the power of Splunk now extends beyond your desktop. These apps unlock new ways to get the most out of your data and the most out of Splunk. In this session we‚Äôll show you how easy it is to get started with these new products. We‚Äôll discuss strategies for taking advantage of the new form factors while navigating some or their limitations. We‚Äôll give you best practices for designing mobile-friendly dashboards, configuring alerts, and managing groups of devices. We‚Äôll also equip you with what you need to diagnose issues you may have when transitioning to our mobile products. We‚Äôll show you how to put the power of Splunk in your pocket (and on your TV).",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1749.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1749.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1752 - Augmented Reality- A Day in the Field with Splunk AR",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Mobile"],
    "Speakers": [
      "Devin Bhushan , Splunk AR, Eng Lead, Splunk",
      "Glen Wong , Senior Engineering Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Do you want to deliver the power of Splunk AR to your colleagues in the field? Splunk AR ties Splunk data to real-world objects, so users can easily consume the data where it lives. We‚Äôll go over several use cases of technicians in the field using Splunk AR to discover, diagnose, and resolve issues in various environments. You'll walk away equipped with the tools to construct these experiences from scratch and enable your organization to deploy Splunk AR.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1752.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1752.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1778 - The Cloud Gateway- A Security Deep-Dive and the Future Ahead",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Dylan Conway , Product Manager, Splunk",
      "Jesse Chor , Head of Mobile Engineering, Splunk",
      "Mike Emery , Sr. Principal Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "The Cloud Gateway is at the heart of many of Splunk‚Äôs most exciting products: Mobile, AR, NLP. It facilitates the communication from your iOS, Android, and AppleTV devices with an on-premise Splunk instance without having to set up a VPN or manage firewall rules. The connection is encrypted end to end, so even if Cloud Gateway was compromised your data would still be secure. In this session we‚Äôre going to share how Cloud Gateway provides these guarantees by doing a deep dive into the encryption used, the device authentication process, and the flow of a message from a mobile device to a Splunk instance and back again. Finally, we‚Äôre going to be talking about some exciting features rolling out to Cloud Gateway in the coming year.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1778.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1778.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1786 - Using Splunk Data Stream Processor for advanced stream management",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Data Fabric Search and Data Stream Processor",
    "Speakers": [
      "Dave Cornette , Enterprise Monitoring Architect, T-Mobile",
      "Michael Guenther , Senior Advisory Engineer, Splunk"
    ],
    "Industry": "Communications",
    "Description": "Learn how the T-Mobile Splunk Team uses Splunk Data Stream Processor (DSP) to provide advanced stream manipulation options to its user base. See how DSP is positioned in a large-scale Splunk as a service ecosystem.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1786.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1786.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1813 - Splunk & Intel Teams Deliver Faster Customers Insights Through Collaborative Engineering",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "FN1815 - The New Dashboarding & Content Export Experience in Splunk- A single experience across Enterprise, ITSI and more!",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Developer Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Miranda Luna , Product Management, Splunk",
      "Nachi Mistry , Sr. Engineering Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "So you saw the new Splunk Dashboards framework and PNG export on the main stage and want to know more? You want to understand what this will mean for your Enterprise, Cloud, ITSI, ES and/or IAI deployments? You've come to the right place. In this session, we'll provide an overview and extended demo of the new dashboarding framework and context export service. We'll cover what's different about this new framework in comparison to both SimpleXML and Glass Tables. We'll also cover the support roadmap for Simple XML and Glass Tables as well as what you need to know in order to migrate. If you're planning to attend any of the other dashboard deep dive sessions, we recommend attending this one first.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1815.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1815.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1886 - Best Practice of EMM deployment for Splunk Mobile",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Mobile",
    "Speakers": [
      "Roy Zhang , Principle QA, Splunk",
      "Strong Yuan , Senior Software Engineer in Test, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "This session is for customers who would like to extend their Splunk usage to mobile devices and understand how Enterprise Mobility Management (EMM) works. It also will benefit customers who have existing mobility management solutions, including mobile device management (MDM) and mobile application management (MAM) systems, and want to enroll the Splunk mobile apps. The session will include an introduction and live demos showing detailed integration with the most popular mobile device management (MDM) solutions: AirWatch, MobileIron, and Blackberry. We also will have live demos to illustrate how to configure different Splunk mobile apps with the enterprise mobility management (EMM) solutions from scratch. Topics to be discussed will include profile configuration, authorized devices, app wrapping, and MDM/MAM-specific features.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1886.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1886.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1916 - Splunk Machine learning and self healing at Priceline",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Mukund Murthy , Software Engineer, Priceline.com",
      "Pranav Nandedkar , software engineer, Priceline.com"
    ],
    "Industry": "Technology",
    "Description": "Do you want to rely on manual intervention to fix your application if something goes wrong? In this deep-dive session you will learn how Priceline uses machine learning to find outliers and anomalies in various data sets, including but not limited to bookings, search patterns, changes in logging patterns, etc. You will learn how we used machine learning combined with predictive analytics to solve variety of use cases. For example, we collect Kafka offset data, which is sending data to their respective syncs. We also monitor to see if the traffic is receded or data consumption has increased or decreased unexpectedly. We will show how different stages of application states are controlled with the use of data and alerts, like disabling the app and enabling it according to the data. We also will show you how Priceline deals with brownouts, the gradual degradation of volumes by using machine learning over long periods, using different self healing techniques and custom apps. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1916.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1916.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1921 - Saving the Nation‚Äôs Food Supply with Data-Driven Analytics",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": "Sandy Voellinger , Copper River Enterprise Services ",
    "Industry": ["Not industry specific", "Public Sector"],
    "Description": "Copper River ES, a strategic partner for Splunk public sector, is working with a large federal agency that has restructured their NOC and SOC organizations into a single unified entity as part of operational optimization. ¬†The agency is responsible for protecting IP and other assets totaling $4.3 trillion as part of safeguarding the nation‚Äôs food supply chain. ¬† The goal was to enhance the ability to handle problem escalations quickly and improve communications between teams. They are currently ingesting more than 3TB daily across 65 data sources where Splunk is leveraged as an integrated data platform and framework service to act as a nerve center for the combined NOC and SOC teams. Implementation has resulted in dramatically reducing MTTD to an average of less than 30 min compared to previous times of up to 12 hours, MTTR times from 16 hours to often less than 1 with overall outage times having now been reduced by about 68%. From a security perspective, it is used to identify data exfiltration and insider threats, as well as for security operations and compliance. ¬†Increasing visibility into all aspects of system operations and troubleshooting efforts is now supported through a series of custom Splunk App‚Äôs, glass tables, reports and alerts with operational guides and training to best leverage the capabilities Splunk has generated.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1921.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1921.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1922 - From 0 to 6 Terabytes Real Quick- Cox Automotive‚Äôs Fast and Furious Splunk Adoption",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Jason Spears , Lead Systems Engineer, Cox Automotive",
      "John Lim , Systems Engineer, Cox Automotive"
    ],
    "Industry": "Not industry specific",
    "Description": "How do you control a race car with unlimited horsepower and make sure it doesn‚Äôt go off the track? With over 25 unique business affiliates within our enterprise and hundreds of application, engineering, and business teams driving rapid adoption, Cox Automotive‚Äôs Splunk Cloud deployment is our very own race car. Come sit in the passenger seat as we recap our ride, which is filled with explosive data ingest rates, unpredictable search slowdowns, out of control data drifts, and rapidly increasing end user requirements. Let our experiences and in-house solutions help you navigate the potholes you will encounter when dealing with the seemingly unstoppable growth rate of an enterprise-level Splunk distributed deployment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1922.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1922.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1933 - Unleash your inner Picasso- experience the new Splunk dashboards",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Stephen  Luedtke , Sr. Data Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Seeking guidance to help create amazing Splunk dashboards? Want to wow your team as well as your execs and become THE dashboard master? Come learn about Splunk's new dashboarding capabilities, and experience rich dashboard examples as well as the art of the possible. We will demo a variety of dashboards, and we‚Äôll share tips and tricks, tutorials and templates to ensure you can build your own. Attend this session and you‚Äôll be on the path to becoming a Splunk dashboard ninja in no time.n n ¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1933.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1933.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1945 - Artificial Intelligence got you down- Here‚Äôs Machine Learning for Humans!",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Matt Portnoy , Senior Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Did you struggle with college statistics? Do the letters ‚ÄòAI‚Äô mean ‚ÄòAlways Intimidating‚Äô to you? Have you been putting off learning about the Machine Learning Toolkit because you aren‚Äôt a data scientist? Well don‚Äôt fret, because we aren‚Äôt data scientists either! We are, however, able to teach you how to crack the code on learning, leveraging, and operationalizing one of the most powerful components of the Splunk platform. Learn where, when, and how to use it, and the steps to make Splunk‚Äôs AI successful for you. We break it down into easy-to-understand segments, walk step-by-step through some use cases that you can take home with you, and arm you with the resources to successfully continue down the AI path. Don‚Äôt miss this opportunity and you won‚Äôt suffer any longer from machine learning envy! Data scientists need not apply. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1945.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "FN1987 - Using Splunk Data Stream Processor as a Streaming Engine for Apache Kafka",
    "SkillLevel": "Beginner",
    "Track": "Foundations/Platform",
    "Products": "Splunk Data Fabric Search and Data Stream Processor",
    "Speakers": [
      "Adam Lamar , Principal Software Engineer, Splunk",
      "Thor Taylor , Director of Product Management, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Do you use Kafka but find yourself limited by what Kafka allows you to do with your data? Would you like to enrich, aggregate, and alert on your data as it moves through Kafka, but can‚Äôt figure out how? You can overcome these obstacles by integrating Kafka with the Splunk Data Stream Processor. The Splunk DSP is a data streaming platform that helps you transform and enrich your data. With DSP you can make data-driven decisions in real time as data is ingested. DSP also provides simple ways to build data pipelines, and gives you full control and visibility into your data as it flows through the platform. Apache Kafka is now widely adopted as a foundational element for data pipelines. DSP integrates seamlessly with Kafka clusters, and allows data to be read from Kafka, processed in highly scalable ways, and then written back to Kafka. Join us and see how to use DSP as a streaming engine for Kafka clusters.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1987.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1987.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN1995 - Splunk Cloud- optimizing performance, value and user experience",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Michael Anderson , Senior Software Engineer, Liberty IT",
      "Ray Mateo , Solutions Engineer, Liberty Mutual"
    ],
    "Industry": "Technology",
    "Description": "This session will cover how to overcome any missing insights in services and processes in Splunk Cloud. You'll learn how to develop alerts and dashboards to show performance and infrastructure health, and an API framework to retrieve data from the cloud infrastructure. We also will show you how to automate retrieval of all entry points to the Splunk on-premises infrastructure, and monitor connections to the intermediate forwarders, deployment servers, HEC and DBX servers, and syslog. In addition, we will address the lack of standardization principles for your on-premises Splunk Infrastructure, how to create gold standard alerts and dashboards, and how to create scripted inputs to gather system information. Finally, we will show you how to address the lack of a centralized view for managing your Splunk deployment server infrastructure, and how to automate the retrieval of deployment clients, server classes, and TA‚Äôs from deployment servers and feed the output to Splunk Cloud.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1995.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN1995.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2030 - Data Fabric Search- Opening doors to unprecedented levels of scale and performance",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Ryan Delanoy , Senior Performance Engineer, Splunk",
      "Yujia Wang , Principal Performance Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Data Fabric Search (DFS) is one of Splunk's newest technologies built to handle the ever increasing rate of growth in data. Combining the rich functionality of Splunk with the parallel execution of Spark, DFS enables searching data at scales previously unheard of. This session will be decidedly for a technical audience as we deep-dive into DFS architecture and demonstrate the capabilities DFS offers to execute searches that scan more than one trillion events at a time. We will also share our experience as performance engineers with tips and tricks on how to tune Splunk deployments to take full advantage of this exciting new feature. Having additional capability to search at massive scale opens doors to use cases that no longer need to make the trade-off between depth of analysis and timeliness of results. Come learn more about Data Fabric Search and see real-world examples of its power put to use. The impossible is possible.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2030.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2030.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2033 - Using Splunk Data Stream Processor as a Data Transformation, Alerting and Action Engine",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Bashar Abdul-Jawad , Principal Software Engineer, Splunk",
      "Dirk Nitschke , Staff Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Do you wish to modify your incoming data before ingestion? How about using Splunk's real-time search feature more efficiently? Splunk Data Stream Processor (DSP) can help. DSP allows you to analyze, transform and act on your data in real-time before it is indexed by Splunk indexers.n n Join us in this session to learn more about how you can use DSP as an alerting and action engine and transform your incoming data in real-time!n n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2033.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2033.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2041 - How Splunk Uses Product Telemetry Data to Improve our Products and Services",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Archana Ganapathi , Director Data Strategy, Splunk",
      "Bharath Aleti , Director, Product Management, Splunk",
      "David Alward , Sr. Monitoring Manager, Splunk",
      "Kevin Louther , Data Analyst, Product Analytics, Splunk",
      "Miranda Luna , Product Management, Splunk",
      "Tracy Knight , Director Performance Engineering, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "At Splunk, we listen to our data for insights on how to improve our products and provide better services for our customers. We collect aggregated product usage, configuration and performance data from customers who share this information, and use it for benchmarking product performance and building more realistic test environments, developing sizing calculators and best practice configuration guidelines, prioritizing what products and features to develop on various platforms, improving user experience and workflows, and more proactively support our customers. Come hear from a panel of Splunkers about how they have been able to deliver valuable outcomes using telemetry data.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2041.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2041.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2048 - Splunk Multi-Deployment Server Architecture",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Joe Cramasta , Senior Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "This session is a technical capacity presentation on how to run Splunk Deployment Server (DS) as a multi-distributed layer of nodes integrated with a version controlled repository and automation techniques for keeping DS nodes in sync across changes.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2048.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2048.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2062 - Data Stream Processor- How to get the most out of your data!‚Äã",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Data Fabric Search and Data Stream Processor",
    "Speakers": [
      "Blaine  Wastell , Product Management Director, Splunk",
      "Thor Taylor , Director of Product Management, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Have you ever been asked to create a resilient petabyte scale data collection and distribution architecture? Do you need to transform data before it is indexed to remove unnecessary or sensitive data or even enrich the data with a lookup before writing the data to your index? Do you need to detect specific patterns to identify the event line break, event timestamp, or assign the appropriate sourcetype? Do you need to control where to send the data including the specific Splunk Index(es) or even a non-Splunk Sink?If so, we will show you how Splunk‚Äôs Data Stream Processor (DSP) can be used to address these requirements to meet both current and future demands. We will walk through the scenarios that customers are dealing with today for these requirements. Finally we will talk about how Universal Forwarder, Heavy Weight Forwarder, and HTTP Event Collector fit into this new data ingestion architecture.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2062.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2062.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2067 - Architecting Splunk for High Availability and Disaster Recovery",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Justin Hardeman , Platform Architect - Sales Engineering, Splunk",
      "Sean Delaney , Principal Architect, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "As Splunk Enterprise becomes more critical to organizations and business functions, it becomes crucial to maximize the uptime of the service. We'll talk about general principles of resiliency/high availability and disaster recovery, and how they apply to a Splunk deployment. We'll also discuss the various mechanisms for implementing them, levels of availability, relative advantages, and the costs of each.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2067.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2067.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2069 - Maximizing permissioned blockchain throughput using Samsung SDS Accelerator and Splunk MLTK",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["AI/ML", "Splunk Enterprise"],
    "Speakers": [
      "Jeff Wu , Senior Product Manager, Blockchain, Splunk",
      "Ted Kim , Samsung SDS"
    ],
    "Industry": "Not industry specific",
    "Description": "Blockchain scalability is one of the main barriers to adoption of this revolutionary new technology. Finance, supply chain, and e-commerce blockchain deployments often have peak throughputs that far exceed their baseline. For example, when tickets for a popular concert go on sale, the peak transaction throughput will result in unacceptable latency for the users. Samsung SDS Accelerator is a layer 2 scaling solution for Hyperledger Fabric that enables up to 10x transaction throughput during this burst of activity. Using Splunk MLTK, we‚Äôre able to detect and react to these bursts of activity without compromising the security guarantees of the underlying blockchain. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2069.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2069.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2084 - Artificial Intelligence- How Will It Rock Your World-  ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["AI/ML", "Splunk Enterprise"],
    "Speakers": [
      "Aaron Cooper , Vice President, Global Policy, BSA | The Software Alliance",
      "Adam Cohn , Vice President, Worldwide Government Affairs, Splunk, (moderator)",
      "Dimitri Kusnezov , Deputy Under Secretary for Artificial Intelligence, U.S. Department of Energy",
      "Jinsook Han , Digital & Strategy Lead for Applied Intelligence, Accenture"
    ],
    "Industry": ["Non-Profit", "Not industry specific"],
    "Description": "With the rapid evolution and adoption of artificial intelligence and machine learning underway, what do you need to know about the upsides and the risks?¬† How is the hype and reality of AI going to change your world over the next five years?¬† How will government policies and standards affect your work in implementing the technology?¬† A panel of thought leaders will share their perspectives on these key questions.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2084.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2084.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2087 - Health Insights in One-click with New Splunk Monitoring Tools",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Enterprise", "Splunk Machine Learning Toolkit"],
    "Speakers": [
      "Amrit Bath , Sr Manager, Engineering, Splunk",
      "Shruti Anand , Product Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Wouldn‚Äôt it be great if you can just be proactively told when your Splunk deployment needs your attention? Wouldn‚Äôt it be simply awesome to go to one place and know exactly what the problem is and how to resolve it? At Splunk we understand that every organization suffers the pain of throwing resources to keep the lights on for their infrastructure environment. Fortunately the new version of Splunk Monitoring helps you know when things are not performing as expected. You can now see health of deployment wide without affecting your search or indexing latency and go through guided set of checks¬†curated from years of support experience to solve issues first hand.n n ¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2087.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2087.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2103 - Exploratory Data Analysis on Aviation Safety Data",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "AI/ML",
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Cory Syvenky , Sr. Cloud Analyst, WestJet",
    "Industry": ["Aerospace & Defense", "Non-Profit"],
    "Description": "It‚Äôs a bird, it‚Äôs a plane. Yes, it‚Äôs a plane! Let‚Äôs go for a flight into the skies of aviation data and the concepts and tools that make aviation data analytics easy. I‚Äôve been capturing this open data for nearly two years, and I‚Äôve been able to unravel some insights based on four projects. Two projects focus on processing Canadian/U.S. safety reports, while the other two are processing data captured and logged from a radio receiver made from a Raspberry Pi. Data Science is offering very exciting careers and providing an important competitive differentiator, which is why we‚Äôll be reviewing several statistical processing techniques made possible by the power of the Machine Learning Toolkit. We also will cover exploratory data analysis tools built into the Search Processing Language. Before we approach for landing, we‚Äôll show everything under the hood so that everybody can understand the things that make it fly. This is both a technical deep dive as-well-as a practical usage walkthrough.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2103.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2103.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2124 - Data Fabric Search(DFS) - Under the Hood",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Ari Bhattacharjee , Distinguished Engineer, Splunk",
      "Sourav Pal , Senior Principal Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Data Fabric Search (DFS) is the next generation of Splunk‚Äôs search platform. DFS executes the following vision: Splunk should be able to leverage compute assets from anywhere and access and execute on data regardless of type and origin. Inspired by the above mantra DFS scales Splunk searches both in terms of volume and cardinality. In this session you will learn how DFS searches scale to trillion scale event volume or billion scale cardinality - capabilities previously impossible. DFS is not limited to local but by supporting scaled federated executions also powers remote splunk deployments. The Search Pipeline of DFS has been build grounds up based on lambda architecture which provides massive scale, high throughput and performance gains. At the end some of the performance and scale numbers which has been achieved internally will be shared.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2124.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2124.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2132 - Operating & Securing Hybrid Environments with Google Cloud & Splunk",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Alex Cain , Sr. Product Manager | Getting Data In, Splunk",
      "Nic Stone , Solutions Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "In this session, we‚Äôll explore how companies can adapt to multi-cloud environments using Google Cloud Anthos and Splunk Enterprise to maintain end-to-end visibility into these hybrid workloads. Google Kubernetes Engine (GKE) On-Prem part of Anthos brings the efficiency, speed, and scale of cloud to manage Kubernetes clusters in your datacenter. Combined with Splunk Connect for Kubernetes, we‚Äôll show you how you get a single pane of glass to manage, monitor & secure your Kubernetes clusters across your organization.¬†  We‚Äôll also do a deep dive on Google Cloud Platform (GCP) security controls and how to export security findings from Cloud Security Command Center and cloud asset changes from Cloud Asset Inventory all into Splunk Enterprise for further forensic analysis, to accelerate incident resolution and ensure compliance. In this session, we‚Äôll explore how companies can adapt to multi-cloud environments using Google Cloud Anthos and Splunk Enterprise to maintain end-to-end visibility into these hybrid workloads. Google Kubernetes Engine (GKE) On-Prem part of Anthos brings the efficiency, speed, and scale of cloud to manage Kubernetes clusters in your datacenter. Combined with Splunk Connect for Kubernetes, we‚Äôll show you how you get a single pane of glass to manage, monitor & secure your Kubernetes clusters across your organization.¬†In this session, we‚Äôll explore how companies can adapt to multi-cloud environments using Google Cloud Anthos and Splunk Enterprise to maintain end-to-end visibility into these hybrid workloads. Google Kubernetes Engine (GKE) On-Prem part of Anthos brings the efficiency, speed, and scale of cloud to manage Kubernetes clusters in your datacenter. Combined with Splunk Connect for Kubernetes, we‚Äôll show you how you get a single pane of glass to manage, monitor & secure your Kubernetes clusters across your organization.¬†In this session, we‚Äôll explore how companies can adapt to multi-cloud environments using Google Cloud Anthos and Splunk Enterprise to maintain end-to-end visibility into these hybrid workloads. Google Kubernetes Engine (GKE) On-Prem part of Anthos brings the efficiency, speed, and scale of cloud to manage Kubernetes clusters in your datacenter. Combined with Splunk Connect for Kubernetes, we‚Äôll show you how you get a single pane of glass to manage, monitor & secure your Kubernetes clusters across your organization.¬†In this session, we‚Äôll explore how companies can adapt to multi-cloud environments using Google Cloud Anthos and Splunk Enterprise to maintain end-to-end visibility into these hybrid workloads. Google Kubernetes Engine (GKE) On-Prem part of Anthos brings the efficiency, speed, and scale of cloud to manage Kubernetes clusters in your datacenter. Combined with Splunk Connect for Kubernetes, we‚Äôll show you how you get a single pane of glass to manage, monitor & secure your Kubernetes clusters across your organization.¬†We‚Äôll also do a deep dive on Google Cloud Platform (GCP) security controls and how to export security findings from Cloud Security Command Center and cloud asset changes from Cloud Asset Inventory all into Splunk Enterprise for further forensic analysis, to accelerate incident resolution and ensure compliance.We‚Äôll also do a deep dive on Google Cloud Platform (GCP) security controls and how to export security findings from Cloud Security Command Center and cloud asset changes from Cloud Asset Inventory all into Splunk Enterprise for further forensic analysis, to accelerate incident resolution and ensure compliance.We‚Äôll also do a deep dive on Google Cloud Platform (GCP) security controls and how to export security findings from Cloud Security Command Center and cloud asset changes from Cloud Asset Inventory all into Splunk Enterprise for further forensic analysis, to accelerate incident resolution and ensure compliance.We‚Äôll also do a deep dive on Google Cloud Platform (GCP) security controls and how to export security findings from Cloud Security Command Center and cloud asset changes from Cloud Asset Inventory all into Splunk Enterprise for further forensic analysis, to accelerate incident resolution and ensure compliance.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2132.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2132.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2143 - How to effectively run high cardinality and federated searches using Data Fabric Search. ",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Data Fabric Search and Data Stream Processor",
    "Speakers": [
      "Asha Andrade , Principal Software Engineer, Data Fabric Search, Splunk",
      "Nikhil Roy , Principal Software Engineer, Splunk"
    ],
    "Industry": "Technology",
    "Description": "How would you go about exploring your data assets using Splunk‚Äôs newly available Data Fabric Search? What should you expect when you adopt Data Fabric Search for your Splunk deployments? We will show you how to go about enriching your Splunk searches and navigating through the different search phases to effectively utilize your resources.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2143.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2143.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2156 - Can‚Äôt we just have a bot run our deployments- Yes, yes we can.",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Mitchell Peters , Sr Architecture Analyst, Optum",
      "Shelbie  Wise , Architecture Analyst, Optum "
    ],
    "Industry": "Healthcare",
    "Description": "Can‚Äôt we just have a bot run our deployments? Yes we can. Here at Optum, our Splunk team has developed a hands-off method for deploying the Splunk Universal Forwarder on thousands of hosts in just minutes. With our automation we have been able to take advantage of bot integration via ChatOps to take care of our business needs, all while keeping our executives happy. Oh, and the backend configs? Yeah, we have tips on those too.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2156.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2156.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2168 - Smart Store Deep Dive ",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Bill Ern , Splunk Product Owner, Lockheed Martin",
      "Da Xu , Senior Engineering Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Dive into the inner workings of SmartStore. In this talk we'll go over how SmartStore works internally with ties to Indexer Clustering, and what decisions the CacheManager makes, e.g., when do we upload/download from the remote storage, etc. We'll also go over the performance numbers that we've seen!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2168.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2168.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2188 - Speed up your search! ",
    "SkillLevel": "Beginner",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Satoshi Kawasaki , Splunk for Good Ninja, Splunk",
    "Industry": ["Non-Profit", "Not industry specific"],
    "Description": "'I'm completely satisfied with my search speed and there is nothing to improve' said no one, ever. The majority of internet users expect websites to load within two seconds. Why should Splunk dashboards and the underlying searches be any different? No one should be satisfied by searches that take minutes to complete. In this talk, we'll cover all the different strategies to take slow searches and speed them up. This is an updated talk from .conf2017.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2188.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2188.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2192 - Get those spreadsheets into Splunk!",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Ryan O'Connor , Senior Advisory Engineer, Splunk",
      "Satoshi Kawasaki , Splunk for Good Ninja, Splunk"
    ],
    "Industry": ["Non-Profit", "Not industry specific"],
    "Description": "Unfortunately not everyone is living the data dream of using connected toaster to send webhooks to Splunk in nicely formatted JSON. Believe it or not, there are still organizations, especially nonprofits, using spreadsheets to manually record their important data. Spreadsheets aren't going to disappear overnight, so Splunk shouldn't ignore the value of spreadsheet data. Learn good practices on how to store and index spreadsheets to Splunk using the Google Drive app.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2192.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2192.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2195 - Building scalable AWS based Splunk Architectures using Cloud Formation in 30 minutes or less",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Arthur  Spencer , Sr. Professional Services Security Consultant, Splunk",
      "Neha Doshi , Splunk Practice Lead - Splunk Sr. Professional Security Consultant, Perficient"
    ],
    "Industry": "Not industry specific",
    "Description": "Using AWS cloud formation we will demonstrate creation of a full blown Splunk Enterprise system in 30 minutes or less. While the system is spinning up, we will discuss the decision points and process that was taken while creating a best-of-breed, AWS-based Splunk deployment. You will be introduced to the core AWS Components (EC2, Storage, VPC, security), Splunk Enterprise Architecture (multi-site clustered index and multi-site search head cluster), Base and CLI Configurations, Cloud Formation Automation, GIT Configuration management, and best practices surrounding those technologies.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2195.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2195.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2241 - In Transition- Helping Veterans Navigate the Transition to Technology Careers",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Adam Renfree , With You With Me",
      "Bertina Ceccarelli , Npower",
      "Bryan Rollins , Warriors to Work Director, Wounded Warrior Project",
      "Corey Marshall , Director, Splunk"
    ],
    "Industry": ["Non-Profit", "Not industry specific"],
    "Description": "More than 200,000 military service members return to civilian life each year in the United States alone, with many thousands more around the globe. Many are looking to build on their experiences, leveraging the technical training and skills acquired while working in the service to their country. Thousands more are looking to change direction. Both paths can lead to the Splunk community, where we have provided access to free training for thousands of veterans through our customers, partners, and more. Join us for a discussion with some of our leading partners, including the Wounded Warrior Project, WithYouWithMe Academy, and Npower, about how veterans can navigate the transition to technology careers with help from a growing network of partners, and how Splunk can provide new and exciting career opportunities.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2241.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2241.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2268 - Metric Index- Evolution & Internals ",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Murugan Kandaswamy , Senior software engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Splunk‚Äôs metric index has changed a lot since we launched it back in Splunk Enterprise 7.0. In this latest iteration, we have upgraded our data model and metric index to natively ingest and store multiple metrics in a single event to further reduce its storage footprint and lower total cost of ownership. This session with provide a deep-dive into our latest metric index layout, its evolution since introduction in Splunk Enterprise 7.0, and how it varies from a log index storage layout.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2268.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2268.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2276 - Data Fabric Search Use Cases- Real World Applications",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Balaji Rao , Principal Engineer , Splunk",
      "Becky Burwell , Senior Production Engineer, Verizon Media",
      "Srini Bobba , Principal Product Manager, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "See Data Fabric Search (DFS) in action! We will walk through real-world customer stories and demonstrate how DFS was used to make effective business decisions. With DFS, organizations can quickly weave together insights across the enterprise to get a deeper and more comprehensive view of customer behavior, organizational threats, or business opportunities. Data Fabric Search excels in speed and scale with use cases primarily falling into two categories: 1) High performance and high cardinality searches processing large volumes of data, and 2) Queries that run operations across multiple deployments. For each customer story, we will demonstrate how DFS is able to run these queries successfully and show how they created powerful business results.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2276.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2276.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2285 - Splunking refugees with help from NetHope and Cisco",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Corey Marshall , Director, Splunk",
      "Satoshi Kawasaki , Splunk for Good Ninja, Splunk"
    ],
    "Industry": "Non-Profit",
    "Description": "It¬†may not the big news, but there are 25 million refugees right now according to the UN Refugee Agency. Cisco Meraki has generously donated network equipment for NetHope to provide internet connectivity to refugee camps. Learn how NetHope sends various data to Splunk to add visibility to the camp's network infrastructure and take traditional IT data for non-traditional analytics on refugees.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2285.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2285.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2514 - Fast and scalable replication of knowledge bundles in Splunk Enterprise",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Aditya D Dhoke , Sr. Software Engineer, Splunk",
      "Anish  Shrigondekar , Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "This session will highlight a new strategy for fast and effective replication of knowledge bundles, resulting in up-to-date search results and a significant reduction in WAN bandwidth usage. Knowledge bundles include the knowledge objects that a search-head distributes to search peers so that they can process a distributed search. Replication of these bundles to search peers can be slow for large deployments and also consumes significant WAN bandwidth, especially in multi-site deployments. This new replication option in Splunk Enterprise accelerates search access to recent data and reduces WAN bandwidth consumption.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2514.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2514.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2515 - How the world largest sovereign wealth fund moved to SPLUNK CLOUD‚Äã",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Enterprise Security"
    ],
    "Industry": "Financial Services",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2515.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2515.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2516 - -What's New in the latest release of Splunk Cloud and Splunk Enterprise-",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Skip Bacon , VP, Enterprise Products, Splunk",
      "Sundeep Gupta , Director, Splunk Cloud, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "This session will detail new innovations and features included in the .conf19 release of Splunk Cloud and Splunk Enterprise. This is one of the most well-attended .conf19 sessions. Be sure to add it to your agenda.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2516.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2516.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FN2519 - Announcing Splunk Investigate",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Cloud",
    "Speakers": [
      "Dan Streit , Principal Software Engineer, Splunk",
      "Hema Mohan , Director, Product Management, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Learn about our latest SaaS offering, Splunk Investigate. This session will provide an overview of the new features of this cloud application and how you can quickly get started investigating all your machine data. Now teams have a way to easily collaborate on investigations and resolve incidents faster than before.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2519.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FN2519.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNC1549 - Administrators Anonymous- Splunk Best Practices and Useful Tricks I Learned the Hard Way",
    "SkillLevel": "Intermediate",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Enterprise Security"
    ],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNC1549.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/FNC1549.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNC2051 - I Deleted a Critical Knowledge Object‚Ä¶. Now What-",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Steve McMaster , Hurricane Labs",
    "Industry": "Not industry specific",
    "Description": "For many organizations, Splunk is considered critical infrastructure. But Splunk itself does not provide any full backup solutions. Several first and third-party options exist, each with their own positives and negatives. Join us as we talk about what options exist today, why they didn‚Äôt work for us, and what we‚Äôve built to solve this problem - right from Splunk - using the open source tool Duplicity. Users of all OS‚Äôs welcome, but the app is currently only supported for Linux.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNC2051.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNC2051.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNC2259 - 5 Tips to Faster Support Case Resolution",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "cp-regex-guru Petterborg , Splunk Architect, Stage 2 Security",
    "Industry": "Not industry specific",
    "Description": "The sooner a support engineer understands your case and has sufficient information, the sooner your case will be resolved. Splunk Support engineers are vey good at what they do, but they can't read minds, and they can't see into your computers. How can you make them understand your issue better and faster? What steps can you take ahead of submitting a support case that will ensure that you understand your issue as well? Attendees will receive some important tips resulting in a faster TTR.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNC2259.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNC2259.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNC2750 - Digging Deep into Disk Diagnoses",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNC2750.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/FNC2750.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNC2751 - Master Joining Your Datasets Without Using Join",
    "SkillLevel": "Advanced",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Nick Mealy , CEO/Chief Mad Scientist, Sideview, LLC",
    "Industry": "Not industry specific",
    "Description": "As you become more comfortable with Splunk, you can build complex searches that draw knowledge from very different sources to create reports that other products just cannot do. However your first instincts here will take you to the 'join' and 'transaction' commands. These commands will give you less-than-great performance as well as some confusing problems to work around. Come to this talk to learn how to avoid these commands *almost* entirely. We'll walk through search language examples starting with simple ones, where you would first start playing with 'join', and work our way up. In each case we'll cover why you would gravitate to join/transaction and what the problems are. Then what the techniques¬†and the search syntax looks like to write a better faster report, and push most of the work out to the indexers. Not only will your searches run faster and your users be happier, but your administrators will be happy too with the lower system resources used!n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNC2751.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "FND1268 - She's the Boss- Female Leaders Smashing The Glass Ceiling ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Enterprise Security"
    ],
    "Speakers": [
      "Carol Jones , CIO, Sandia National Laboratories",
      "Jane Hite-Syed , NGS CIO, National Government Services",
      "Monika Panpaliya , Senior Director, Digital Common Services, Boeing",
      "Patty Morrison , Splunk Board Member, Splunk",
      "Suzanne McGovern , Chief Diversity Officer & Head of Talent, Splunk"
    ],
    "Industry": "Diversity & Inclusion",
    "Description": "Women are underrepresented across all levels of the technology industry. Find out how these four female leaders advanced their careers to lead the industry. Join us for an in-depth discussion about female diversity and the importance of including women in leadership from those who've made it to the top.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1268.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1268.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1364 - Harnessing the Next Generation of Tech Talent",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Business Flow",
    "Speakers": "Neil Gow , SE Director, Splunk",
    "Industry": ["Diversity & Inclusion", "Non-Profit"],
    "Description": "Generation Z is our largest generation ever. They are over 2 billion strong and are predicted to make up nearly 30% of the workforce by 2025. Fifty percent of them are likely to have a university degree that will carry them through 17 jobs, spanning five different careers in their lifetime. So how can we harness the energy of this huge pool of 'think differently,' 'act differently' resources? With an internship program. Learn how the Splunk ANZ team focused on addressing the staffing challenges many tech companies face, particularly with regard to promoting diversity and including underrepresented groups, such as female students studying STEM subjects. This session will review how they built an internship program that not only delivered huge value to the business, including Gen Z diversity, but also focused on transferring technical and soft skills to facilitate their transition into full-time employment.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1364.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1364.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1466 - Mind the gap!  The what, why and how of data bias, why you should avoid it and how you can save money or lives if you do.",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "Dipock Das , Senior Director, Product Management, Incubation, Splunk",
    "Industry": ["Diversity & Inclusion", "Not industry specific"],
    "Description": "Why is the queue for the women‚Äôs restroom always longer than the men‚Äôs at a concert or theater? Data is fundamental to the modern world. From business decisions to economic development and public policy, we rely on data to allocate resources and make critical decisions. However, because so much of the data fails to take into account bias, such as gender and race, bias and discrimination are baked into our systems. This results in missed economic opportunities and tremendous costs in time, in money and, in some cases, lives. In this session we will explore examples of data bias based on studies that are eye-opening, informative, and will change the way you look at the world. We will look at the pitfalls that lead to poor data-driven decisions, and their outcomes. We also will explore the steps you can take to inform your own data driven decisions. And, yes, we will answer the question, 'Why is the women‚Äôs queue is longer than the men‚Äôs?'",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1466.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1466.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1502 - Helping Women in Technology to Boost Their Careers by Getting Public Recognition for Intellectual Property that They Create",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise Security",
    "Speakers": "Rimma Budnitskaya , Director, Legal (IP), Splunk",
    "Industry": ["Diversity & Inclusion", "Not industry specific"],
    "Description": "This session will illuminate the world of Intellectual Property (IP) so that women are more empowered to gain recognition. The underrepresentation of women in STEM has meant that, historically, men have had a reputational advantage, but women can gain ground. IP rights provide an avenue for increased acknowledgement, both inside and outside the company. This session will cover the issues of ownership as well as the different types of IP, and which IP may be most valuable to the company. It also will explain the role of an IP group in a company, and how women can take advantage of their efforts to see their contributions being acknowledged. It also will discuss the business pressures at play, with different company groups and products vying for limited resources. The goal of this session is to give women the information and tools they need to take advantage of opportunities, gaining the much-deserved recognition they deserve, and boosting their professional career in technology!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1502.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1502.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1745 - Life in the 3%- A Conversation on Claiming Your Space In the Workplace",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Alyssa Niles , Product Marketing Manager, Splunk",
      "Christopher Russell , Product Marketing Manager, Splunk",
      "Kara Gillis , Director of Product Management, Splunk",
      "Keegan Dubbs , Senior Product Manager, Splunk",
      "Marvin Green , Principal Product Manager, Mobile, Splunk",
      "Vidhi  Agrawal , Principal Product Manager, Core products portfolio, Splunk"
    ],
    "Industry": ["Diversity & Inclusion", "Not industry specific"],
    "Description": "'There‚Äôs always a tension between one‚Äôs individual self‚Äîone‚Äôs million data points‚Äîand the statistical breakdown of your existence. It‚Äôs the awareness of this tension that I navigate each day.' I wrote this in response to the reveal that black employee representation across Splunk‚Äôs U.S. offices was only 3%. #RepresentationMatters and having a 'seat at the table' are critical frameworks and tactics to improve diversity, and this panel discussion brings together a diverse cross-section of Splunkers to further explore these topics. Specifically, panel participants will use there statistical data points (e.g., 3%) as a foil to reflect on how they‚Äôve leveraged their individual motivations to push for and create change within their particular role. We intend for the audience to leave stirred by the ideas this conversation will open up, and moved to ask themselves what they can do to create change or elevate others who‚Äôve been underrepresented in their workplace.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1745.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1745.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1829 - Panel Discussion - Perspectives and Practical Skills for Men as Advocates for Gender Equity",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Developer Cloud",
    "Speakers": [
      "Ammar Maraqa , SVP Strategy and Corp Dev, Splunk",
      "Asmita Puri , Sr. Software Engineer, Splunk",
      "Josh Klahr , VP of Product Management, Splunk",
      "Katrina Reid , VP Technical Program Management, Splunk",
      "Marvin Green , Principal Product Manager, Mobile, Splunk",
      "Robin Barre , Senior Director of Engineering, Splunk"
    ],
    "Industry": "Diversity & Inclusion",
    "Description": "Do you want to be an ally but don't know where or how to start? Diversity and inclusion in technology workplaces is not a women‚Äôs issue, or an issue relevant only to other underrepresented groups. Diversity and inclusion are business issues, and they are human issues. We know that businesses profit from the many benefits that diverse perspectives bring to innovation and company competitiveness. In this panel discussion, we aim to facilitate a conversation to better understand the barriers to advocacy, to promote best-practices for effective advocacy, and to enable sharing of first-hand experiences of successful advocacy.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1829.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1829.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1956 - Empathy- The Forgotten Data Point",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Chantalle Palomo , Project Manager - Industries & Specialization, Splunk",
      "Pablo Guillen , Sales Engineer, Splunk "
    ],
    "Industry": "Diversity & Inclusion",
    "Description": "For those of us who work in the technology sector and adjacent disciplines, our technical skills are largely seen as our most valuable; the programming languages we know, what we‚Äôve accomplished with those languages and so on. While our technical skills are usually our ticket in, they have little or no impact on how happy we are at work. For example, the correlation between your proficiency in Splunk and your commitment to your team is negligible. As life at work evolves, we see the rising need for an alternative data point: empathy. With the help of sentiment analysis, our talk will highlight how the presence or absence of empathy impacts our working lives. And, better yet, how we can change the course of a team, project, and our own perception by leveraging empathy in a conscious way.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1956.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1956.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1981 - Building a Kickass LGBTQ+ Employee Resource Group",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Allie Engle , Manager, Cloud Business Process & Delivery, Splunk",
      "Kristina Blehm , Sr. Administrative Assistant, Splunk"
    ],
    "Industry": "Diversity & Inclusion",
    "Description": "Do you want to promote productivity and camaraderie at the same time? Do you want to spearhead events that are about community and inclusion? If so, join us as we talk about what it takes to create an Employee Resource Group (ERG) that celebrates diversity. In this session, we‚Äôll share the grassroots origins of Pride@Splunk, focusing on the transition from an unofficial club to an established ERG. More importantly, we‚Äôll draw on our experience to provide tips for starting your own ERG in any sized company. Come learn how to lead an ERG that supports diversity, advocacy, and inclusion.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND1981.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1981.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND1986 - Splunk Accessibility -  Splunking made accessible for users with disabilities",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Kumar Varun , Sr. Product Manager, Splunk",
      "Sean Kugler , Accessibility Analyst, Northern Arizona University"
    ],
    "Industry": ["Diversity & Inclusion", "Non-Profit", "Public Sector"],
    "Description": "Have you ever wondered how people with disabilities use Splunk ? Ever wondered what it would be like to perform searches in Splunk using a screen reader or a speech recognition application ? Then come to this session to learn about the enhancements made to the Splunk platform that makes it easy to use with assistive technology tools. We will delve into the experience of performing investigation in Splunk using a screen reader and discuss the enhancements made to the platform to make this a superior experience. You will learn about the work we are doing at Splunk to address compliance to the WCAG, Section 508, and EN 301 549 accessibility standards. Finally you will hear how our customers are using Splunk with assistive technology tools to accomplish their day-to-day work.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN1986.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND1986.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND2072 - Enhancing Diversity in Tech through Employee Resource Groups - Our BEAMs Journey",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Antoinette Raines Raines , LMS/CMS Administrator, Splunk",
      "Marvin Green , Principal Product Manager, Mobile, Splunk"
    ],
    "Industry": "Diversity & Inclusion",
    "Description": "Splunk‚Äôs support and promotion of diversity and inclusion led to the establishment of their most recent Employee Resource Group (ERG) for black employees called BEAMS. Black Employees and Mentors, BEAMS, officially launched February 2019, and has provided a platform for underrepresented employees to make an impact within the Splunk community and beyond. Join members of BEAMS for this discussion about changing the narrative for Black employees in the tech industry, and learn how you can thoughtfully provoke the same within your organization. Come learn from the experiences of BEAMS and their open and bold mindset, how BEAMS navigates challenges associated with creating change, promoting equality within a large organization, and going beyond the office walls, and how they support partnerships with youth education organizations. Be prepared to leave with thoughtful anecdotes and an action item list for your organization.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND2072.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND2072.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND2209 - Going Beyond Inclusion in the Workplace",
    "SkillLevel": "Beginner",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Davin Searls , Community & Corporate Partnership Manager, Communication Service for the Deaf, Inc.",
      "Jarlath Bloom , Technical Support Account Manager, Splunk "
    ],
    "Industry": "Diversity & Inclusion",
    "Description": "Technology has enveloped our lives - Smart TVs at home, FortNite on your morning commute, to communication with our colleagues‚Ä¶ even when they‚Äôre the next cubicle over. Before the Internet, people who are blind had to rely on others to read the news to them, unless they were fortunate enough to have access to a braille copy. Today, a staggering amount of information is at their fingertips, thanks to the Internet and screen readers. People with limited mobility can now work home if they choose to. One disability group still faces significant challenges. Over 70% of Deaf sign language users are under- or un-employed.¬†n n Many people have implicit bias assuming that communication with Deaf and Hard of Hearing employees is difficult, costly, challenging.n n In this presentation, Davin and Jarlath discuss how offices can not only become accessible, but go beyond creating a culture of inclusion, awareness and equity.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND2209.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND2209.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FND2245 - Retaining Talent and Striking a Work-Life Balance via Job-Sharing",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Katy Mann , Director, National Security Programs, Splunk",
      "Pamela  Sotnick , Program Manager, Splunk"
    ],
    "Industry": "Diversity & Inclusion",
    "Description": "Who says you can‚Äôt have it all? In today‚Äôs workplace, where the competition for talent is fierce, offering a true work/life balance is the key to keeping the best and the brightest as part of your organization. Based on more than 15 years of experiences across Fortune 500 companies and startups in the technology industry, Pam Sotnick and Katy Mann have been trailblazers in job-sharing and have shown how it works; not just for employees but also for organizations. Striking the right balance helps to retain talented women or men who need to reduce the number of hours devoted to their work life due to family responsibilities or other considerations. Job-sharing also can help to retain skilled workers who might otherwise choose to retire early or move to another organization. Come learn how job-sharing can work for your organization or how to make it work for you as an individual.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FND2245.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FND2245.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2529 - Building a Splunk SmartStore data platform with FlashBlade for high-volume datasets",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Vaughn Stewart , Pure Storage",
    "Industry": "Not industry specific",
    "Description": "Splunk‚Äôs new, cloud native architecture SmartStore simplifies Indexer maintenance by 10X by disaggregating compute from storage. Learn how SmartStore with Pure Storage FlashBlade delivers dynamic scaling, storage efficiency and high performance to accelerate operational intelligence and security management. This session will cover new capabilities enabled by SmartStore, performance considerations and deployment best practices.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2529.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2529.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2584 - Handling Expanding Data Sources & Datacenter Migration While Strengthening the Nutanix Security Posture with Splunk and HCI",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": ["Phantom", "Splunk Enterprise"],
    "Speakers": [
      "Brandon Gagliardi , Sr. Security Engineer, Nutanix",
      "Nicholas Pierini , Manager, Security Engineering, Nutanix"
    ],
    "Industry": "Not industry specific",
    "Description": "Nutanix implemented Splunk to improve operations and security. Attend this session to learn how we started small and grew our Splunk footprint, going from 80 GB/day to 700GB-1.8TB/day, to satisfy key IT and business needs. You will also learn how we leveraged Splunk and our own Nutanix infrastructure for a successful data center migration that involved over 2000 clients and 80+TB of data. We‚Äôll share best practices and insights into running virtualized Splunk Enterprise on hyperconverged infrastructure (HCI). You‚Äôll also learn about an app for Phantom, which we‚Äôll demo, we built to provide security operations teams the ability to quickly contain a VM by stopping or suspending it, then safely starting it, plus the other workloads, like firewall, Docker (incl. Splunk Docker), ETL, etc., we run alongside Splunk on the same infrastructure stack. Whether you‚Äôre a Splunk user or own the infrastructure that supports your Splunk team, you‚Äôll get details to help you in your job.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNS2584.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2584.mov"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2585 - Get Both High Performance & Ease of Management for Splunk with Nutanix",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "James Brown , BigData Solutions Architect, Nutanix",
    "Industry": "Not industry specific",
    "Description": "Explore the benefits of running Splunk on Nutanix Enterprise Cloud, both taking the complexity out of managing the infrastructure and ensuring the performance you need so that your experts can spend more time extracting insight from data. Attend this webinar to gain valuable insights into how to architect the best environment for Splunk Enterprise with deployments that can scale to handle increasing data ingest rates and ever-increasing expectations for high performance. See a demo and learn useful tips on how Nutanix hyperconverged infrastructure (HCI) based solutions allow you to take full advantage of server virtualization without the limitations of other approaches and add in the speed and flexibility of the public cloud.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNS2585.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2585.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2586 - From Zero to Fully Online with Nutanix HCI & App Management",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": "Splunk Enterprise",
    "Speakers": "James Brown , BigData Solutions Architect, Nutanix",
    "Industry": "Not industry specific",
    "Description": "You want to focus on gathering insights, not setting up your Splunk deployment. Nutanix Enterprise Cloud, built on industry-leading hyperconverged infrastructure (HCI), ensures you can be up and running fast, easily adapt to growth, and removes the risks of infrastructure challenges when moving from pilot to production. Attend this session to see how easy it is to have the cloud-experience for your on-prem Splunk infrastructure and flex to the public cloud when needed. You‚Äôll see a demo of how you can use built-in application lifecycle management and blueprints to simplify and speed managing Splunk Enterprise.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNS2586.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2586.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2822 - Lost In Translation - The Challenge of Managing Microservices",
    "Track": "Foundations/Platform",
    "Speakers": "Mirko Novakovic , Instana",
    "Description": "Instana CEO Mirko Novakovic explores microservices applications and the performance management challenges created by their complexity. Unique microservice architectures, operational and deployment needs create a large management gap.¬†n With so many moving pieces in addition to highly complex architectures, having the raw data won‚Äôt meet the challenge. There‚Äôs just too many pieces, too many dependencies and too much data for humans (even teams) to understand. New management tools are needed that translate data into information.¬†n n Otherwise, each stakeholder must fend for themselves even though the ephemeral application architecture makes it impossible to find bottlenecks. It‚Äôs like trying to get directions in a foreign city where nobody speaks your language - every question and answer gets lost in translation.¬†n n Mirko examines distributed microservice applications, how their complexity creates management problems, and what APM tools should do to automatically meet those challenges and deliver high performing applications.n Instana CEO Mirko Novakovic explores microservices applications and the performance management challenges created by their complexity. Unique microservice architectures, operational and deployment needs create a large management gap.¬†n With so many moving pieces in addition to highly complex architectures, having the raw data won‚Äôt meet the challenge. There‚Äôs just too many pieces, too many dependencies and too much data for humans (even teams) to understand. New management tools are needed that translate data into information.¬†Otherwise, each stakeholder must fend for themselves even though the ephemeral application architecture makes it impossible to find bottlenecks. It‚Äôs like trying to get directions in a foreign city where nobody speaks your language - every question and answer gets lost in translation.¬†Mirko examines distributed microservice applications, how their complexity creates management problems, and what APM tools should do to automatically meet those challenges and deliver high performing applications.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNS2822.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2822.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2827 - The 1m+ UDP messages per second ingestion challenge",
    "Track": "Foundations/Platform",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2827.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2837 - The Blindspot No One is Talking About‚Ä¶But Hackers Are Targeting",
    "Track": "Foundations/Platform",
    "Speakers": ["Greg Kushmerek , Onapsis", "Tara Khanna , Accenture"],
    "Description": "Today‚Äôs largest enterprises run their business on ERP Platforms. These same companies rely on SPLUNK¬† Enterprise Security to monitor and respond to threats targeting their infrastructure and applications. Join Tara tile and Greg name title to learn why ERP platforms are under attack, what leading enterprises are doing to protect them and how you can leverage SPLUNK to monitor threats and prevent catastrophic downtime of your most critical business applications.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FN2837.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2837.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2892 - Secrets from a Splunk Ninja-  Deployment Architecture Best Practices",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Industry": "Not industry specific",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2892.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2896 - Cloud-scale On-Prem- SmartStore Best Practices with Dell EMC",
    "SkillLevel": "Good for all skill levels",
    "Track": "Foundations/Platform",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Industry": "Not industry specific",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/FNS2896.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "FNS2956 - Splunk in AWS- Learn how organizations leverage Splunk to power innovation and cloud adoption",
    "SkillLevel": "Beginner",
    "Track": "Foundations/Platform",
    "Products": "Splunk Cloud",
    "Speakers": "Igor Alekseev , Amazon Web Services",
    "Industry": "Not industry specific",
    "Description": "AWS cloud adoption continues at a rapid pace. Enterprises who migrate their application workloads to the cloud recognize 30-40% reduction in IT overhead costs, resource flexibility, increased speed and innovation. Throughout their cloud adoption journey, enterprises need to manage existing applications and have full visibility over their performance and security.n n Splunk‚Äôs platform built for real-time data management offers native applications for monitoring and analysis. Built on AWS, Splunk Cloud remains the customer‚Äôs choice solution for aggregating their data related use cases while seamlessly supporting their existing applications across both on-premises and the cloud. In this session we will share how Splunk‚Äôs data management, monitoring and analytics capabilities across IT Infrastructure, Security, and Business Analytics use cases help enterprises adopt cloud.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/FNS2956.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "FNS3310 - The 1m+ UDP messages per second ingestion challenge",
    "Track": "Foundations/Platform"
  },
  {
    "Event": ".conf19",
    "Title": "IT1046 - Soup to Nuts SRE- How to leverage ITSI, VictorOps and Phantom to be a site reliability engineering super hero",
    "SkillLevel": "Advanced",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Phantom",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk On-Call",
      "VictorOps"
    ],
    "Speakers": "Chris Crocco , Senior Sales Engineer, Splunk",
    "Industry": [
      "Communications",
      "Not industry specific",
      "Online Services",
      "Technology"
    ],
    "Description": "Site Reliability Engineering: Easy to say, harder to do. It can be especially difficult to make sure that all of tenants of SRE are applied to the services you support in a way that is easy for your engineers to adopt. In this session, we will take a look at how you can use Splunk's ITSI, VictorOps and Phantom platforms to make robust solutions that can help your teams consistently solve complex problems and mature their services.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1046.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1046.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1118 - Anatomy of a Successful Event Analytics Deployment",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Alok Bhide , Director of Product Management, Splunk",
      "Martin Wiser , ITOA Practitioner, Splunk"
    ],
    "Industry": [
      "Communications",
      "Financial Services",
      "Healthcare",
      "Higher Education",
      "Non-Profit",
      "Online Services",
      "Public Sector",
      "Retail",
      "Technology",
      "Travel & Transportation"
    ],
    "Description": "This session dives deep into event analytics deployments and how to execute them. From data onboarding to event consolidation and event reduction, this session covers proven strategies and tips and tricks to show you how to approach replacing an existing Event Management Systems while avoiding information overload for your operations staff. If you want to move off your legacy MoM and replace it with Splunk's IT Service Intelligence you don't want to miss this!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1118.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1118.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1119 - AIOps - How to build a Self Learning Event Analytics Platform",
    "SkillLevel": "Advanced",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Martin Wiser , ITOA Practitioner, Splunk",
      "Pierre Brunel , Staff Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "AIOps platforms utilize big data, modern machine learning, and advanced analytics technologies to directly and indirectly enhance IT Operations functions. This session shows how to leverage Splunk IT Service Intelligence (ITSI) and the Machine Learning Toolkit (MLTK) to build a basic, self-learning recommendation engine. Your Operations Center will reap the benefits from having assisted recovery input, but this session does not stop there. It also will show you how to fully automate the recovery. If you have AIOps initiatives on your radar come on and participate in this session ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1119.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1119.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1171 - Accelerate your ability to sniff out application exceptions and detect outliers in performance KPIs",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Eurus Kim , Staff ML Architect, Splunk",
      "PJ Pokhrel , Performance Engineer, StubHub",
      "Steve Veio , Performance OPS Manager, StubHub"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you frustrated with how long a Splunk time series query of your data can take when you need it now, and are you looking to use machine learning to quickly gain insights about your app‚Äôs performance? Finding application exceptions or detecting outliers in your performance KPIs too late can lead your business to suffer without the information it needs to make the right decisions in a timely manner. We will show you how we used the metrics index and machine learning capabilities in Splunk to make better alerts, build scheduled performance reports, and ultimately gain deeper insights and make better decisions based on our data. Sharing these insights as a weekly scheduled report helped our team find hidden issues, increase performance awareness, and maintain SLAs around performance KPIs. Additionally, better alerts operationally helped us to detect outliers in performance metrics within minutes after they occur. Join this session to see queries, demos and several examples for you to take back with you and implement this solution at your company. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1171.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1171.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1186 - Remediation-as-a-Service with Splunk ITSI",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": "Karthick Muruganantham , JPMorgan Chase",
    "Industry": ["Financial Services", "Not industry specific", "Technology"],
    "Description": "A large volume of known production incidents and end-user issues are still being resolved manually. This becomes worse when it happens in unusual hours and no one is there to fix it. Every minute of downtime is detrimental to business and waking up an engineer at the middle of the night to fix simple known issues is not worthwhile. Our self-healing (Event-Driven Remediation) solution fixes simple and known incidents automatically. For complex alerts, it gets relevant diagnostics and context from the logs. This could massively improve customers' and employees' experience in any organization.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1186.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1186.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1203 - A deep dive into Boss of the NOC 2019",
    "SkillLevel": "Beginner",
    "Track": "IT Operations",
    "Products": [
      "Phantom",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Industry": "Not industry specific",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1203.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1227 - Splunk ITSI ‚Äì From 'Just Getting Started' to 'What‚Äôs Hot in This Release",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk IT Service Intelligence",
    "Speakers": "Alok Bhide , Director of Product Management, Splunk",
    "Industry": [
      "Aerospace & Defense",
      "Communications",
      "Energy & Utilities",
      "Financial Services",
      "Healthcare",
      "Higher Education",
      "Manufacturing",
      "Non-Profit",
      "Oil & Gas",
      "Online Services",
      "Public Sector",
      "Retail",
      "Technology",
      "Travel & Transportation"
    ],
    "Description": "Have you heard the buzz? Splunk IT Service Intelligence (ITSI) just hit its latest release, and it‚Äôs jam-packed with new feature you just can‚Äôt miss, including the latest in infrastructure troubleshooting and monitoring, app analytics, event management, service insights, predictive analytics, and, of course, AIOps. Attendees at this session can sample it all, from just getting started to making the most of the latest and greatest.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1227.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1227.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1258 - Infrastructure and System Monitoring with Splunk and Telegraf",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": "Lance O'Connor , Distinguished Engineer, TiVo Inc.",
    "Industry": "Not industry specific",
    "Description": "Telegraf is a open source tool that is used for collecting metrics from a variety of inputs, including system data (CPU, memory, disk, and network), docker, MySQL, etc. Telegraf (as of v1.8) supports a 'splunkmetric' serializer for native ingest into Splunk's metric store using a variety of Telegraf's output modules, including file outputs, and HTTP with the ability to include HEC-required fields. Telegraf can be deployed as a stand-alone daemon or as a Splunk application that can be pushed out from deployers, masters, and the like. We'll investigate the various integrations with Telegraf and Splunk including using Telegraf as the system to feed Splunk's App for Infrastructure (in lieun  of collectd), custom dashboards, as well as integrations with ITSI. With Telegraf's multitude of inputs, outputs, and a nearly universal run-time, it's a fantastic tool to add to your system monitoring workflows.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1258.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1258.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1287 - 2019 State of DevOps Expert Panel",
    "SkillLevel": "Good for all skill levels",
    "Track": "IT Operations",
    "Products": ["Splunk Cloud", "Splunk Enterprise", "VictorOps"],
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "IT1296 - DevSplunkOps- Making Splunk the Single View for the SDLC",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Endre Peterfi , Staff Sales Engineer, Splunk",
      "James Odom , Head of Service Delivery, Converging Data"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you tired of looking in multiple areas for different parts of the DevOps cycle? Learn how to use Splunk to gather and display all your metrics in a single place. We will show you how we Splunked Azure DevOps (TFS), SonarQube, GitLab, Service Now, and Slack to provide a single view for the Plan, Build, and Run steps of a team, and how that compares to other teams.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1296.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1296.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1339 - Distributed Tracing via Structured Logging Using Splunk",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Amit Ziv , Sr Financial Software Engineer, Bloomberg L.P.",
      "Pat  Rogan , Sr Financial Engineer, Bloomberg L.P."
    ],
    "Industry": "Technology",
    "Description": "Is your team spending too much time investigating common business and engineering questions due to a lack of transparency into your rapidly growing distributed system? Is logging for your microservices a haphazard mess? Is isolating a single event workflow throughout the pipeline just TOO MUCH WORK? Learn how we utilized Splunk to simplify troubleshooting distributed systems at Bloomberg. In this session, we will: Walk through some custom components that provide transparency into complex distributed microservices; show how to utilize them to find and isolate a single event workflow; explain how to write highly-optimized Splunk SPL queries to answer various business workflow questions; and demonstrate how to present the results using advanced visualizations.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1339.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1339.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1346 - Why Dinosaurs Make Bad Pets-  Legacy Monitoring Tools and their Extinction ‚Äì TIAA Adopts ITSI as their new MoM",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Emily  Duncan , ITOA Specialist, Splunk",
    "Industry": ["Financial Services", "Not industry specific"],
    "Description": "Too many tools, too many silos between data and collaboration, Outages take too long to Identify Root Cause and There is So Much Noise Abstract: ¬†TIAA had a goal ‚Äì to replace Legacy Monitoring with an AIOps approach. ¬†What did that mean? ¬†They had to find a better way to break down the silos between data and collaboration and start focusing attention on the right things with the right people. ¬†Monitoring had become about MTTI (mean time to innocence) instead of fixing the fight issues more quickly and finding a way to move from ‚Äòreacting‚Äô to outages to ‚Äòpreventing‚Äô them. ¬†ITSI has become the ‚Äòaggregator‚Äô of monitoring data and will help TIAA move from the old Dinosaur Approach of being event driven to the AiOps approach of Service and Priority Driven. ¬†Learn about the Journey, the Lessons Learned, and the Best Practices to Ensure Success. ¬† ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1346.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1346.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1388 - Splunk, PCF and ITSI ‚Äì supporting PCF with ITSI at scale",
    "SkillLevel": "Beginner",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Kirk  Kirk , ITOA Architect , Splunk",
      "Shubham Jain , Software Engineer, Splunk"
    ],
    "Industry": ["Financial Services", "Not industry specific", "Technology"],
    "Description": "Many Fortune 500 companies use Pivotal Cloud Foundry to push its high-quality code into production faster. While this helps companies enforce enterprise logging and application development standards, the traditional monitoring tools used to monitor development environments become the bottleneck because they are not architected to handle a firehose-nozzle connection. Learn how to use the new Splunk ITSI module for PCF, along with the new version of Splunk Firehose Nozzle for PCF to gain operational insight into PCF platform and increase developer satisfaction.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1388.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1388.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1433 - Down in the Weeds, Up in the Cloud- IT Ops",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Ry Lait , Senior Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Analytics Workspaces, Application Insights, Azure Monitor, O365 Admin Centers, just a few of the many Microsoft tools required to monitor and interrogate information from Azure & Office 365. Getting the valuable intel and insights from your Azure and Office 365 environments should be easy, and effortless. Throw on your Splunk hoodie and join Ryan as we Splunk our way through all things IT in Azure, Office365 as part of the Microsoft-as-a-Service world! Infrastructure management, real-time billing, SLA monitoring, capacity planning, all quick, all easy, all powerful with Splunk!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1433.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1433.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1448 - Splunk for NewOps ‚Äì Using Data-Driven IT Operations to Better Manage IT Systems at Scale",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit",
      "Splunk On-Call",
      "VictorOps"
    ],
    "Speakers": [
      "Andi Mann , Chief Technology Advocate, Splunk",
      "Endre Peterfi , Staff Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Splunk is increasingly at the forefront of new approaches to IT Operations, especially in disruptive ‚Äòcloud-native‚Äô businesses. This session will help you understand how ‚ÄòNew Ops‚Äô techniques like Observability, Site Reliability Engineering, SLOs/SLIs, Error Budgets, ChatOps, and Blameless Post-Mortems can help your IT Ops team; and how you can adopt ‚ÄòNew Ops‚Äô technologies like Containers, Microservice Architectures, Machine Learning, Orchestration, Predictive Analytics, and AI for IT Ops.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1448.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1448.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1514 - A Prescriptive Design for Enterprise-Wide Alerts in IT Service Intelligence",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": [
      "Jeff Wiedemann , Staff SE and ITSI Master, Splunk",
      "Matt  Hasty , Sr. Engineer, GEHA"
    ],
    "Industry": ["Financial Services", "Healthcare", "Not industry specific"],
    "Description": "Producing meaningful, trusted alerts is the holy grail of any IT service monitoring tool, yet the road to get there is winding and perilous. While Splunk IT Service Intelligence is uniquely suited to convert machine data into actionable alerts, how to design your ITSI deployment to effectively produce, maintain, and scale alerts isn't obvious, until now! In this talk, we'll walk you through the alerting strategy GEHA implemented in conjunction with Splunk to achieve meaningful alerts show you a highly streamlined design that you can replicate in your deployment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1514.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1514.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1523 - The top 10 glasstable design principles to boost your career and your business",
    "SkillLevel": "BeginnerIntermediateAdvancedGood for all skill levels",
    "Track": "IT Operations",
    "Products": "Splunk IT Service Intelligence",
    "Industry": [
      "Aerospace & Defense",
      "Communications",
      "Energy & Utilities",
      "Financial Services",
      "Healthcare",
      "Higher Education",
      "Manufacturing",
      "Non-Profit",
      "Oil & Gas",
      "Online Services",
      "Public Sector",
      "Retail",
      "Technology",
      "Travel & Transportation"
    ],
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1523.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/IT1523.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1564 - Los Angeles World Airports - Streamlining event management with IT Service Intelligence (ITSI)",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Kelcy Taylor , SLED Account Manager, Splunk",
      "Michael Friedhoff , Director & Lead Architect, Wipro Ltd.",
      "Shahla  Dallalzadeh , IT Manager, Los Angeles World Airports"
    ],
    "Industry": ["Public Sector", "Technology", "Travel & Transportation"],
    "Description": "Los Angeles World Airport has chosen Splunk's ITSI as their centralized event/alert management platform. We‚Äôve consolidated alerts/events from multiple management platforms across the enterprise, reducing help desk churn by grouping similar events, and evaluating the results against smart Key Performance Indicator (KPI) thresholds so that only actionable alerts or events are processed. In addition, we‚Äôve broken down the legacy data siloes through the use of service definitions, glass tables, and deep-dives, providing better insight for all team members. Lastly, we‚Äôve automated ITSI service and dependency creation via the Splunk ServiceNow bi-direction integration App. Plan top attend this session and you will learn how we‚Äôve increased visibility (making data available for everyone); increased efficiency by reducing alert/event noise; improved resolution using ITSI Smart KPIs; and implemented auto service creation via ServiceNow ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1564.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1564.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1589 - 'Excuse Me! Your Microphone isn‚Äôt on' ‚Äì supporting 400 teaching spaces with Splunk & ITSI ‚Äì A case study",
    "SkillLevel": "Beginner",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Ed Messina , IT Security and Risk Manager, Monash University",
      "Paul  Brasier , Service Improvement Manager -Technical Services, Monash University",
      "Rashmi Pokharel , Systems Engineer, Monash University"
    ],
    "Industry": "Higher Education",
    "Description": "Do you remember the time when you had to attend lectures in person? Monash University has extended teaching hours and stopped repeating lectures. To provide flexibility to students and release pressure on finite campus facilities, lectures are now live streamed and are guaranteed to cover 100% of the classroom content. We are using Splunk and IT Service Intelligence (ITSI) to help monitor live streaming of lectures. It is impossible to manually monitor hundreds of teaching spaces in real-time and keep track of lecture schedules, the status of AV devices, microphones, and audio signals. Come and see how we at Monash University use Splunk ITSI glass tables to rule them all! Using ITSI we get real-time insights into service health and entity-level alerting based on ITSI thresholds.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1589.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1589.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1602 - Infrastructure Insights- Reducing Time by Shining a Light on Siloed IT Landscapes",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Eric Macintosh , Systems Engineer, UPMC",
      "Rob Roman , Systems Engineer, UPMC"
    ],
    "Industry": "Not industry specific",
    "Description": "In a highly virtualized environment, getting a clear picture of the infrastructure landscape can be challenging. Because data is siloed between each layer of IT, discovering their relationships is often a manual task involving multiple teams. But using Splunk, building those relationships becomes a breeze. Join us as we discuss how we combine data from the Configuration Management Database (CMDB), Virtual Infrastructure, and Storage Environment to present an easy-to-use interface that allows our users to explore their infrastructure. Troubleshooting issues that used to take a user hours of downloading and parsing data from multiple sources now takes seconds with a click of a button. From finding all applications running on one host to determining which teams to notify for upcoming storage work, we can now quickly show all meaningful relationships between applications, servers, hosts, and storage.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1602.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1602.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1642 - How 3M is Transforming SAP ERP Operations through AIOPS",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Phantom",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Claw Clawson , SplunkYoda, Splunk",
      "Michael Flint , IT Operations Manager, 3M",
      "Nathan Carr , DevOps Engineer, 3M"
    ],
    "Industry": [
      "Aerospace & Defense",
      "Communications",
      "Energy & Utilities",
      "Healthcare",
      "Manufacturing",
      "Not industry specific",
      "Oil & Gas",
      "Technology",
      "Travel & Transportation"
    ],
    "Description": "Discover how 3M is using Splunk to get more value and insights from their mission-critical SAP deployment and its complex legacy environment. You can see how far we have we come and where  our vision will take us. Managing SAP is a complex and mission-critical challenge. With its proprietary and often-customized inner workings, SAP has become synonymous with complexity and has long been a difficult challenge for IT departments around the globe to manage. With even short outages carrying the potential of large impacts, it is more important than ever for large ERP customers to bring their systems management and monitoring practices into the data-driven world. In this session, learn what transformational outcomes have been and are being achieved as this 116-year-old global manufacturer partners with Splunk to embrace and overcome ERP and legacy operational data chaos.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1642.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1642.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1648 - AIB IRELAND ‚Äì Splunk-ITSI monitoring of time critical Payment Business Flows with real time insights into health of Mobile and Payment Applications",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk IT Service Intelligence",
    "Speakers": [
      "Damien Perrem , Head of Technology - Payments Platforms, AIB",
      "Garvan Power , Middleware Senior Technical Lead, AIB"
    ],
    "Industry": "Financial Services",
    "Description": "Splunk Insights platform supporting AIB Digital Transformation on the journey to AIOps. This presentation will outline the payments business and technology strategy, steps, challenges, and benefits AIB has realized leveraging Splunk and IT Service Intelligence to deliver:n * Payments end-to-end business activity monitoring, including payment-level integrity checking, trends, and performance against time critical cut offs; andn * Mobile and Payment App 'live' health monitoring using Splunk ITSI for predictive service insights into business, application, and inframetrics, including OS and Oracle health diagnostics.n AIB is using Splunk ITSI to monitor service health across the stack and will share examples where health degradation of critical services was highlighted, allowing AIB to intervene in time and resolve the issue before a critical incident occurred.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1648.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1648.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1670 - Customer Service is as Easy as Pie with ITSI",
    "SkillLevel": "BeginnerIntermediateAdvancedGood for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": [
      "Christina Miceli , Splunk System Design Engineer, Penn State University ",
      "Sandy Leon , Sales Engineer, Splunk"
    ],
    "Industry": ["Higher Education", "Not industry specific", "Technology"],
    "Description": "Do you need to support thousands of people every day logging into your organization‚Äôs web applications? Customer service is important to Penn State University (PSU), and Splunk ITSI offered the perfect solution for health monitoring and data sharing between executive management and subject matter experts within the WebAccess team. At PSU, WebAccess is the Single Sign-On (SSO) solution supporting over 140,000 students, facility, and staff. ITSI‚Äôs Service Analyzer showcases the relationships among various SSO components: Active Directory, CoSign, Duo Two-Factor Authentication (2FA), Lightweight Directory Access Protocol (LDAP), Kerberos, and Shibboleth. Join us and learn how ITSI pioneered the recipe for PSU to isolate root cause slicing deep dives and allowed management to analyze performance on a glass table. Splunk‚Äôs ITSI continues to deliver valuable insights from back end systems to front end user interfaces, improving customer service. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1670.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1670.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1697 - Every Minute Counts- Integrating Splunk and VictorOps to Accelerate Incident Response",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk On-Call",
      "VictorOps"
    ],
    "Speakers": [
      "Dylan Klausing , Sales Engineer Manager, Splunk",
      "Kirk  Kirk , ITOA Architect , Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Splunk/VictorOps allows your data to talk to people, and your people to talk to data, all while improving MTTR/MTTI. You‚Äôre already using Splunk today to get cool dashboards, ask questions of your data with search, and trigger important alerts based on data that‚Äôs of interest to you. But, just because alerts are important doesn‚Äôt mean they are for everyone. And for those who should respond to the alert, it‚Äôs important to get the alert into their hands immediately. Transitioning to a modern NOC, or 'New Operations Center,' Splunk and VictorOps enable teams to collaboratively solve issues by providing on-call users with actionable alerts that allow for smarter investigation, faster mobilization, and lower mean time to resolution. In this session we‚Äôll take a look under the hood at different Splunk and VictorOps integrations.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1697.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1697.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1708 - The Basics- How to make on-call suck less with VictorOps",
    "SkillLevel": "Beginner",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk On-Call", "VictorOps"],
    "Speakers": [
      "Dave Wiedenheft , Sr Product Manager, Splunk ",
      "Melanie Macari , Sr. Product Marketing Manager, Splunk + VictorOps, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "In this session, we‚Äôll discuss ways that VictorOps empowers DevOps teams by delivering context-rich infrastructure and application monitoring alerts to the right people so they can collaborate cross-functionally to empower fast, efficient incident resolution‚Äîand reduced downtime. Applications are fixed quickly while teams work better together and continuously learn how to improve systems and processes for a better on-call experience. You‚Äôll see an in-depth demo of the product to better understand the difference between Collaborative Incident Response and traditional 'trouble ticketing,' and get insight into how Splunk integrates with VictorOps to make alerting a seamless experience.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1708.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "IT1717 - Splunk as a Tool for DevOps Acceleration",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk On-Call",
      "VictorOps"
    ],
    "Speakers": "Josh Atwell , Sr Technology Advocate, Splunk",
    "Industry": "Not industry specific",
    "Description": "DevOps adoption requires high performing teams. One of the biggest challenges organizations have when adopting a DevOps framework is how to get early wins, get value early in the process, and overcome plateaus in adoption. These improvements are typically achieved through the use of automation, improved responsiveness, better situational awareness, and increased sharing between teams. As you will see in this session, Splunk easily sits in the middle of all of this.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1717.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1717.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1722 - Predict Real World Outage using Splunk MLTK",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Machine Learning Toolkit",
    "Speakers": [
      "Gintaras Gaigalas , Sr. RF Engineer, T-Mobile",
      "Vijay Veggalam , Member of Technical Staff, T-Mobile"
    ],
    "Industry": "Communications",
    "Description": "Do you want to predict an outage before it happens? Are you wondering how to pursue the incremental journey to Artificial Intelligence Operations (AIOps)? This case study will reveal a real-world use case from T-Mobile USA and show you how to predict cell tower congestion in advance using Splunk Machine Learning Toolkit. In the age of binge watching on cell phones and wireless broadband services, cell congestion reduces speed and reliability and results in buffered video streaming and/or dropped calls that dents the use of services and the revenue. Building forecasting models for congestion requires correlation of several parameters including seasonal variations. Doing this on a large scale in real time takes significant resources. In this session, attendees will learn about the journey to build this predictive capability, including data analysis techniques, machine learning algorithms, benefits, and lessons learned. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1722.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1722.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1729 - Kubernetes Observability with Splunk Connect for Kubernetes (SCK)",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Chaitanya Phalak , Software Engineer, Splunk",
      "Don  Tregonning , Senior Software Engineer, Splunk",
      "Shubham Jain , Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Kubernetes is the go-to standard for the automation of deployment, management and scaling of containerized applications. From an observability perspective it is extremely difficult to analyze, troubleshoot and gain actionable insights from these containerized applications. We bridge this gap of observability with the open-sourced Splunk Connect for Kubernetes. Splunk Connect for Kubernetes is the Splunk supported integration to ingest logs, metrics and Kubernetes object state information into Splunk. This session is intended for k8s users and developers who want to make their lives easier leveraging Splunk alongside Kubernetes. Come join the developers who built Splunk Connect for Kubernetes and learn how to configure and run Splunk to monitor your Kubernetes environment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1729.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1729.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1734 - Porsche unleashes the Next Level of Operational Maturity with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "IT Operations",
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Industry": ["Manufacturing", "Travel & Transportation"]
  },
  {
    "Event": ".conf19",
    "Title": "IT1753 - How Kronos Consolidated Logging and Infrastructure Monitoring with the Splunk App for Infrastructure",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Azmath  Shaik , Tools Engineer, Kronos Incorporated",
      "Srikar Mohan , Cloud Systems Architect, Kronos Incorporated"
    ],
    "Industry": "Not industry specific",
    "Description": "Monitoring a microservice-based and globally distributed SaaS solution in the public cloud is challenging alone, but doing it with a variety of monitoring and logging tools makes it even harder. Learn how the Kronos Workforce Dimensions team consolidated logging, infrastructure monitoring, and cloud monitoring all within Splunk to facilitate seamless issue detection and correlation in an effort to minimize time to resolution. In this session, we will share our approach and lessons learned with respect to deployment in the cloud, alerting and visualization (dashboards) in our journey of consolidation of tools and leveraging the new Splunk App for Infrastructure app along the way.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1753.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1753.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1761 -  Service and Asset Discovery with Wire Data",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": "David Cavuto , Staff Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Your network is speaking to you! Listen to what your applications are saying. Monitoring the metrics already present in your wire data can provide the key to understanding and characterizing their performance. Using tools like Splunk Stream, you can collect dozens of metrics at the IP, TCP, and Application layers. This session will show you how to characterize the performance of your applications and the network, and how to tell which is the source of trouble. We'll also explore how to perform service and asset discovery with wire data as a basis of fact, correlating it with your database 'of record' to ensure its accuracy.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1761.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1761.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1766 - Monitoring your VMWare vSphere Environment with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": "Ian Torbett , Product Manager, Splunk",
    "Industry": "Not industry specific",
    "Description": "Siloed IT monitoring for Virtualization struggles to scale as teams use different tools to monitor the same IT environment, increasing complexity and decreasing productivity. Imagine analysts, admins and virtualization teams collaborating and troubleshooting on a single platform. No more finger pointing, no more 'my tool says', no more data disagreements. Use Splunk for centralized infrastructure monitoring of your virtualized environment.n n ¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1766.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1766.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1785 - Want to Turbocharge your Developer Pipeline-",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": "Viktor Adam , Senior Software Engineer, Atlassian",
    "Industry": ["Not industry specific", "Technology"],
    "Description": "Do you want to help your developers waste less time on issues and spend more time optimizing build times using Splunk? Do you want to improve developer satisfaction while cutting build times by 35% on a long-established and entrenched code base? Then join us to hear how Jira developers at Atlassian, the world leader in software collaboration tools, did just that. We will explain how we used Splunk Enterprise to collect metrics as structured events from developer machines to improve our Maven build times for several hundred developers. We aggregated, analyzed, and visualized these events to not only identify and resolve performance bottlenecks as they occurred across our developer pipeline, but also to pinpoint the next big thing to tackle; a dream result for us. Not a Maven user? No worries. The approaches we will cover are good for any developer setup, allowing you to jump start build time improvements while generating the continuous insights you need to do more with less time and less waste. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1785.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1785.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1798 - Qualcomm‚Äôs Journey to World-Class IT Monitoring Using Splunk",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": [
      "Ben Marcus , Sr. Staff IT Engineer, Qualcomm",
      "Michael Donnelly , ITOA Solutions Architect, Splunk",
      "Ryan Sims , Staff Manager, IT, Qualcomm"
    ],
    "Industry": "Not industry specific",
    "Description": "Qualcomm‚Äôs focus on inventing mobile technology breakthroughs relies on a complex, global IT infrastructure. In order to deliver on this mission, its IT team embarked on a journey using Splunk Enterprise and IT Service Intelligence to develop world-class IT monitoring approach and implement a framework for continuous improvements. Learn how Qualcomm got started with core Splunk for logging, evolved to include system metrics, and ITSI for core services. Qualcomm will present how it approaches achieving its major objectives, such as democratizing access to data, breaking down silos around teams to improve collaboration, reducing time to troubleshoot and recover incidents, and achieving better visibility and understanding around service performance.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1798.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1798.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1859 - Splunk Implementation as a Customer Impact Analysis Platform for Mission Critical Core Network Service",
    "SkillLevel": "Intermediate",
    "Track": "IT Operations",
    "Products": "Splunk Enterprise",
    "Industry": "Communications"
  },
  {
    "Event": ".conf19",
    "Title": "IT1878 - How a team of 4 Site Reliability Engineers can manage 100's of team‚Äôs data and 10,000 VM's through automation",
    "SkillLevel": "Advanced",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Cloud",
    "Speakers": [
      "David Ashe , Senior Site Reliability Engineer, Paddy Power Betfair",
      "Gerard Healy , SRE, Paddy Power Betfair"
    ],
    "Industry": ["Communications", "Online Services", "Technology"],
    "Description": "This talk will tell how Paddy Power Betfair‚Äôs development teams onboard data to Splunk using pipeline deployments from QA right through to Production. We‚Äôll discuss the large scale of our stack, but how a small team manages Splunk across the organization with the help of automation. We‚Äôll go into detail to demonstrate the business value of Splunk and how it provides efficiencies across the organization.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1878.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1878.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1918 - How S&P Global Migrated to the Cloud with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Mark Wang , Senior Director, S&P Global",
      "Qing Yun Huang , Director of IT Operations, S&P Global",
      "Vinit Masaun , Site Reliability Engineer, S&P Global"
    ],
    "Industry": "Financial Services",
    "Description": "S&P Global is undergoing a cloud transformation. As we continue to mature in the  cloud, we are  partnering with Splunk to enable monitoring that is accurate, timely, and actionable. The cloud transformation project was aggressive, and we have exited our primary data centers and have nearly migrated 100% of applications to the cloud within eight months. We are building in the cloud using infrastructure automation, DevSecOps, and continuous monitoring. The cloud environment is by no means simple. It continues to be complex because some applications have migrated to be cloud-native while others are lift and shift. In addition, we are moving to containers and multi-cloud. All those teams use Splunk to monitor for issues and investigate root causes. By integrating and automating our IT services, we have reduced MTTI and MTTR, and increased our productivity. We will share details about our successful implementation story, and provide steps to help you achieve monitoring maturity in changes.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1918.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1918.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1931 - Marcus by Goldman Sachs- Monitoring an Online Banking Startup with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["AI/ML", "Splunk Enterprise"],
    "Speakers": [
      "Maria  Loginova , Vice President, Goldman Sachs",
      "Yisroel Bongart , Senior Sales Engineer, Splunk"
    ],
    "Industry": "Financial Services",
    "Description": "Marcus by Goldman Sachs is an online, consumer lending and savings platform, often referred to as a startup within the 150-year-old company. The Marcus platform was designed and built from the ground up using the latest technologies and following agile software practices. Splunk software is used to monitor application and infrastructure logs and supports not only DevOps but also Development, QA, Production Support, and Security teams. This session will cover the challenges and successes we have experienced during our first years of rapid growth, the products and capabilities that we added to our platform this year, and provide a glimpse at the potential role of Splunk Next products in online retail banking use cases in the future.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1931.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1931.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1953 - Using real-time data to become the UK‚Äôs most recommended connectivity provider",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Matthew Wood , Head of TalkTalk Labs, TalkTalk",
      "Paul Emmett , Head of Network Operations, Talk Talk"
    ],
    "Industry": "Communications",
    "Description": "TalkTalk is the UK‚Äôs leading value telecommunications company with a strategy to become the UK‚Äôs most recommended connectivity provider. We need to intelligently use real-time data, analytics and automation in order to create a step-change improvement in customer experience and realize cost savings. This presentation explains how Splunk has helped us to use real-time network telemetry data to detect network problems, significantly improve the customer experience, and save TalkTalk money.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1953.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1953.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1962 - Using Splunk and its premium solution to accelerate DevOps lifecycle",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk On-Call",
      "VictorOps"
    ],
    "Speakers": [
      "Alfie You , Principal Software Engineer, Splunk",
      "Scott Lu , Senior Engineering Manager, Splunk"
    ],
    "Industry": "Technology",
    "Description": "As more technology organizations pursue agility and move towards continuous delivery, a stable and reliable IT infrastructure is the foundation that enables the transformation. However, the increasing complexity of the underlying infrastructure also brings a lot of challenges. Splunk has built a variety of solutions on top of our platform to deal with this complexity and deliver analytics and troubleshooting data to our engineering teams and decision makers. We will share a bit about our continuous integration process for triaging automated tests using Splunk, how we build IT infrastructure monitoring/analytics system based on Splunk ITSI, and how we take corresponding actions via VictorOps.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1962.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1962.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1968 - 4 Easy Steps for Reclaiming Your Life (without quitting your job)",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk On-Call", "VictorOps"],
    "Speakers": "Bethany Abbott , TechOps Manager, NS1",
    "Industry": "Not industry specific",
    "Description": "Everything breaks at 3:00 a.m. No one wants a team of engineers managing incidents on little to no sleep. Think about how tired you were the morning after the last all-nighter you pulled. Coffee can only do so much. If you work in any type of technical operations role you know how easy it is for on-call to take over your life. When managing an on-call team, you must think about the human side of on-call to avoid employee burnout and alert fatigue. In this session we will outline a four-step process to streamline incident management, review how to manage alerts through VictorOps, and give your team their lives back!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1968.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1968.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1970 - Tracking Micro Services with Splunk",
    "SkillLevel": "Advanced",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Josh Knox , Principal Engineer, Kinney Group",
      "Paul Gullette , Automation Engineer, Kinney Group"
    ],
    "Industry": "Not industry specific",
    "Description": "Using a combination of Splunk AWS plugin, Docker logs, and direct from script real-time HEC logging, data/jobs can follow an entire data pipeline or workflow. This session will discuss how metrics can be gathered to show bottlenecks, and inefficiencies.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1970.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1970.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT1990 - 'Splunking' IBM i Data to Power a Complete View of Your Infrastructure",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Brian Brake  , Senior System Engineer, Cox Automotive ",
      "Chip Sutton , Director of Software Development, Syncsort"
    ],
    "Industry": [
      "Financial Services",
      "Healthcare",
      "Not industry specific",
      "Retail",
      "Technology",
      "Travel & Transportation"
    ],
    "Description": "IBM i systems are used by many customers in a number of industries such as banking, retail, transportation and hospitality. Splunk is a perfect tool for consolidating and analyzing event, security, performance, and application data from these critical IBM i systems. Having a single and complete view of infrastructure data allows operations, security, and performance analysts to quickly identify and correlate operational, security, and performance issues. Syncsort Ironstream‚Ñ¢ for Splunk can easily capture the needed event, security, and performance data in real time. Detailed performance data from these IBM i systems combined with Splunk‚Äôs machine learning algorithms can provide a new degree of confidence in capacity planning.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT1990.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT1990.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2001 - Monitoring and troubleshooting workloads running on public cloud infrastructure made easy",
    "SkillLevel": "Good for all skill levels",
    "Track": "IT Operations",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "IT2002 - Leaving the 'Dinosaurs' Behind- Replacing Legacy Monitoring Tools Part I",
    "SkillLevel": "Good for all skill levels",
    "Track": "IT Operations",
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2002.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/IT2002.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2009 - Big DevOps in Small Packages- Building a scalable cloud monitoring platform with SmartStore, Docker and AWS Services at UK Ministry of Defence",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Josh Collyer , Sr. Data Scientist, UK Ministry of Defence",
      "Julia Lawrence , Sr. DevOps Engineer, UK Ministry of Defence"
    ],
    "Industry": "Public Sector",
    "Description": "Last year, at the Container Strikes Back session, Brent Boe and Brian Bingham introduced the new Splunk official container. Today, we‚Äôre talking about the benefits as well as the challenges we encountered adopting the 'Splunk in containers!' strategy at the Ministry of Defence for both our testing and our production environments. Our small DevOps team tasked with deploying Splunk did not have the bandwidth to build a resilient and scalable Splunk deployment in a traditional way at the pace required. By consuming the official Splunk Docker image, taking advantage of SmartStore backed by AWS S3, making a liberal use of other AWS services, and with support from Splunk PS architects as well as communities around Splunk‚Äôs official GitHub repos, we were able to rapidly deploy a complex Splunk cluster in AWS with minimal overhead. This has allowed our project to keep to our tight deadlines around cloud migration, while also providing a monitoring platform that can be scaled out over time as adoption increases.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2009.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2009.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2091 - Real-world strategies for Kubernetes & docker integrations with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Ahmed  Kira , Counter Errorist, Splunk",
      "Parjinder Pannu , Software Engineer, Cisco Systems"
    ],
    "Industry": "Not industry specific",
    "Description": "Have you jumped on the Kubernetes train and are now thinking about your logging strategy? Or are you considering migrating your application to a microservices architecture like Docker and want to proactively plan your logging strategy? The data capture methods and data format can be significantly different from what you used in the past. Additionally, multi-line events need to be accounted for. There are a few different ways to ingest this data into Splunk. For example, Splunk 'Kubernetes Connect' leverages Fluentd behind the scenes. There also is a Splunk logging plugin for docker, and a syslog logging plugin. The Splunk Universal Forwarder also can be deployed on a sidecar. What the pros and cons with so many choices? This session will help you sort it all out.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2091.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2091.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2095 - Distributed Tracing in Splunk- Get end-to-end visibility into application performance with Splunk and OpenTracing ",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": [
      "Dave Cornette , Enterprise Monitoring Architect, T-Mobile",
      "Gary Burgett , Staff Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you addressing the challenges of gaining visibility into a distributed microservices environment? Is your organization considering using distributed tracing to augment your APM capabilities? Have you heard of OpenTracing and want to learn what capabilities it gives you and how to get started? Come learn about the OpenTracing project and how you can use it with Splunk to get a complete picture of your application environment using logs, metrics, and traces. We'll go from the basics of what the project is to how to get started integrating with Splunk. We'll also review an example of a large telco customer to see how they got started with OpenTracing and how they rolled it out in their application environments.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2095.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2095.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2098 - Using Splunk for Engineering Productivity ",
    "SkillLevel": "Advanced",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Bill Houston , Senior Release Engineer, Splunk",
      "Eddie Shafaq , Release Engineer, Splunk"
    ],
    "Industry": "Technology",
    "Description": "This session will discuss using Splunk to identify areas of improvement around the build and release of software by providing faster, continuous integration and delivery services for our development team at Splunk.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2098.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2098.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2133 - Improved Methods for Using Selenium with Splunk to Monitor Web Apps",
    "SkillLevel": "Advanced",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": "Justin Brown , IT Engineer, Pacific Northwest National Laboratory",
    "Industry": ["Not industry specific", "Public Sector", "Technology"],
    "Description": "Using data that you probably already have in Splunk, you can gain tremendous insight into the performance of your web applications. However, this requires someone to visit your application, and ideally you don't want your customers discovering your problems for you. What happens when nobody is looking? What if a part of the site is broken but users just haven't tripped over it yet?  We'll demonstrate the methods that we developed at the Pacific Northwest National Laboratory using Splunk and open source tools like Selenium to monitor web applications with synthetic interactions that happen in a real browser to verify everything is performing as expected. We'll share how to put the pieces together, including configuring Selenium Grid, creating monitoring that thoroughly tests your apps, dashboards that create and test your Selenium interactions for you, getting screenshots and network waterfall data, and our monitoring dashboards that combine test results with existing Splunk data.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2133.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2133.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2139 - United Health Group- Providing real-time visibility with Splunk IT Service Intelligence from the front end all the way to the mainframe",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": [
      "Ben Nolan , Splunk IT Service Intelligence Administrator, Optum ",
      "Jacob  Edelen , Splunk ITSI Administrator, Optum"
    ],
    "Industry": ["Healthcare", "Technology"],
    "Description": "Does your IT environment look like a huge bowl of spaghetti? Is it even possible to untangle that vast, complex, and diverse ecosystem? Is moving from reactive to proactive even a possibility? Join us to learn how United Health Group is using Splunk IT Service Intelligence to provide end-to-end visibility and proactive incident response to its critical business applications. We‚Äôll show you how mapping service dependencies and defining meaningful key performance indicators from the front end all the way back to the mainframe is providing value to the DevOps teams and the businesses they support.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2139.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2139.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2184 - Fiserv Turns ITSI Up to 11 ‚Äì with Powerful KPIs, Better Performance, & Custom Alerts",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": "Peter Thomas , Manager, Application Monitoring, Fiserv",
    "Industry": ["Financial Services", "Not industry specific", "Technology"],
    "Description": "ITSI provides a platform to turn your never-ending stream of app and infrastructure data into manageable KPIs that you can act on, but how do you manage the number of events ITSI detects? What if you need to extend ITSI with additional capabilities in order to merge your alerts with your support team's response processes? We will turn ITSI up to 11 by adding the concept of 'platforms' as a collection of related services, support reoccurring maintenance windows, and generate rich alerts that include information such as which entities are impacted and what the KPI values are. These concepts are combined so that all the problems in your platform generate a single alert with alert text rich enough that that your support teams can respond without opening ITSI, and we will do it all with just SPL.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2184.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2184.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2202 - Success in the Public Sector- How the State of Michigan uses Splunk to improve the lives of its citizens",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Mobile"
    ],
    "Speakers": [
      "Amy Hundley , Deputy Director for Field Operations Administration, State of Michigan -  DHHS‚Äô, State of Michigan",
      "Josh  Scheurer , System Architect, State of Michigan",
      "Sanjay  Srivastava , Division Director (Eligibility) , Department of Technology Management and Budget, State of Michigan "
    ],
    "Industry": "Public Sector",
    "Description": "If you‚Äôre not investing in new technology, you are going to be left behind! One of the key challenges within any state government agency is ensuring system and application performance, SLA enforcement, secure operations, and adhering to strict federal and state compliance mandates, all while operating with limited budgets and staff. With help from Splunk, Health and Human Services (HHS) agencies manage systems that issue public benefits to citizens, maintain child welfare, enforce child support, and monitor public health. Come to this session to learn how to leverage Splunk to help you understand the 'complete picture' of your systems and business processes to help your team move toward proactive management and increase customer satisfaction within your governmental applications. Create something useful from millions and billons of lines of log data to improve your application!n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2202.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2202.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2219 - Fighting Fraud at Mastercard Thousands of Times a Second ‚Äì A Use Case of Application Monitoring",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": "Ted Boehm , Vice President, Software Engineering, Mastercard",
    "Industry": "Financial Services",
    "Description": "At Mastercard, we assist our banks in making sure their cardholders are protected from fraud attacks on their cards. We process tens of thousands of transactions per second all within tens of milliseconds. When our platform has outages (big and little), we need to understand how the problem occurred so we can prevent future issues and provide the best service possible. I will provide a detailed use case of a past incident, our challenges and how Splunk helped us find the culprit and make changes to our platform and processes to prevent the issue in the future.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2219.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2219.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2240 - Red Hat OpenShift and Splunk Better Together",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Business Flow", "Splunk Enterprise"],
    "Speakers": [
      "Matt Modestino , ITOA Practitioner, Splunk",
      "Mattia Mascia , Senior Consultant, Red Hat "
    ],
    "Industry": "Not industry specific",
    "Description": "Red Hat and Splunk are partners in providing solutions to manage and monitor Kubernetes deployments. This joint RedHat and Splunk session will cover the benefits of Red Hat OpenShift to run your Kubernetes deployments and how Splunk can provide the monitoring capabilities and insights you need to get the most out of your Kubernetes deployment.n n ¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2240.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2240.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2949 - Observability Demystified ",
    "Track": ["IT Operations", "IT Ops"],
    "Speakers": "Cory Watson , Technical Evangelist, Splunk - SignalFx Products",
    "Description": "What in the world is this observability stuff all about? How is it different from monitoring or the other things we‚Äôve been doing?¬†n n This session will give you a crash course in observability, how to roll it out, how to practice and improve it, and how to ensure you‚Äôre getting the best bang for your buck. We‚Äôll examine the goals, how people use the tools, and what benefits you can expect.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2949.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2949.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2950 - Unified Observability with OpenTelemetry",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["SignalFX", "SignalFx"],
    "Speakers": [
      "Constance Caramanolis , Senior Software Engineer, Splunk",
      "Steve Flanders , Director of Product Management, Splunk"
    ],
    "Description": "We now live in a Cloud Native world where we build and deploy software very differently from the previous generation. Large, centralized systems are being decoupled and distributed to address scalability needs and to allow companies to deliver value faster. Compared to monolithic applications, microservice architectures introduce complexity in network communication, feature much shorter life cycles, and require resiliency in dynamic environments. As companies began to build or migrate to microservice architectures they often run into operational complexity and struggle to efficiently monitor their environments. These challenges have highlighted the need to observe systems differently and lead to the rise of Observability. In this session, we will discuss OpenTelemetry and how it provides visibility into both distributed traces and metrics. We will walk through the architecture including client libraries and collection as well as cover key concepts including annotations, sampling policies and more. Live demos and coding examples will be presented through the talk. By the end of the session, you will know what OpenTelemetry is, why it is important, how you can get started and how you can get involved.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2950.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2950.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT2951 - Effective Strategies for Monitoring Docker and Kubernetes Environments",
    "Track": ["IT Operations", "IT Ops"],
    "Speakers": "Arijit Mukherji , Distinguished Architect, Splunk - SignalFx Products",
    "Description": "Containerization and the adoption of microservices have dramatically accelerated software innovation. However, containerized environments behave so differently compared to traditional ones that they present new observability challenges, and require new monitoring strategies and tools. What are those challenges? In this talk, we will discuss three ‚Äì the explosion in scale, massive component churn caused by continuous delivery, and the need for infrastructure-to-application correlation ‚Äì¬† then share effective strategies for overcoming them in a number of practical examples.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2951.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT2951.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT3005 - Introduction to Real-Time Monitoring with SignalFx",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["SignalFX", "SignalFx"],
    "Speakers": [
      "Alberto Farronato , Head of SignalFx Product Marketing, Splunk - SignalFx Products",
      "Amit Sharma , Director, Product Marketing, Splunk",
      "Jeff Lo , Director of Product Marketing, Splunk - SignalFx Products"
    ],
    "Description": "SignalFx, the latest addition to the Splunk family, is the market leader in real-time cloud monitoring and Observability for infrastructure, microservices, and applications. This session will serve as a primer into the new challenges and solutions involved in effectively monitoring and troubleshooting modern cloud environments built with microservices, containers, Kubernetes, and serverless functions. As you progress on your cloud-native journey and develop your own monitoring and Observability strategy, we will share three valuable insights: 1) best practices for collecting, visualizing, analyzing, alerting, and troubleshooting these complex environments using metrics, traces, and logs; 2) lessons learned from companies that have successfully reduced MTTD and MTTR, improved developer productivity, and improved customer experiences; 3) a live demonstration of the SignalFx platform in actionn ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT3005.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT3005.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IT3123 - Actionable Alerts Using Splunk and VictorOps at Irdeto‚Äôs 24-7 Service Operations Center",
    "Track": ["IT Operations", "IT Ops"],
    "Speakers": [
      "Daryel Murnin , Sr. Manager Cloud Service Operations, Irdeto",
      "Steve Harte , Incident Manager, Irdeto"
    ],
    "Description": "In Irdeto‚Äôs 24/7 Service Operations Center, our goal is to enable proactive enable proactive event management based on performance. We manage a vast infrastructure and operations stack and it‚Äôs important we have the right tools to make better decisions. We fought the war on 'white noise'. Playbooks were established and actionable alerts created. On-Call schedules gave us access to domain expertise. Reporting capabilities helped drive continuous improvement. To better understand how we did this¬†you‚Äôll see an in-depth demo on Integration, the Rules Engine and gain insight into our evolution using ITSI with VictorOps.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT3123.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IT3123.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2199 - Build intelligent self-assuring data center with Cisco ACI, NAE and Splunk Enterprise",
    "SkillLevel": "Intermediate",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": "Asha Hedge , Cisco Systems",
    "Industry": "Not industry specific",
    "Description": "Do you spend most of your valuable time analyzing and troubleshooting connectivity or performance issues in your data center? Did you wish your networks were smarter in alerting you about potential issues before it actually impacts your SLA? Join us to learn how Cisco ACI, NAE(Network Assurance Engine) & Splunk can help you achieve this goal. Cisco ACI, the industry-leading SDN solution, enables scalable multi-cloud networks with a consistent policy model, and gain the flexibility to move applications seamlessly to any location or any cloud while maintaining security and high availability. Cisco NAE uses mathematical models to continuously verify that policy implemented in your data center is inline with the intent. Splunk Apps for ACI, NAE bring health/performance metrics, faults and policy deviations together to help you accelerate your root cause analysis, thereby improving the operational efficiency of your data center. Session covers use cases and demo of these Cisco Data Center Networking product integrations with Splunk Enterprise.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2199.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2199.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2579 - Data Models- Bridging the Knowledge Gap to Work with Complex Data ‚Ä¶ Even Mainframe Data! ",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Ian Hartley , Technology Architect, Syncsort",
    "Industry": "Not industry specific",
    "Description": "Do you have complex or obscure data?  Do users, without the necessary domain knowledge, struggle to work with this data?  Perhaps a Data Model can help bridge the knowledge gap.  This session will use valuable (but complex‚Ä¶and even scary) mainframe metrics as a working example of how to get users up and running fast by leveraging the power of a data model.  But, these principles are not just for mainframe.  They can equally apply to other data types and scenarios.  Not all users are well-versed in complex data structures and fields, but some are‚Ä¶so combine Subject Matter Expert (SME) knowledge with this great Splunk facility to make everyone‚Äôs life simpler.  Deliver real results in a very short time with little overhead or burden on users.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IT2579.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2579.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2583 - Moving Towards an Advanced Fusion Center",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Cloud", "Splunk Enterprise Security"],
    "Speakers": "Lesly White , Sr. Director, Cyber Operations SIEM and Sensor, Optiv",
    "Industry": "Not industry specific",
    "Description": "Transform your SOC into a Cyber Fusion Center. Learn how to address alert fatigue and cut down on missed alerts by implementing AI technology in your SOC.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2583.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2583.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2617 - Integrating with improved visibility and insight - with IBM Z in your hybrid multicloud",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": [
      "Dan Wiegand , Senior Offering Manager, IBM",
      "Tony Papageorgiou , Offering Manager for API Enablement on IBM Z, IBM"
    ],
    "Industry": "Not industry specific",
    "Description": "IBM Z continues to be the cornerstone of the global economy powering the world's largest banks, retailers, airlines and insurance companies.¬†¬†¬†With the adoption of hybrid multicloud a reality for today's fast moving businesses, the mainframe is no longer isolated from the rest of the IT infrastructure and is now an integral part of your cloud strategy.¬†¬† As you expose and integrate your data and applications through APIs and look to gain further insight, any lack of visibility impacts your business's ability to deliver key services¬†.¬† Learn how IBM is not only providing access to the volumes of IBM Z machine data but is also providing valuable insight into that data to both operations and¬† lines of business.¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2617.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2617.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2633 - Operational Efficiencies with Splunk SmartStore",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Somu Rajarathinam , Pure Storage",
    "Industry": "Not industry specific",
    "Description": "Splunk SmartStore not only reduces the storage requirements for the aged data by maintaining only one copy of the data across the indexer cluster but significantly improves the operational aspects of the indexer cluster be it recovery from node failures or data rebalancing activities.  In this session, the speaker will go over the operational efficiency tests performed on traditional and SmartStore indexes and review the results.  ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2633.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2633.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2634 - Performance and scale testing of Splunk Enterprise",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Somu Rajarathinam , Pure Storage",
    "Industry": "Not industry specific",
    "Description": " What if you can scale test your Splunk Enterprise with multi-terabyte of data ingest followed by concurrent search tests on the loaded data?  Attend this session to learn more about the framework for multi-terabyte data generation and multi-user search tests on Splunk Enterprise 7.2+.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2634.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2634.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2726 - Splunk SAP ‚Äì Be the Hero",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Brant Hubbard , CEO, RHONDOS",
    "Industry": "Not industry specific",
    "Description": "Be the Hero by bringing in your organization‚Äôs most important system into the world of Splunk! Join the team from RHONDOS as they show off real world use cases of how clients have leveraged SAP PowerConnect for Splunk to create a paradigm shift when it comes to monitoring SAP. Learn how to gain real-time visibility into system performance, monitor mission critical data flows and improve the security posture of your organization‚Äôs SAP environments.n  ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2726.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2726.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2752 - Tame the Beast of IT Complexity- AI, ML, & Automation Are the Answer",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Rob Kelsall , VP, Global Sales Engineering, Resolve Systems",
    "Industry": "Not industry specific",
    "Description": "Are you drowning in a sea of data that expands daily? Overwhelmed by 1000s of events and alarms? Tasked with tracking a dynamic, ever-morphing infrastructure? Expected to resolve requests, incidents, and performance issues in seconds, not days‚Ä¶ without adding any more headcount to your team? You‚Äôre not alone.n n Enter Automation, AIOps, and machine learning (ML). It‚Äôs finally IT‚Äôs turn to harness these powerful technologies to improve operational efficiency, reduce MTTR, eliminate alarm noise, streamline service requests, increase performance without lifting a finger, and tame the beast of IT complexity.¬†n n Join our session as we explore practical applications for these technologies today and in the future to transform the way you approach IT operations. Get real world examples from other IT professionals and see how you can maximize your investments in Splunk, ITSM, monitoring tools, and more by bringing AI, ML, and automation to the mix.‚Äãn ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2752.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2752.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2796 - Harnessing AIOps for a Retailer‚Äôs Digital Transformation at Pace and Scale Using ITSI",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Enterprise", "Splunk IT Service Intelligence"],
    "Speakers": [
      "Michael Isherwood , Technology Delivery Lead Associate Director , Accenture Federal Services",
      "Oli Figus , Technology Strategy Consultant, Accenture"
    ],
    "Industry": "Not industry specific",
    "Description": "How can a rapidly-innovating retailer match the pace of delivery with comprehensive alerting? And how can support teams visualise complex end-to-end flows in a microservice architecture? In partnership with Accenture, our clients implement Splunk to match innovation with world-class monitoring and analytics. Our clients innovate to change the way they deliver systems using 100% Agile delivery, configuring leading software on a private 'platform as a service'. We will demonstrate how one can address the challenges of pace and scale by focusing on tight integration and configuration of increasingly complex AIOps ecosystems.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2796.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "ITS2895 - Splunk Apps for Infrastructure from Dell EMC",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": "Splunk Enterprise",
    "Speakers": "Kyle Prins , Senior Systems Engineer , Dell",
    "Industry": "Not industry specific",
    "Description": "Monitoring infrastructure operations is easy with Splunk, but it takes more than great SPL skills to build and end to end view of infrastructure supporting your mission critical applications.  In this session, you'll hear from an experienced Site Reliability Engineer how Dell EMC's investment in Splunk apps across their platforms makes it easier for Splunk users to monitor infrastructure and integrate these these insights into an overall application performance monitoring strategy.  ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS2895.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/ITS2895.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "ITS3009 - Leveraging the AWS ISV Workload Migration Program to Migrate your Splunk Workloads to Cloud ",
    "SkillLevel": "Good for all skill levels",
    "Track": ["IT Operations", "IT Ops"],
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Guy Farber , Global Manager, ISV Workload Migration Program, Amazon",
    "Industry": "Not industry specific",
    "Description": "In this session, you will learn how AWS and Splunk have come together to help accelerate your Cloud migration. Splunk Cloud delivers a secure, reliable and scalable service, enabling you to get answers from your machine data without the need to purchase, manage and deploy additional infrastructure. Splunk on AWS enables you to bring your current license and run Splunk in a scalable and secure way on the AWS Cloud. n n The AWS ISV Workload Migration Program (WMP) helps accelerate both customer migration paths of Splunk workloads to AWS, by creating a repeatable migration methodology, coupled with incentives to lower the overall cost of migration.n  ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/ITS3009.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1066 - Industrial Cyber Security In A Converging IT-OT World",
    "SkillLevel": "Advanced",
    "Track": ["Internet of Things", "IoT"],
    "Products": ["Splunk Enterprise Security", "Splunk for Industrial IoT"],
    "Speakers": "Michael Rothschild , Indegy",
    "Industry": "Manufacturing",
    "Description": "The digital convergence of IT and OT infrastructures promises huge efficiencies, cost savings and opportunities; but it is not without risk. OT was primarily built to run all types of manufacturing & critical infrastructure processes while IT was built to store, transmit and manipulate data in order to conduct business. The two worlds could not be more different in purpose or design; and this can expose even the most secure organizations to new types of cyber threats. In this session we will discuss the current challenges we face in the drive to convergence and how to secure your industrial or critical infrastructure organization from the clear and present threat.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1066.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1066.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1103 - Applying Splunk Essentials for Predictive Maintenance",
    "SkillLevel": "Intermediate",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Young Cho , Senior IoT Practitioner, Splunk",
    "Industry": "Not industry specific",
    "Description": "Predictive maintenance is a key initiative and a strategy that directly impacts the bottom lines of many industrial operations around the globe. Yet many of the organizations don‚Äôt know where and how to start due to a lack of knowledge about data platforms, methodology, and analytics techniques. Based on the recently released 'Splunk Essentials for Predictive Maintenance' app that offers key methodologies and Splunk‚Äôs powerful machine learning capability, this session will demystify the data science elements of predictive maintenance to make the process real and pragmatic. Through this session, the audience will learn and appreciate the power of Splunk in a way that will allow agile application of analytic-driven predictive maintenance to the broader moving parts of their operations. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT1103.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1103.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1318 - Maintaining a state of good repair with predictive analytics",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Tony Nesavich , Staff Sales Engineer, Splunk",
    "Industry": ["Energy & Utilities", "Oil & Gas", "Public Sector"],
    "Description": "Take a deep dive in this enablement focused presentation where we cover the background, data and how to implement 3 Splunk solutions entirely captured in this sessions' companion app that shows how to use Splunk for maintaining a state of good repair, make data-driven decisions to garner rate payer confidence and proactively realize conservation goals. ¬†The use cases covered in this session are: *** Corrosion Analytics - See how to use machine learning combined with ArcGIS, Maximo and Corrosion data to create an interactive map to predict pipe failures and replacement priorities based on proximity to sensitive infrastructure. *** Mobile Work Fleet - see how to use scripted inputs to develop asset management dashboards, make data driven purchasing decisions and optimize routes. *** Water Leak detection - see how Splunk's Machine Learning Toolkit can be used to easily detect anomalous consumption based on user behavior and automate alerting utilities and customers to prevent water waste.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1318.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1318.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1401 - Splunk for Good, Seattle University, and University of Connecticut partner to Power Aquaponics Facilities Around the Globe",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": ["Splunk Enterprise", "Splunk Mobile"],
    "Speakers": [
      "Hunter Mason , Electrical Engineering Student, Seattle University",
      "Ryan O'Connor , Senior Advisory Engineer, Splunk"
    ],
    "Industry": ["Higher Education", "Non-Profit"],
    "Description": "Wouldn‚Äôt you love to be able to give students at your university some hands-on experience with Splunk so they have a tangible skill to add to their resume when they‚Äôre looking for jobs? What if we told you that two universities on opposite sides of the United States have partnered with Splunk4Good and Splunk Mobile and done just that. The University of Connecticut and Seattle University are working together on sustainability efforts at aquaponics facilities around the globe and collecting data from them. During this talk you will learn some useful tools, tips, and tricks for how they got there, and how you can get your university enabled with Splunk4Good. Finally, we‚Äôll talk about what you can do to teach students about Splunk and sustainability, and why that‚Äôs so important in 2019.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1401.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1401.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1410 - Add value to your SIEM- how Israel's Ministry of Energy applies Machine Learning to protect their Critical Infrastructure and OT Operations",
    "SkillLevel": "Intermediate",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Eurus Kim , Staff ML Architect, Splunk",
      "Philipp Drieger , Staff Machine Learning Architect , Splunk"
    ],
    "Industry": "Public Sector",
    "Description": "Critical OT Infrastructure is a potential target for cyberattacks that can affect national security. Therefore the Ministry of Energy of the State of Israel implemented an advanced security strategy to protect all power plants in the country. By monitoring all their decentralized SIEM systems and SCADA events from power plant operations they get a comprehensive view of their nationwide security posture in energy supply. Due to highly heterogeneous SIEM landscapes they normalize those with Splunk's CIM and leverage machine learning based approaches on this data to get an edge over manual hand written rules. With the help of Splunk's Machine Learning Toolkit (MLTK) they can not only iterate faster on their use cases but also get immediate outcomes that help their security operations. In this session you learn in detail how they approached anomaly detection use case and their journey with MLTK to get practical insights.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1410.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1413 - A healthcare company changing lives with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Shelby Neal , VP of Information Technology, Accuhealth Technologies LLC",
      "Stephen Samson , CEO, Accuhealth Technologies LLC"
    ],
    "Industry": "Healthcare",
    "Description": "This session is about a healthcare company born from cybersecurity using Splunk to disrupt the traditional healthcare delivery model. Accuhealth has created a remote patient monitoring platform to analyze health and biometric data collected from IoT devices to improve the patients' quality of life. A doctor is alerted in real-time of any abnormal changes to their patient's vitals and have immediate access to medical trends, allowing the doctor to make faster and more informed decisions. Splunk is at the nerve center of our platform. Using machine learning and health data, the tool provides actionable insights and predictive analysis to patients, doctors, caregivers, and researchers. Additionally, we have leveraged Splunk to integrate the three pillars of telehealth: Telemedicine, Chronic Care Management, and Remote Patient Monitoring. Learn first hand and see a demo of how Accuhealth is creating a paradigm shift in healthcare. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT1413.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1413.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1442 - Real-time public transport information systems monitoring and analysis in the city of Amsterdam ",
    "SkillLevel": "Intermediate",
    "Track": ["Internet of Things", "IoT"],
    "Products": ["Splunk Enterprise", "Splunk for Industrial IoT"],
    "Speakers": "Simon Ric - Hansen , Data Analyst, DITP",
    "Industry": ["Non-Profit", "Public Sector"],
    "Description": "With around a million people interacting with the public transport in and around the city of Amsterdam daily, supplying accurate travel information is critical for an efficient and well-informed public transportation experience. With four different transport types (boat, bus, tram, and metro) and a host of custom systems creating around 4.5 million update events per day, analyzing this travel information depends on everything working seamlessly together. To provide accurate and trustworthy real-time passenger information services, monitoring of not only information availability but quality is needed. This use case shows how Splunk was implemented to monitor the data streams at all points in the information chain, and how real-time insights and alerting allows for proactive problem resolution and provides high-quality real-time information services for the end-user.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1442.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1442.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1509 - Building the 'smartest factory on planet earth' ‚Äì Accenture partnering with leading crystal maker innovating with Splunk for Industrial IoT",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit",
      "Splunk for Industrial IoT"
    ],
    "Speakers": [
      "Ron Perzul , Senior Sales Engineer, Splunk",
      "Stefan Schroder , Managing Director, Accenture"
    ],
    "Industry": "Manufacturing",
    "Description": "Production of crystal and gemstones requires high-class, top-quality output and unmatched quality and accuracy in the E2E production line. Based on in-depth experience, our joint client is one of the leading providers of production line machinery, serving its own business units as well as industry customers with precision optical instruments, grinding, sawing, drilling, and dressing tools. The new technical innovations in the area of Industrial Internet of Things (IIoT) offer completely new options to improve smart production lines. Thus Accenture is partnering with Splunk on creating a roadmap to build a fully digital, smart factory that will become a world-leading lighthouse facility. This session will provide insights into how the power of data enabled by Splunk can realize a quantum step in modern production line environments. It also will help you understand the value of data science for predictive quality, digital twin scenarios, reduced lot size, and closed loop R&D processes. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT1509.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1509.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1560 - Teaching Splunk to Hear- Audio Spectrum Analysis in Splunk for Event Classification and Anomaly Detection",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Joshua Marsh , Senior Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "If we hear a nearby gunshot, we instinctively react. A mechanic often knows their machine's sound so well that they can diagnose issues by sound alone. While machines can be given analytical capabilities with machine learning (ML), sensing human inputs - like auditory or other sensory data - in a form that machines can understand is challenging. In Splunk, we have been all about making machine data accessible to humans, but what if we flip that and make human data accessible to machines? I take audio captured from live and recorded sources and using Fast Fourier transform feed it into Splunk's Machine Learning Toolkit (MLTK) for classification and anomaly detection. Can we use Splunk to detect gunshots? Can we learn a machine‚Äôs normal sounds to detect pending failures? This presentation uses Splunk to apply superhuman ML detection and learning capabilities to human data to show that the MLTK contains accessible tools you can apply to your IT and security problems. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT1560.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1560.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1603 - Splunk electrified- Building a modular application for the new Porsche Taycan",
    "SkillLevel": "Intermediate",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Tim Klapper , Service Manager Splunk, Porsche  ",
      "Tobi Schug , Senior Software Engineer, Porsche"
    ],
    "Industry": "Manufacturing",
    "Description": "Twenty years ago, IT was seen as a cost center. Ten years ago it was a business enabler. Today we see IT as a fundamental part of Porsche‚Äôs strategy to build the sports car of the future. Our approach with Splunk also has changed. Machine data is no longer seen as an afterthought. We partnered with the business, we understood their needs, we learned to speak their language, and we incorporated Splunk from the beginning. And it's not limited to cars. IT is included across the full digital journey of our customers. We will give you insights into the digitalization of the new Porsche Taycan, Porsche‚Äôs first all-electrically powered four-seat sports car which will be introduced in September 2019. We will share best practices as to how we mastered being heard within various business units, overcame legal challenges , and showcase an example of our digitalized charging infrastructure which analyzes the right data for monitoring as well as predicting performance and forecasting demands. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1603.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1621 - Improving the asset reliability for manufacturing the world‚Äôs most advanced fighter jet, Lockheed Martin‚Äôs F-35 Lightning II with Splunk for Industrial IoT",
    "SkillLevel": "Good for all skill levels",
    "Track": "Internet of Things",
    "Products": "Splunk for Industrial IoT",
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1621.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1621.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1629 - Deep Dive- How to use Splunk to protect the environment",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Charlie Studdard , Machine Data Analytics, Honda Manufacturing of Alabama",
    "Industry": ["Manufacturing", "Non-Profit"],
    "Description": "Can Splunk help eliminate environmental risks and save the company money at the same time? The Alabama Department of Environmental Management (ADEM) sets standards defining the amount of Volatile Organic Compounds (VOCs) that can be safely released. Honda Manufacturing of Alabama (HMA) must adhere to those standards and track our compliance within the parameters set forth by the ADEM. Failure to comply with these standards will result in potentially damaging the environment and large fines. HMA uses a Regenerative Thermal Oven (RTO) to burn off pollutants from our paint department, which is controlled by an Allen Bradley Programmable Logic Controller (PLC). Using this PLC and the sensors built into the RTO, we collect individual chamber temperatures, fan speeds, exhaust temperatures, motor winding temperatures, motor vibrations, and fan vibrations. Using these readings and the Splunk Machine Learning Toolkit we try to predict if the temperature will be within the set range. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1629.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1629.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1632 - Gatwick Airport- From Road to Runway, how we embarked more users on Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Alex Webber , IT development Specialist, Gatwick Airport Ltd",
      "Paul Bannister  , IT Development Specialist, Gatwick Airport Ltd"
    ],
    "Industry": "Travel & Transportation",
    "Description": "Gatwick Airport has become a name synonymous with Splunk, and since we first embraced the world of Splunking there has been no slowing down with our innovative ways of using every data feed and technique available to gain insightful business analytics to improve operation. Join us as we take you through our new and exciting use cases. We will show you how we provide our key operations, from road to runway, with all the data insights they could ever need, adding key resilience to existing systems and combining our Cloud and Enterprise environments. All while we are utilizing inventive CSS techniques to give the impression of bespoke individual systems. We are getting more end users onto the Splunk platform without them even realizing their using Splunk at all.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1632.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1632.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1641 - Threat Hunting in Industrial (ICS-OT) Environments",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": ["Splunk Enterprise Security", "Splunk for Industrial IoT"],
    "Speakers": [
      "Amy Bejtlich , Threat Intelligence, Dragos",
      "Marc  Seitz , Threat Analyst, Dragos"
    ],
    "Industry": "Not industry specific",
    "Description": "Industrial operations comprise a diverse blend of technology that run critical processes. The proliferation of automation and networking has increased the sophistication of Industrial Control Systems (ICS), also known as Operational Technology (OT) environments.n Threats targeting OT are increasing in both frequency and sophistication. Dragos tracks 9 OT-targeting activity groups, the most significant of which, XENOTIME, was responsible for the TRISIS malware that targeted safety systems (SIS) resulting in multiple plant shutdowns and the potential to cause harm to human operators.n Traditional IT threat hunting is not well-suited to OT environments. This session will outline the differences between IT and OT assessments, highlight the most significant threats facing OT, and review best practices for OT-specific threat hunting engagements, including techniques that empower defenders to detect and respond more efficiently to existing and future threats, therefore reducing adversary dwell time.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1641.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1641.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1830 - How to boost operational readiness and situational awareness for law enforcement ",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Bobby Suber , Sales Engineer, Splunk",
      "Herschel  Sova , Director of Managed Services, GTS Technology Solutions"
    ],
    "Industry": ["Non-Profit", "Public Sector"],
    "Description": "Can law enforcement protect citizens in this age of digital transformation? Are they using technology in way that promotes insights and outcomes to help them become more proactive? Do those insights provide officers with increased situational awareness to ensure officer safety and effectiveness? We‚Äôll show you how the connected vehicle provides data to unlock insights into the operational readiness of the digital officer while also providing improved situational awareness for their safety.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT1830.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1830.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1893 - Improving cost-efficiency of inland cargo shipping within the Port of Hamburg ‚Äì powered by Splunk IoT capabilities",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": "Splunk for Industrial IoT",
    "Speakers": [
      "Henning Brandt , Data Analyst, ESE GmbH",
      "Janina Kropf , Data Analyst, ESE GmbH"
    ],
    "Industry": "Travel & Transportation",
    "Description": "The Port of Hamburg is the main entrance to the German market and the third largest European port by transit volume, passing nearly 9 million containers each year. Although it has witnessed several stages of automation, there is still vast, untapped potential to preserve resources, both economic and ecological. By introducing IoT with Splunk, we move away from the docks and onto the vessels, equipping one tugboat and one inland cargo ship with IoT technology to measure movement and gather data about energy consumption from their 1950s diesel engines. The goal of this PoC environment is to automate the communication between ship and port authority, as well as visualize their field of operation to evenly distribute load and optimize the travel distances. On a broader spectrum, we also built a simulation model within our dashboard to investigate the benefits of adapting the vessels with engines powered to natural gas or electricity based on their consumption patterns.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT1893.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1893.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1897 - Next Generation Smart SOC",
    "SkillLevel": "Advanced",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": [
      "Eman Alawadhi , VP Cyber Security and Resilience , Expo 2020",
      "Eric Eifert , DarkMatter"
    ],
    "Industry": "Communications",
    "Description": "The mega event Expo brings together ideas, innovations, and inventions is will open its doors in the UAE on 20 October 2020 for a period of six months. This celebration of human ingenuity offers a glimpse into the future and is anticipated to attract 25 million visits, 70 percent of those visitors from 190 countries. The Expo 2020 Dubai is teaming up with the DarkMatter Group, which is the region‚Äôs first and only fully-integrated digital transformation, defense, and cybersecurity solutions provider, to fully deploy advanced cybersecurity technologies to oversee the entire digital platform, as well as the applications and data to secure the Expo 2020‚Äôs digital experience. This session will cover why Expo 2020 and DarkMatter chose Splunk as the right solution to reduce their operational requirements to single solution that is able to ingest and analyze events from every single asset (IT&IoT) supported by the automation frameworks in the solution.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT1897.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1897.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1935 - Splunk like your life depends on it",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": "Splunk for Industrial IoT",
    "Speakers": "Katie Brown , Senior Solutions Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Many of the talks at .conf will be around how to solve business problems, how to configure clusters, and how to improve your KPIs. This talk focuses instead on how to monitor and detect problems in the physical realm: IoT. What do you do when an agency's or business's security posture is a matter of life and death? What are they doing to equip themselves against cyberattacks? This talk will discuss previous security breaches and industrial IoT device failures that result in death, and how they could have been detected or prevented with Splunk. It also will give you actionable takeaway's for you to implement. After all, security isn't always saving dollars; sometimes it is actually about saving lives.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1935.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1935.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT1937 - Splunk at the Speed of Flight ‚Äì Delivering Critical Passenger Cabin Services ",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "Splunk Enterprise",
      "Splunk IT Service Intelligence",
      "Splunk for Industrial IoT"
    ],
    "Speakers": [
      "Bill Babilon , USAF Account Executive and Splunk Solutions Architect, Splunk",
      "Paul Jeffery , Senior Sales Engineer, Splunk",
      "Q Damiano , Sr. Engineer, Systems Architecture, Satcom Direct"
    ],
    "Industry": "Travel & Transportation",
    "Description": "Business General Aviation (BGA) relies on multiple critical communications services, operating in flawless concert, for a safe and successful flight. ¬†In-Flight Connectivity (IFC) is a critical BGA cabin service driving the industry. Learn how SatCom Direct is using Splunk to capture and cross-correlate live KPI feeds from various sources such as aircraft flight dynamics, satellites and ground stations to provide the ultimate in-air experience from a single aircraft to an entire managed fleet. Armed with Splunk, Satcom Direct can immediately detect and work to restore any service impacting events and from the same data, develop improved insights for ongoing performance enhancements. From the executive suite to the operations battleground, come learn how Splunk leverages data and insights at the speed of flight.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT1937.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT1937.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2020 - Image indexing framework for image search and deep learning applications ",
    "SkillLevel": "Intermediate",
    "Track": "Internet of Things",
    "Products": ["Splunk Enterprise", "Splunk for Industrial IoT"],
    "Industry": "Manufacturing"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2026 - Solar Analytics- Changing the World One Solar Panel At A Time",
    "SkillLevel": "Intermediate",
    "Track": ["Internet of Things", "IoT"],
    "Products": ["Splunk Enterprise", "Splunk for Industrial IoT"],
    "Speakers": "Dean Jackson , Staff Sales Engineer, Splunk",
    "Industry": ["Energy & Utilities", "Non-Profit"],
    "Description": "Solar generation and energy storage is dramatically dropping in cost and is being deployed on a massive scale across the globe. However, system monitoring and diagnostics, cost reporting, and usage can be difficult. With Splunk Essentials for ICS (Industrial Control Systems) and Splunk IAI (Industrial Asset Intelligence), a smart energy solution easily can be created. Does it seem too hard to onboard data? See how we use the Splunk add-on builder to create technology add-ons for solar panels and batteries. Want better visibility? Using Splunk IAI, we can gain faster insights into the performance of solar panels, inverters, and battery systems. Want to understand the economics? By applying business analytics, we can easily report of revenue, costs, and total return on investment. This solution can be applied to both small and large solar and energy storage installations, and we have a real world use case with some exciting energy data!n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT2026.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT2026.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2038 - Splunk Cloud Gateway and Connected Experiences",
    "SkillLevel": "Beginner",
    "Track": ["Internet of Things", "IoT"],
    "Products": "Splunk Enterprise",
    "Speakers": "Andy Shaffer , Test Coordinator, Battelle",
    "Industry": "Aerospace & Defense",
    "Description": "At PCAPP we use Splunk Cloud Gateway and the Connected Experiences Suite to help operators, supervisors, and managers ensure safe, compliant destruction of chemical weapons.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT2038.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT2038.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2066 - The most epic road trip to .Conf- IOT in an RV, OMG",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "Splunk Enterprise",
      "Splunk On-Call",
      "Splunk for Industrial IoT",
      "VictorOps"
    ],
    "Speakers": [
      "Brett Roberts , Senior Systems Engineer, Dell",
      "Kyle Prins , Senior Systems Engineer , Dell"
    ],
    "Industry": "Not industry specific",
    "Description": "Splunk .conf is our favorite event every year and we wanted to extend the excitement while getting even more Splunky. So we grabbed an RV, set up some sensors, built an edge computing environment, and packed up the Big Data Beard recording equipment for a road-trip across the country for the week leading up to .conf, traveling from New York City to Las Vegas. We stopped along the way to hear awesome stories from fellow Splunk users, sharing them online via live chats and podcasts. With the power of Splunk, we captured data, discovered trends, predicted failures, and discovered more exciting ways to use Splunk to drive value from machine-generated data across the country. Hear the full story of how three engineers had the most interesting trip to .conf2019 of all!",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT2066.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT2066.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2128 - ControlWatch- Cybersecurity Monitoring for Operational Technology (OT) and Industrial Control System (ICS) Environments",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": "Splunk Enterprise",
    "Speakers": "Chris Weule , Booz Allen Hamilton",
    "Industry": "Manufacturing",
    "Description": "Today‚Äôs industrial, manufacturing, and building management systems rely on an array of on-demand, uninterruptable technologies, like Industrial Control Systems (ICS), for their day-to-day operations. Escalations in cyber-related attacks have made increased visibility into these often overlooked systems paramount. Over the past year, Booz Allen has built an OT cybersecurity monitoring solution called ControlWatch that provides enhanced visibility and anomaly detection with a focus on OT environments. By aggregating data from within and around the process, the solution provides a critical view for plant managers, C-level decision-makers, or the boots on the ground. We‚Äôll highlight the context into, detection of, and alerting on a myriad of malicious and misaligned activities. We have implemented unique OT-centric use cases and will walk-through a day-in-the-life scenario to show you how the solution increases cybersecurity awareness and resilience in a production organization at all levels.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT2128.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT2128.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2134 - Innovation, Automation, and Orchestration for Collaboration Technology with Splunk",
    "SkillLevel": "Intermediate",
    "Track": ["Internet of Things", "IoT"],
    "Products": [
      "Splunk Enterprise",
      "Splunk Mobile",
      "Splunk for Industrial IoT"
    ],
    "Speakers": "Chris Ramsay , IT Facilities Engineer , Puget Sound Energy",
    "Industry": "Not industry specific",
    "Description": "AV and conference technology may seem trivial to the traditional IT OPS engineer, but it is one of the most visible and expensive parts of an enterprise. Everyone from the CEO to even the new hires on their first day use the technology. At PSE we were able to leverage Splunk to help us build, maintain, and manage our enterprise AV program (and save a lot of money in the process). In this session you will learn how we used Splunk to make data-driven decisions that influence and shape a multi-million dollar AV program.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT2134.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT2134.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2146 - Where the rubber meets the road, an Internet of Things (IoT) and Machine Learning case study",
    "SkillLevel": "Good for all skill levels",
    "Track": "Internet of Things",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit",
      "Splunk for Industrial IoT"
    ],
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2578 - Splunk Fortifies ABB Ability Industrial Cloud Foundation",
    "SkillLevel": "Good for all skill levels",
    "Track": ["Internet of Things", "IoT"],
    "Products": ["Splunk Enterprise", "Splunk for Industrial IoT"],
    "Speakers": "Ravi Prattipati , Chief Architect, ABB Inc",
    "Industry": "Manufacturing",
    "Description": "As one of the world's largest and most trusted industrial brands, our customers demand the most technologically advanced and reliable systems to operate the most critical assets on the planet. Downtime for our customers is never an option. As we migrate our business delivery backbone to the cloud, we have to enforce the same level of reliability and performance on the architecture that supports our services - .9999 is failure where we live. In this presentation learn how ABB Digital and Splunk have collaborated to create new insights into the performance, security and operations of our Azure-backed ABB Digital IOT Platform to protect our brand and increase the velocity of services that we can bring to our internal customers and to those that invest in our ABB branded services.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IoT2578.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT2578.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoT2863 - Energy Insights- Developing an Energy Transformation Framework In Manufacturing with GrayMatter and Splunk at Continental Automotive",
    "Track": ["Internet of Things", "IoT"],
    "Speakers": "Alan Hinchman , Chief Revenue Officer, Gray Matter Systems, LLC",
    "Description": "¬†Intersecting energy asset data with production and operational data opens new doors to better visibility, energy savings and meeting green standards. In this session you‚Äôll learn how Continental Automotive eliminated energy waste, reduced costs and lowered emissions levels by breaking down energy consumption and operational data silos on the factory floor.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/IOT2863.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoT2863.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "IoTIOTS2759 - Deployment Models for OT Security",
    "SkillLevel": "Good for all skill levels",
    "Track": "Internet of Things",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Industry": "Energy & Utilities",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/IoTS2759.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1071 - Large Scale Threat Hunting in Splunk",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Ashleigh Moriarty , Lead Technologist, Booz Allen Hamilton",
      "Dan Rossell , Analyst, Booz Allen Hamilton"
    ],
    "Industry": "Not industry specific",
    "Description": "Threat hunting is hard, and threat hunting in an enterprise network with thousands of endpoints is even harder. We will demonstrate how we leveraged Splunk Enterprise to build an Advanced Threat Hunting platform designed for large scale threat hunting of 100,000 or more endpoints. Using Splunk Enterprise allows us to combine analytics, data enrichment, and custom workflows to display in one platform the most important data to analysts. Our threat hunting platform addresses the challenges of data retention and collection, high false positive rates, and analyst fatigue, all while lowering the time to detection of malicious incidents and improving the efficiency of enterprise SOC operations.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1071.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1071.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1104 - Don't Blow Your Budget Fighting Fraud; Orchestrate and Automate Instead",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Cloud", "Splunk Enterprise"],
    "Speakers": [
      "Abhishek Dujari , Security Specialist, APAC, Splunk",
      "Matthew Joseff , Director of Specialists - North Asia and Japan, Splunk"
    ],
    "Industry": ["Financial Services", "Not industry specific"],
    "Description": "Manual sorting through spreadsheets, disparate applications, and scattered data sources to conduct link analysis for a fraud investigation is both painful and ineffective. There must be a better way, right? In this session we'll use Splunk Enterprise and Splunk Phantom to automate repeatable fraud investigation tasks, which will save your team time and better protect your assets from the bad guys.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1104.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1104.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1106 - Using Splunk and DNS to detect that your domains are being abused for phishing",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Arnold Holzel , Senior Security Consultant, SMT",
      "Karl Lovink , Lead Security Operations Center, Dutch Tax and Customs Administration"
    ],
    "Industry": "Not industry specific",
    "Description": "As a high-profile public-sector organization, the Dutch Tax and Customs Administration deals with criminals claiming to be representatives of the organization and contacting the public with phishing e-mails every day. By using Splunk and RFC‚Äôs like, RFC7208 ‚Äì Sender Policy Framework (SPF) for Authorizing Use of Domains in Email, we have developed a technique to identify phishing attacks that are carried out under the disguise of the Dutch Tax and Customs Administration. This technique is universally applicable. A precondition is access to the DNS logging. By means of this technique, insight can be obtained where the phishing e-mails are sent from and to whom the phishing e-mails are sent. In this talk we will start by explaining which standards are available to increase e-mail security and how we have build an app in Splunk, including dashboard and a wizard to create the necessary DNS records to gain insight information about the abuse of our domains.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1106.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1106.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1111 - IOC's- Indicators Of Crap",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Xavier Ashe , VP, Security Engineering, SunTrust Banks",
    "Industry": "Not industry specific",
    "Description": "'You should be looking at Indicators of Compromise!' exclaims your CISO, regulator, vendor, and mom.  No problem, right? You have the most expensive security intelligence vendor and all you have to do is correlate in your expensive SIEM. n n If you've tried this, then you are laughing with me. Come hear my exploration into implementing IOCs at a major US insurance company and a major US bank. I‚Äôll address the differences between Indicators of Compromise vs Indicators of Attack, and I will show you how not to use the MITRE ATT&CK‚Ñ¢ framework, plus some tips on how it use it well.  My goal is to save you from falling into the same pitfalls when dealing with Indicators of Crap.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1111.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1111.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1128 - Automate Your Phishing Response with Splunk Enterprise Security, Splunk Phantom, and Machine Learning",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Benji Arnold , Sr. Security Analyst , JPMorgan Chase",
      "Dennis Rhodes , Sr. Security Analyst, JPMorgan Chase",
      "Mackenzie Kyle , Manager - Cybersecurity Operations Center, JPMorgan Chase"
    ],
    "Industry": "Financial Services",
    "Description": "We developed an automation framework that classifies and mitigates emails reported to the SOC. The framework acts as an engine that consumes multiple data sources, including a supervised machine learning model and a risk scoring algorithm to assess with high confidence if an email is phishing, spam, or benign. We will discuss the benefits of our approach to phishing mitigation, such as enhancing our SOC's ability to automatically identify, prioritize, and mitigate malicious phishing attempts against employees before any damage is done.  The session will outline the overall design of the framework, detail the primary components that are used within Splunk Phantom and Splunk Enterprise Security, and will outline the supervised machine learning model that we trained to aide the automation engine.  ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1128.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1128.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1156 - ATT&CK‚Ñ¢ing Linux with SPL",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Doug Brown , Senior Information Security Analyst, Red Hat",
    "Industry": "Not industry specific",
    "Description": "In this session we will discuss using Splunk to detect a range of Linux-based adversary techniques from MITRE‚Äôs ATT&CK‚Ñ¢ framework. We will also demonstrate how event sequencing can be used to map a path through the ATT&CK‚Ñ¢ matrix and improve overall detection fidelity. We will provide auditd configuration suggestions for Linux endpoints to support greater coverage.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1156.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1156.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1178 - Defend Against Malicious Insiders Using Splunk Enterprise Security, Splunk's Machine Learning Toolkit, and Statistics",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Bryan Thiry , Cyber Intel Analyst Sr, Lockheed Martin",
      "Jason Barnette , Cyber Intel Analyst Sr., Lockheed Martin"
    ],
    "Industry": "Not industry specific",
    "Description": "Identifying insider threats is always difficult, and the challenge grows exponentially as the size of a workforce increases and the diversity of normal employee behavior expands. As a result, analysts must get creative to separate routine from malicious activity. This presentation will detail how Lockheed Martin uses machine learning and anomaly detection to identify insider threats. We'll discuss real-world examples of how we leverage Splunk' Machine Learning Toolkit with Summary Indexes, Lookups, Alerts, and Splunk Enterprise Security. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1178.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1179 - The House Always Wins- Using Splunk Enterprise to Fight Data Exfiltration From Insider Threats",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "David Doyle , Splunk Puncher, Bechtel",
      "Eric Secules , Forensic Investigator, Bechtel"
    ],
    "Industry": "Not industry specific",
    "Description": "What happens when the call is coming from inside the house? Data exfiltration by insiders is a dangerous threat, but one that often doesn't get the same level of attention as the sexier external ones. We'll start this session with a brief overview of why and how users exfiltrate information, and we'll progress to tactics, such as effective SPL searches, for operationalizing insider threat detection. You'll leave this session better able to catch insider threats in the in the act of exfiltration instead of days, weeks, or months later. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1179.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1179.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1205 - Securing a Global Investment Fund Using Splunk Cloud and Splunk Enterprise Security",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Cloud",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Grant Slender , Chief Information Security Officer, QIC",
      "Simon O‚ÄôBrien , Principal Sales Engineer, Splunk"
    ],
    "Industry": "Financial Services",
    "Description": "Join this session to learn the do‚Äôs and dont‚Äôs of rolling an effective cloud security visibility platform for a global organization. We will cover topics such as why we moved away from our previous SIEM provider, deploying and managing a cloud-based SIEM, and effectively using a third party organization to provide tier 1 and 2 event and incident support. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1205.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1205.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1230 - Is it Normal or Suspicious- Detecting Anomalies via Market Basket Analysis",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk User Behavior Analytics",
    "Speakers": [
      "Nancy Jin , Data Scientist, Splunk",
      "Ping Jiang , Sr. Software Engineer in Test, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Detecting abnormal behavior is an important objective in security monitoring, but is extremely challenging as we mostly are expected to detect 'unknown unknowns.' We can, however, use an entity's past behavior to measure how much of what we observe today deviates from normal behavior. In this way we can detect unknown, hidden and insider threats early on to stay ahead of advanced threats. This talk presents a unified, scalable framework for anomaly detection that is built on the frequent itemset mining technique. The premise is that if we can align an event with more frequent patterns observed in history, then the event is unlikely to be an anomaly. By mining through an extensive set of features and feature co-occurrences, the model can accurately capture the normal behaviors. Any new behaviors can then be scored. At which point, any new rare co-occurrences of events can be detected and sent to analysts and SOC teams for rapid investigation.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1230.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1230.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1248 - Advanced Threat Hunting and Anomaly Detection with Splunk UBA",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": "Tom Smit , Staff Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Splunk User Behavior Analytics (UBA) contains the largest library of unsupervised machine learning in the market. In this session we'll show how to analyze data from both cloud and on-premises data sources in both types of deployment (cloud/on-premises) to convey the unique benefits of Splunk UBA. We'll discuss real world examples that showcase the importance of using UBA and all other tools at your disposal for day-to-day threat hunting. Specifically, we'll show how to use Splunk Enterprise, Splunk Enterprise Security, and Splunk UBA together to hunt and detect anomalies that can reveal significant threats. We'll wrap up with best and worst practices from deployments seen throughout the world. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1248.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1248.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1250 - Feed the Beast! Use Splunk to Address APTs At Speed and Scale By Utilizing Endpoint-Centric Threat Hunting Uses Cases ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Jay Novak , Threat Hunt Team Lead, Booz Allen Hamilton",
      "Max Moerles , Cyber Threat Analyst , Booz Allen Hamilton"
    ],
    "Industry": "Not industry specific",
    "Description": "Going beyond basic perimeter defense, Threat Hunting cuts through the noise of endpoint telemetry and anti-virus data to find nation-state level Advanced Persistent Threats (APTs) that hide below the alert threshold. We will demonstrate, through 4 hunt analytic use cases, how to overcome the legacy challenge of relying on Packet Capture (PCAP) data to detect adversaries, highlighting the need to transform Hunt operations by combining Endpoint Detection and Response (EDR) telemetry data with knowledge of APT behavior to find hidden adversaries. This talk will provide a framework for planning and executing hunts, demonstrate why focusing on EDR telemetry data can add additional value over and beyond traditional network data, and how to strengthen hunting through a Purple Team approach.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1250.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1250.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1264 - You replaced IBM QRadar with Splunk Enterprise Security. Now What-",
    "SkillLevel": "Beginner",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Cloud", "Splunk Enterprise Security"],
    "Speakers": [
      "Nick  Ho , Sales Engineer, Splunk",
      "Ross Rutherford , Information Security Engineer, Western Union"
    ],
    "Industry": "Not industry specific",
    "Description": "Never used Splunk before, have no Splunk admins and you‚Äôve just bought Splunk Enterprise Security? That was us, and now we're using Splunk in ways that we could've only dreamed of using IBM QRadar. In this session we‚Äôll share our implementation story, how we worked with Splunk to accelerate our learning curve, and how we went from 0 to 3TB in 3 months with no Splunk admins. We'll also cover how Splunk allows us to onboard data sources that we couldn't with QRadar. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1264.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1264.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1280 - Scary (Spooky-) Fast Intelligence-Based Hunting with Splunk Phantom",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise Security"],
    "Speakers": [
      "Haris Shawl , EY",
      "Robb Mayeski , Security Automation Magician , EY",
      "Will Burger , Security Automation Consultant, EY "
    ],
    "Industry": "Not industry specific",
    "Description": "Organizations today struggle with quickly and consistently applying behavior-based threat intelligence across their security tools. The hours needed to stitch together this information manually leave analysts unprepared to quickly turnaround questions from management about their vulnerability to threats that their management sees in the news. In this session we will demonstrate how to use Splunk Phantom to reduce that time lag by automating your threat hunts. Specifically, we will show you how to use Yet Another Recursive Algorithm (YARA) rules on endpoint and network security tools automatically and simultaneously. We will use a case study to show the benefits achieved from this playbook: better reporting, more robust procedures, faster time to detect malware variants, and generally more efficient and effective threat hunts.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1280.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1280.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1305 - Detect and Mitigate Insider Threats Using Splunk's Machine Learning Toolkit and Splunk Enterprise Security",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Karthik Subramanian , Principal Senior Cybersecurity Engineer, SAIC",
      "Tyler Williams , Cybersecurity Data Analyst, SAIC"
    ],
    "Industry": "Not industry specific",
    "Description": "When is a 20MB email to an external Gmail account dangerous? It all depends on context. Understanding what normal behavior is will reveal whether specific behavior is malicious or ordinary. We‚Äôll walk you through how using Splunk‚Äôs Machine Learning Toolkit and Splunk Enterprise Security together provides actionable insight for analysts to improve security. We'll also detail how we caught insider threats in our environment with these tools. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1305.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1305.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1336 - Using Splunk to Catch Theft Rings",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Logan Foshee , Threat Analyst, Lowe's",
      "Nic Haag , Splunk Professional Services Consultant, Aditum Partners"
    ],
    "Industry": "Retail",
    "Description": "We helped our client use Splunk to disrupt theft rings plaguing its retail stores. We'll present how we took in public wifi data, tracked MAC addresses that appeared in multiple stores, and ultimately created a system in Splunk that alerted in-store loss prevention teams when individuals likely to be involved in theft rings entered the store. We'll go over the steps taken to operationalize our theft deterrence program so that you can adopt it in your organization or modify it to fit your needs.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1336.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1336.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1357 - Klapp-Back at Attackers- Capturing Data in the Wild to Build Tailored Defenses with Splunk Security Analytics",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Bhavin Patel , Security Software Engineer, Splunk",
      "Jose Hernandez , Security Researcher, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Splunk's Security Research Team collects attack data in the wild from across the globe and analyzes new and unusual techniques, tactics, and procedures employed by threat actors. We use this data to help customers build tailored defenses‚Äîdefenses that automatically detect, investigate, and respond to suspicious activities in real time. In this session we will discuss how Splunk security researchers created our own honeypot and data collection framework in response to research demonstrating that honeypots were twice as effective as open-source intelligence feeds at detecting new threats (http://tinyurl.com/y335po8d). We will provide an introduction to honeypots and explain how we architected and built KLAPP-Back, a high-interaction SSH honeypot. We will also discuss how KLAPP-Back helped us build better detection analytics and seed Splunk Enterprise Security, Splunk Phantom, and Splunk User Behavior Analytics use cases with attacker data. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1357.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1357.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1372 - One Size Fits None- Lessons from Implementing Compliance",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Bob Clasen , Computer Engineer, MITRE",
      "Eugene Katz , Splunk Evangelist, MITRE"
    ],
    "Industry": "Aerospace & Defense",
    "Description": "We will share our journey, lessons, and observations from the past year of implementing compliance at the MITRE Corporation. We'll recap our path from initially learning about Defense Federal Acquisition Regulation Supplement (DFARS), also known as NIST 800-171, to complying with it. We'll share insights from the process that may help you in your compliance journey, but we'll also discuss how your journey might be different than ours, as one size never fits all with compliance. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1372.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1372.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1374 - Augment Your Security Monitoring Use Cases with Splunk's Machine Learning Toolkit",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Oliver Kollenberg , Security Consultant, Siemens",
      "Philipp Drieger , Staff Machine Learning Architect , Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Do you want to use machine learning to enhance your datacenter security monitoring, but you don‚Äôt know where to start? Then this is the talk for you. Come learn how high secure datacenter operations benefit from operationalizing machine learning. With the help of the Splunk's Machine Learning Toolkit, your security analysts can take different approaches to use case creation and gain new insight into what's going on in your environment. We'll detail the challenges, benefits and use cases of using machine learning for datacenter security monitoring, and we'll answer questions such as: Where does it make sense to apply machine learning, and where should we stick with classic searches? Can we detect meaningful anomalies in system behavior? Is it possible to cluster our account activities and find unusual patterns? This is a practical session of security monitoring use cases, deep diving into the ideas, concepts and the SPL behind them.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1374.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1374.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1375 - Use Red Team Exercises to Build Alerts, Train Staff, and Drive Policies",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Adam Parsons , Sr. Detection & Response Engineer, L3Harris Technologies",
      "Nate Piquette , Sr. Detection & Response Engineer, L3Harris Technologies"
    ],
    "Industry": "Not industry specific",
    "Description": "Most of us have had (or still have) nightmares about an alert that someone's exfltrating data from our organization. We've lived that nightmare at Harris, and we've learned from it. In this session, we'll discuss how we used red and purple teaming to improve our security posture post-breach. Learn from our experience so that you can strengthen your team's alerting, staff comptency, and policies, and reduce the risk of a breach at your company.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1375.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1375.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1391 - Building a Security Monitoring Strategy 2.0",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Phantom",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Paul Davilar , Security Consultant, Splunk",
      "Paul Pelletier , Sr. Security Consultant, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "So you have a SIEM with security data, e.g. firewalls, proxy, endpoint data, etc. Now what? How do you effectively operationalize your investment? This session provides recipes, principles, patterns, and strategies for using Splunk and data-driven analytics to move your security monitoring and compliance effectiveness up the maturity curve. This session will cover how to identify key mixes of data sources, core OOTB content to use, and how to layer capabilities aligned with your maturity. We will help you go beyond the endless alerts and investigations and start creating value by reducing the impact of potential security events. We're excited to show you that there's no need for a PhD in security assurance and operations‚Äîjust Splunk and a solid plan.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1391.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1391.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1411 - Supercharge Your Security Operations Center with Splunk and MITRE",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Business Flow", "Splunk Enterprise"],
    "Speakers": [
      "Christian Heger , SOC Architect / Technical Head of SOC & Analyst, DATEV eG",
      "Sebastian Schmerl , Head of Cyber Defense, Computacenter"
    ],
    "Industry": "Financial Services",
    "Description": "DATEV provides information services to ~2.5 million payrolling, accounting, and tax clients. Given the sensitivity of the personal and financial data that our clients process, DATAEV decided to establish a SOC to secure our clients' information, and we put Splunk at the core of its operations. In this session we will discuss four key elements relevant to building a successful SOC with Splunk. We'll first discuss how we formed our SOC and orchestrated its activities internally. We'll then discuss how we use MITRE's ATT&CK‚Ñ¢ framework to prioritize activities, how we spread our SOC's security knowledge to all relevant groups at DATEV, and how we use Splunk to create real-time situational awareness for different SOC customers, for stakeholders, and for management.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1411.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1411.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1432 - Down in the Weeds, Up in the Cloud- Security",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Enterprise Security"
    ],
    "Speakers": "Ry Lait , Senior Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "This is one of multiple sessions in a series at .conf this year focused on getting valuable intel and insights from your Azure and Office 365 environments. Throw on your hoodie and join Ryan as we Splunk our way through all things Azure, Office365, security, compliance, and visibility in the Microsoft-as-a-Service world.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1432.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1432.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1446 - Build Automated Decisions for Incident Response with Splunk Phantom",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise"],
    "Speakers": "Mark Cooke , Staff Incident Responder, GE",
    "Industry": "Not industry specific",
    "Description": "Incident response (IR) analysts are required to make multiple decisions on every alert and incident. Whether the decision is to escalate, respond, or to discard the alert, each one of those decisions is critical to protecting their environment. With the integration of SOAR platforms like Splunk Phantom into IR teams, many of those decisions can now be automated for analysts. These decisions can save hours of work for analysts and allow for focus on more critical alerts. However, there are still questions to answer before implementing these decisions. What data is needed to make confident decisions? Where in the process should these decisions be made? How can existing decisions be improved? How should new decisions be integrated? The General Electric IR team has worked to answer these questions by using Splunk Enterprise and Splunk Phantom. In this session, we will show how our team approached these questions, implemented solutions, and integrated decisions for our analysts to save time and focus their efforts.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1446.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1446.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1479 - Automate Forensic Investigations in AWS with Splunk",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Alina Dejeu , Incident Responder, GE ",
      "David Rutstein , Principal Analyst, GE"
    ],
    "Industry": "Technology",
    "Description": "Alerts in cloud environments require your team to quickly and precisely gather evidence and isolate affected environments. The GE Digital Predix Incident Response (IR) team found an abundance of content for analyzing forensic evidence from Windows environments, but they noticed a gap in content built for performing investigations on Linux-based hosts. The Predix IR team¬†will discuss the tools they¬†have built to contain a¬†compromised Linux-based hosts, gather evidence, and analyze that evidence in Splunk. Utilizing splunk searches, lookups, and visualization components¬†to look both narrowly into the data set as well as broadly across the rest of the¬†environmental data in splunk to identify known bad or potentially suspicious activities that may warrant¬†further investigation by an analyst.¬†n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1479.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1479.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1490 - Lessons Learned from Deploying Splunk UBA",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["AI/ML", "Splunk User Behavior Analytics"],
    "Speakers": [
      "Maria Sanchez , Technical Support Engineer, User Behavioral Analytics (UBA), Splunk",
      "Teresa Chila , Data Scientist, Chevron"
    ],
    "Industry": "Technology",
    "Description": "Splunk User Behavioral Analytics (UBA) is a machine learning driven solution that helps organizations find hidden threats and anomalous behavior across users, devices, and applications. In this session we'll answer questions that came up during our large-scale deployment such as, once you've got UBA installed, how do you know if it is working well in your environment? And how long after installation does it take for the system to be operational and produce results? We'll also share best practices for validating outputs and tuning the system. This session will help you jumpstart your understanding of UBA and help you get your UBA deployment into production and detecting threats faster. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1490.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1490.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1500 - Accelerating Cloud Migration with Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Industry": "Financial Services"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1506 - Our Splunk Phantom Journey- Implementation, Lessons Learned, and Playbook Walkthroughs",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise"],
    "Speakers": [
      "Chris Hanlen , Lead Cyber Security Specialist, NAB",
      "John Murphy , Security Analyst, NAB"
    ],
    "Industry": "Not industry specific",
    "Description": "Learn from our experience implementing Splunk Phantom so that you can speed up your automation journey.  We'll examine key decisions we made with our implementation and the good and the bad that resulted. We'll also cover our automation efforts in event triage, incident response and everything in between, with walkthroughs of our top playbooks. Additionally, we'll present how we tackled Splunk alert ingestion and what Phantom could look like in a cloud-first deployment.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1506.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1506.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1511 - Zero to Hero- A 202-Year-Old Firm‚Äôs Journey to End-to-End Security Visibility",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Cloud", "Splunk Enterprise Security"],
    "Speakers": [
      "Craig Gilliver , Head Of SecOps, Johnson Matthey",
      "Edward Asiedu , Senior Professional Services Consultant, Splunk"
    ],
    "Industry": "Manufacturing",
    "Description": "Does your small team also run a full-featured SOC that supports a global company? In this session we‚Äôll show you how we‚Äôve used Splunk Cloud and Splunk Enterprise Security to bring together all the relevant security intelligence from our technology stack, transforming our security operations from ad hoc and tactical to strategic and compliance-driven. We‚Äôll discuss key takeaways from our journey, such as the benefits of ingesting data properly from the outset so you can reap the rewards as you scale; how we leverage multiple use cases out of single data sources; and how we created easy-to-understand visualizations that convey our firm‚Äôs security posture to management.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1511.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1511.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1518 - I Have Authority to Operate in the Cloud...Now How Do I Secure It-",
    "SkillLevel": "Beginner",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise",
      "Splunk Enterprise Security"
    ],
    "Speakers": [
      "Patrick  Shumate , Solutions Architect, Splunk",
      "Stephen Alexander , Sr. Solutions Architect , Amazon Web Services"
    ],
    "Industry": "Public Sector",
    "Description": "You finally got Authority To Operate (ATO) in the Cloud, and you're feeling the budgetary and political pressure to transition your workloads to AWS. But how do you actually transition a workload securely? This session covers the essentials of using Splunk to quickly increase your security posture and awareness in the Cloud. Learn from our experiences and leave with more confidence that you're asking smart questions of your data, monitoring and alerting on the right things, assigning responsibilities to your team appropriately, and have an actionable security plan in place to protect your Cloud assets.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1518.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1518.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1538 - Getting Started with Risk-Based Alerting and MITRE",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Bryan Turner , IT Security Analyst, Publix Super Markets",
    "Industry": "Not industry specific",
    "Description": "Risk-based alerting is gaining traction in the SOC: by using multiple-lower fidelity searches to yield higher-fidelity investigations, it allows analysts to rapidly prioritize investigations, correlate 'risk objects' between alerts, identify gaps in monitoring, and generally understand attack narratives. We'll discuss the first steps needed to transition from the traditional one-to-one ticket investigation model to this holistic approach, i.e. how risk-based alerting works, a description of prerequisites, and dashboard optimization.  We will also discuss how to start building a comprehensive search inventory based on Splunk analytics, MITRE, and your own threat intelligence.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1538.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1538.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1544 - Enterprise Security Biology III- Dissecting the Incident Management Framework",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Speakers": "John Stoner , Principal Security Strategist, Splunk",
    "Industry": "Not industry specific",
    "Description": "Splunk's Incident Management Framework is used extensively in support of the notable event creation, and it serves as a bridge that associates the Risk, Asset & Identity, and Threat frameworks together. In this session we will discuss how incident management functions, what occurs behind the scenes to prepare events that are correlated, and how to present correlated events to analysts. Attendees will leave this talk with a greater understanding of the Incident Management Framework and methods to work more effectively with it within Splunk Enterprise Security.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1544.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1544.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1545 - Improve Your Cyber Monitoring & Response Strategy with Splunk Enterprise Security and Splunk Phantom",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise Security"],
    "Speakers": "Ed Svaleson , Accenture",
    "Industry": "Not industry specific",
    "Description": "How do you know if your alerting and response processes adequately cover the tactics and techniques that your adversaries will use against you? If you're not sure, then how do to you continuously improve to adapt to ever-evolving threats? This session will provide practical guidance on leveraging models like the diamond model, MITRE ATT&CK‚Ñ¢, and OODA to deconstruct your monitoring and response program so that you can make strategic improvements and mature it on a strong foundation. Using these frameworks will help your team recognize its own bias in developing use cases, understand how its alerting and response coverage maps to adversary tactics/techniques, and develop and prioritize new use cases. The session will wrap up discussing practical tips for creating a continuous improvement program that helps you leverage Splunk Enterprise Security and Splunk Phantom to maintain a strong security posture.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1545.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1545.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1550 - Have No Fear, WMI Is Here- Identify Lateral Movement and Malicious Backdoors with Windows Management Instrumentation",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Ryan Becwar , Sales Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Attackers are increasingly using a 'living off the land' approach, often using crypto mining malware, EternalBlue, timing, or other attacks that leverage the Windows Management Instrumentation Command Line. These attacks typically don't generate any events via conventional Sysmon and PowerShell, so even if you're pulling in those logs you likely won't see them. Join this session to learn how to detect and protect your organization from these advanced WMI-based attacks.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1550.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1550.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1554 - How We Scaled Splunk Enterprise Security to 100TB with Search Head Clustering",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Speakers": [
      "Devendra Badhani , Sr Engineering Manager, Splunk",
      "Jesse Chen , Principal Performance Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Want to scale Splunk Enterprise Security to 100TB/day? We've done it! In Splunk labs, we built workloads that closely simulate our customers' usage patterns, and we scaled beyond a 100TB per day ingest rate with search head clustering. In this session we'll share key aspects of our Splunk Enterprise Security workload design: diverse source types, major data models, search scenarios, data enrichment, and hardware choices for search head and indexer.  We will also share how different configurations impact search performance and how to tune Splunk Enterprise Security effectively with parameters such as max_searches_per_cpu, acceleration.max_concurrent, allow_skew, and maxBundleSize to name a few. Come see how we scaled to large volumes while efficiently utilizing hardware capacity for maximum performance.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1554.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1554.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1556 - Building Behavioral Detections- Cross-Correlating Suspicious Activity with the MITRE ATT&CK‚Ñ¢ Framework",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Haylee Mills , Security Engineer, Charles Schwab",
    "Industry": "Not industry specific",
    "Description": "Advanced attackers that live off your land add insult to what can be very serious injury. In this session we'll show you how to use behavioral analysis to identify advanced attackers that evade traditional signature-based detection methods. We do so in our organization by using Splunk to combine insights from traditional data sources to detect activity across multiple phases of the MITRE ATT&CK‚Ñ¢ framework. We'll focus on how to build queries¬†¬†tune them for your environment, and start catching these threat actors with behavioral detections as soon as you get back from .conf.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1556.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1556.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1573 - Survival of the Fastest- The 1-10-60 Rule",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Tim Sullivan , Global Senior Strategic Solutions Architect, CrowdStrike",
      "Wissam Ali-Ahmad , Lead Solutions Architect, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Winston Churchill once said, 'Success is not final, failure is not fatal: it is the courage to continue that counts.' Then again, Churchill wasn‚Äôt in cybersecurity...While our successes are certainly never final, our failures can absolutely be fatal‚Äîto a company and our continued employment. What's a good way to actually measure success and failure, though, outside of not appearing on the front page of the paper? Well, as CrowdStrike notes, you have on average one minute to detect an attack in progress, ten minutes to understand it, and sixty minutes to contain it. We will show how to use this 1-10-60 Rule as a measuring metric and leverage the data and capabilities within Splunk and its ecosystem to ensure that we win the survival of the fastest.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1573.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1573.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1597 - Build a JARVIS for Your SOC",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Jono Pagett , Head of Cyber Defence Centre, Bank of England",
      "Peter Littler , Cyber Security Analyst, Bank of England"
    ],
    "Industry": "Not industry specific",
    "Description": "The boss saw Ironman and wanted to create a JARVIS-like assistant for our SOC...so we built him one using Splunk. In this session we will share how we developed a Splunk virtual assistant to improve SOC efficiency and support the SOC 2.0 model of continual improvement. SOC JARVIS solves problems such as: How does a SOC manage its attack detection ideas and knowledge? How does an analyst understand the impact of their search changes on alert volumes? How does the SOC manage feedback between analysts and search authors? Learn how to use Splunk in a novel way to address these problems so that you can make your SOC workflows more efficient and let analysts spend more time threat hunting and improving how they detect attacks.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1597.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1597.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1619 - Cops and Robbers II- Paint the Town Purple! ",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1619.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/SEC1619.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1620 - Develop Endpoint Detection Superpowers with Sysmon + Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1620.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/SEC1620.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1671 - Use Splunk SIEMulator to Generate Data for Automated Detection, Investigation, and Response ",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Phantom",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": [
      "Phil Royer , Research Engineer, Splunk",
      "Rod Soto , Principal Security Research Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Obtaining data to develop defenses against threats is a constant challenge for security analysts. To that end, Splunk's Security Research team developed the Splunk SIEMulator, a framework modeled after Chris Long's DetectionLab that allows a defender to replay attack scenarios using AttackIQ in a simulated environment. SIEMulator‚Äôs Attack Range environments are all configured with Splunk forwarders and the apps necessary to create and store data in CIM data models. We'll show you how to use the SIEMulator to produce shareable data that can help security analysts replicate scenarios and effectively detect, investigate, and respond to threats.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1671.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1671.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1673 - Integrating the Analyst, the Logic, and the Machine",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Lukasz Antoniak , Cyber Detection Crafting Chief, Viasat",
      "Ryan Rake , Viasat"
    ],
    "Industry": "Not industry specific",
    "Description": "Are your analysts spending too much time clearing through notable events? Ours were too, but today our analysts are living the dream: they have all the details they want right there on the Incident Review screen, all while our alerts fine-tune themselves (with workflow action human input). Come and see how we achieved Incident Review Screen 2.0. by using Splunk's Machine Learning Toolkit to transition to smarter correlation searches. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1673.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1673.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1674 - Lessons Learned From Building a Threat Detection Program",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["AI/ML", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Chris Ogden , Principal Threat Detection Engineer, Sony Corporation of America",
      "Drew Guarino , Senior Threat Detection Engineer, Sony Corporation of America"
    ],
    "Industry": "Not industry specific",
    "Description": "We will share experiences and best practices for implementing notable events, the various Splunk Enterprise Security frameworks, and adaptive response actions, and we'll share our approach for building a program to consistently develop, measure, and iterate on correlation searches. We will discuss how to integrate lessons learned from incidents, red team engagements, threat intelligence, threat hunting, and requirements from business units into the program. Example tactics we'll cover include leveraging low-fidelity detections to develop higher-fidelity and higher-value ones, managing detection content simply and easily through macros, and building a formula to assess the efficacy of your detection content. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1674.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1674.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1705 - Diving into Splunk Phantom's Overlooked Features",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Phantom",
    "Speakers": [
      "Kavita Varadarajan , Product Manager - Phantom, Splunk",
      "Phil Royer , Research Engineer, Splunk",
      "Sam Hays , Sr. Technical Community Manager , Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Whether you're a new or experienced Splunk Phantom user, you'll learn from the high-value, often overlooked features we discuss in this session. We'll showcase some of Phantom's most overlooked valuable features, as well as experienced users' top ranked features. Join us to learn more about how you can optimize your use of Splunk‚Äôs SOAR (Security Orchestration Automation & Response) platform.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1705.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1705.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1706 - Mission Control- A Day in the Life of a Security Analyst",
    "SkillLevel": "Beginner",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Phantom",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": [
      "Atom Coffman , Starbucks",
      "Rob Truesdell , Sr Director, Product Management, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Join us to see the latest developments with Splunk‚Äôs Security Operations Suite. We‚Äôll share background on the underlying architecture as well as a showcase of new features. Learn how your security use cases are solved with scale and performance.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1706.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1706.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1709 - Examining Splunk Phantom's Architecture",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": "Phantom",
    "Speakers": "Sourabh Sourabh , VP & Distinguished Engineer, Splunk",
    "Industry": "Not industry specific",
    "Description": "Want to learn more about Splunk Phantom's platform architecture? Join us in this session for an in-depth technical review of all key processes, including ingestion, automation, action execution, health monitoring, the data store, and more.  This session will give experienced users a much deeper understanding of the technology behind Splunk‚Äôs SOAR (Security Orchestration Automation & Response) platform.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1709.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1709.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1775 - Step Up Your Defenses with End-To-End Detection, Investigation, and Response",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Phantom",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": [
      "Bhavin Patel , Security Software Engineer, Splunk",
      "Jose Hernandez , Security Researcher, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Maturing and scaling your security operations rests on your ability to process and analyze huge volumes of often unrelated data in real time. But today's tools notoriously overwhelm SOC analysts with the sheer number of alerts and high percent of false positives, resulting in confusion about what tools to use for investigation and response. In this session, members of Splunk's Security Research Team will discuss the next generation of Enterprise Security Content Updates that they developed, which integrate the entire Splunk for Security product suite to create a robust end-to-end defense‚Äîdetection, investigation, and response. We will go over how to use these security guides, which will leverage Splunk Enterprise Security, Splunk Phantom, and Splunk User Behavior Analytics. We'll also highlight the Run Story feature we built to operationalize ESCU Analytics stories and share tools and techniques customers can use to write and test their own use cases.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1775.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1775.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1781 - BotS the Missing Link",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1781.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/SEC1781.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1796 - Post-Pwn3D- Using Splunk Enterprise and Splunk Enterprise Security for Incident Response and Forensic Analysis",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Dave Martin , Supervisory Special Agent, Federal Bureau of Investigation",
      "Josh Wilson , Consulting Engineer, August Schell"
    ],
    "Industry": "Not industry specific",
    "Description": "After breaches, incident response teams often end up with an overwhelming amount of forensic evidence data, including disk images, memory captures, PCAP, and more. We'll show you how one of our IR/forensics teams is ingesting this data into Splunk to answer the who, what, where, when and why of breaches. Our presentation will show you how to use Splunk Enterprise and Splunk Enterprise Security for Incident Response (IR) workflow tracking and reporting on multi-source forensic data captures.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1796.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1796.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1803 - Modernize and Mature Your SOC with Risk-Based Alerting",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Jim Apger , Staff Security Architect, Splunk",
      "Jimi Mills , Security Operations Center Manager, Texas Instruments"
    ],
    "Industry": "Not industry specific",
    "Description": "Today SOCs are in desperate need of a different alerting approach. Texas Instruments (TI) decided to transform its SOC by using risk-based alerting to generate fewer, higher fidelity alerts, and by aligning to the MITRE ATT&CK‚Ñ¢ framework, which provides more situational awareness to analysts. This risk-based approach reduces false positives and the situational numbness associated with the legacy whitelisting process. Splunk and TI will walk you through TI's SOC successes as it transitioned to risk-based alerting. TI will detail a few real-life risk-based rule examples, discuss learning curves to fast track your transition, and discuss how MITRE ATT&CK‚Ñ¢ fits in with this approach.  After this session, you will have the foundation to embark on your risk-based alerting journey, allowing you to increase detection mechanisms, increase your coverage of the ATT&CK‚Ñ¢ techniques, and improve the overall effectiveness of your SOC.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1803.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1803.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1849 - Lessons Learned From Securing Japan's First Online-Only Bank",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Industry": "Financial Services"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1852 - Make Compliance a Breeze with Splunk Enterprise Security",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Speakers": [
      "Darren Dance , Staff PS Consultant, Splunk ",
      "Jason Timlin , Professional Services, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "This session will give you the tools to tackle compliance with Splunk Enterprise Security. The session will showcase why you might want to grant different compliance views to your teams based on the compliance standard they are responsible for adhering to, and how to do so. We'll also cover how to present the compliance standards that a notable event relates to and how to grant your compliance officers visibility into only the notable events that are relevant to them.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1852.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1852.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1904 - The Duck Test- Leverage Machine Learning to Remediate Fraud in Huge Datasets",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": "Matthew Harper , Director, Cyber Crime Prevention, Aflac",
    "Industry": "Financial Services",
    "Description": "Aflac measures risk to provide financial protection to more than 50 million people worldwide. Join this session to learn how Aflac mitigates fraud by using Splunk's Machine Learning Toolkit (MLTK) to find outliers and cluster events. Using Splunk and the MLTK reduced the time needed to conduct necessary analyses (e.g. link analysis) from weeks and months to just minutes‚Äîwe will share with you how we use Splunk's MLTK to iterate quickly, develop new anomaly detection techniques, and improve our overall fraud mitigation perfomance. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1904.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1904.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1908 - Tales From a Threat Team- Lessons and Strategies for Succeeding with a Risk-Based Approach",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Speakers": "Stuart McIntosh , Threat Intelligence, Outpost Security",
    "Industry": "Not industry specific",
    "Description": "We've run a risk-based approach with our security alerts for over a year, and we're excited to review our progress with you. We'll discuss how we increased the number of behavioral indicators by 300% while reducing our alerts by 50%. We'll also discuss how we expanded our risk approach to handle on premise and cloud environments within the same framework, which yielded a single alerting mechanism that leverages all of our data enrichment. We'll also share the roadmap for our risk-based approach, which incorporates risk rules that utilize algorithms to identify risks not discovered by traditional detection approaches.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1908.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1908.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1927 - ATT&CK‚Ñ¢ Yourself Before Someone Else Does",
    "SkillLevel": "Beginner",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "BOTSFATHER Kovar , Principal Security Strategist, Splunk",
      "Dave Herrald , Principal Security Strategist, Splunk",
      "John Stoner , Principal Security Strategist, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Do you love the idea of the MITRE ATT&CK‚Ñ¢ framework, but you‚Äôre not sure how to use it in your Splunk-centric security program? This talk will teach you practical ways to use the framework in your own organization and the Splunk security tools that will help you do so. We'll start the talk by identifying an adversary and some of their known techniques, and then we'll show how to choose an appropriate set of detections and how to test whether those detections are working as expected. You'll leave the talk better able to take advantage of threat intelligence, cover the right set of ATT&CK‚Ñ¢ tactics and adversary groups, and eliminate organizational blind spots.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1927.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1927.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1930 - Break Free From Legacy GRC to Achieve Real-Time Integrated Risk Visibility",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Anthony  Perez , Director of Field Technology - Public Sector, Splunk",
      "Matt Coose , Qmulos"
    ],
    "Industry": "Not industry specific",
    "Description": "As organizations shift away from legacy Governance, Risk, and Compliance (GRC) approaches towards an integrated risk management (IRM) strategy, cyber risk management paradigms must also shift. This presentation will address why firms are shifting to IRM and how the shift to IRM will affect security organizations globally. We will showcase strategies used by forward-leaning peers and thought leaders to operationalize integrated risk management programs in their organizations.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1930.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1930.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1949 - Splunk Phantom Ignition- Getting Automation Off the Ground and Working for You",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Phantom",
    "Speakers": [
      "Brandon Robinson , Senior Security Architect, Stage 2 Security",
      "Luke Summers , Cyber Security Engineer, Stage 2 Security",
      "Mhike Funderburk , Senior Security Engineer, Stage 2 Security"
    ],
    "Industry": "Not industry specific",
    "Description": "Did you get more staff for heartbleed? How about Shellshock or the OPM breach? Neither did we. The threat landscape is growing faster than ever and we need to cover more bases without more people. Enter Splunk Phantom: automation and integration for the masses. This session will help you understand what you need to build an effective Phantom ecosystem. I will go over initial strategies, real world examples, and use cases, and we will also take a glance at some more robust development projects that show the power of Phantom's extensibility. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1949.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1949.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1952 - Finding Evil Is Never An Accident- How to Hunt in BOTS",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Michael Haag , Director of Advanced Threat Detection, Red Canary",
    "Industry": "Not industry specific",
    "Description": "To secure the modern endpoint, you need sufficient data, the right visibility and analysis, and the technology necesary to stop an intrusion. We will leverage BOTSv4 data in this session to help you test and validate Splunk use cases related to hunting threats using endpoint data. We‚Äôll cover several real world case studies as described in MITRE ATT&CK‚Ñ¢, and we will simulate adversary groups by executing a single Atomic test and building an elaborate chain reaction. We will then show you in Splunk how to confirm your data quality and confirm you have what you need to detect and evict an adversary from your environment. We will demonstrate practical hunt techniques using BOTSv4 data and how to raise the flag when data is missing or is not required.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC1952.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC1952.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC1998 - Solving the Opioid Crisis and Protecting Patient Privacy ‚Äì using Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Industry": ["Healthcare", "Non-Profit"]
  },
  {
    "Event": ".conf19",
    "Title": "SEC2007 - Splunking the Endpoint V- Hands On with BOTSv4 Data",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Business Flow",
      "Splunk Data Fabric Search and Data Stream Processor",
      "Splunk Enterprise"
    ],
    "Speakers": "James Brodsky , Director, Global Security Kittens, Splunk",
    "Industry": "Not industry specific",
    "Description": "Initial compromises happen on your endpoints, so why are you not Splunking them? In this edition of Splunking The Endpoint, we will tell you exactly what to configure in Splunk, and where, why, and how to do so in order to get unparalleled visibility into threats targeting your network. Not only will we revisit popular operating system and open-source endpoint data sources like Sysmon and Osquery, but we'll also talk about various popular commercial EDR products and give you best practices for collecting data from them. Lastly, we'll help you address any doubts about scale problems and licensing costs.n n Please bring your laptop! We will dive through the latest Boss of the SOC (BOTS) endpoint data and demonstrate the detection techniques needed to answer BOTS questions. Everything you learn will be something you can take home and put into production immediately.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2007.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2007.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2011 - Security Ninjutsu Part Six- Campfire Stories of Demons and Bad People",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2011.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/SEC2011.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2013 - Splunk Security Essentials 3.0- Driving the Content that Drives You",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": [
      "David Veuve , Principal Security Strategist, Splunk",
      "Johan Bjerke , Principal Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Whether you have just SSE or all of Splunk's Premium Products, you can benefit from the ton of Security Content that Splunk produces. We'll start this session by setting a quick baseline on all of the fantastic detections that Security Essentials has had in the past, and then jump into the new prescriptive guides, MITRE ATT&CK‚Ñ¢ integration, Auto-Dashboard-Magic, and all the related functionality that will help you plan your usage of any/all of Splunk's security products. We'll present all this information through the lens of helping you get the best possible detections deployed with the least amount of effort.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2013.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2013.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2056 - Hunting in the Dark- Profiling Encrypted Network Traffic",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Jayson Weiss , Security Engineer III, Box",
      "Mike Sconzo , Staff Threat Intel Engineer, Box"
    ],
    "Industry": "Not industry specific",
    "Description": "It's not easy to detect malicious patterns within encrypted network traffic. JA3, a method of fingerprinting Secure Sockets Layer (SSL) traffic developed by SalesForce, aims to address this by profiling client (JA3) and server (JA3s) SSL connections. Since these fingerprints are unique and persistent, they provide a way to discover applications, fingerprint Operating Systems, and even discover malware. This presentation showcases how to use Splunk to streamline JA3 event data gathered from Bro/Zeek, use that in combination with host-level visibility provided by Carbon Black, and ultimately correlate network signatures with endpoint telemetry. You will learn how to use this method to get a better understanding of what processes are causing benign or malicious SSL connections on your network and how to hunt for unknown threats.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2056.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2056.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2083 - Catch exfiltration from cloud file stores early!",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": [
      "Ignacio Bermudez Corrales , Senior Data Scientist, Splunk",
      "Stanislav Miskovic , Security Data Science, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "In this session, we tackle data breaches and information exfiltration from cloud file stores. Beyond the attacks that make headlines and result in millions of stolen personal records, we will also focus on the far less publicized risks related to exposure of intellectual property, infrastructure details or finances. We will share our experience in building a defensive strategy that now detects highly-covert exfiltration attempts.n n To this end, we first shed a lot of light on how companies use general-purpose file stores, such as Box, Office365 or Google Drive. We cover the types of files that commonly get stored in the cloud, file sharing practices, access properties, as well as uses of cloud stores by various departments. There are a lot of unexpected insights which eventually invalidate common security assumptions.n n As the boundary between good and bad gets blurred, we will provide you with a peek into how to design an effective data-driven defense. This approach helped us hone our detection to just tens of validly suspicious exfiltration files in a massive cloud store.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2083.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2083.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2105 - Measure What Matters to Streamline Security Operations with Splunk",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Cloud", "Splunk Machine Learning Toolkit"],
    "Speakers": "Keshia LeVan , Detection Engineer, Red Canary",
    "Industry": "Not industry specific",
    "Description": "To tame an event queue that's ballooning out of control, you need to know first which rules and data sources are generating a disproportionate number of alerts, and second the security value you're getting from those rules and data sources. Any changes made to rules or telemetry analyzed without that knowledge risk making your organization more vulnerable. In this session we'll discuss how Splunk empowers us to perform advanced analytics on everything from alert conversion rates to human time expenditure on alerts so that we can optimize all processes related to alerting. As long as we know what to measure and where to look, Splunk can help us tune our security operations centers to reduce monotony and false positives without diminishing our ability to detect actual threats.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2105.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2105.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2109 - Hunting Threats with Splunk UBA",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk User Behavior Analytics",
    "Speakers": [
      "Chris Shuler , Senior Security Engineer, LyondellBasell",
      "Jonathan Guillotte , Senior Security Engineer, LyondellBasell",
      "Richard Towle , Enterprise Architect, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "We're excited to provide a deep, step-by-step process for how to hunt threats using Splunk User Behavior Analytics (UBA). Our global professional services lead for Splunk UBA will go over how to build custom threats, hunt down rogue employees, build advanced watchlists, and get better at finding the needle in the haystack. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2109.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2120 - Scaling Splunk Enterprise Security",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Marquis Montgomery , Principal Security Architect, Splunk",
    "Industry": "Not industry specific",
    "Description": "As the types of devices and applications used in IT organizations increase exponentially, scaling the analytics-driven SOC becomes even more imperative. In this session Splunk Professional Services will help you learn from its past experiences architecting Splunk Enterprise Security environments for scale into the terabytes per day. We will share technical details on improvements to search technology and Data Model Acceleration in Splunk Enterprise that will help you increase performance and decrease total cost of ownership. We will also take a deep dive under-the-hood into Splunk Enterprise Security Frameworks in which you should make special considerations for high volume. ¬†Finally, we'll share important metrics on how to monitor the ongoing health of your Enterprise Security deployment, ensuring you stay on track over time, even in periods of rapid growth.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2120.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2120.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2129 - Defense Against the Dark Arts- Splunk Edition",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Erika Strano , Sales Engineer, Splunk",
      "Melisa  Napoles , Sales Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Malware infection, lateral movement, data exfiltration, oh my! If you‚Äôve spent any time around the wizarding world of security, you know how much effort goes into preventing dark magic from happening. What if you could use machine learning to stay one step ahead of the adversary? Fasten your seatbelts, because in this talk we will show you how Splunk can utilize machine learning models to take your security detections to the next level. We‚Äôll demonstrate how Splunk's Machine Learning Toolkit can be used to train, validate, and then deploy models to identify anomalies and discover clusters of bad behavior via user-friendly guided workflows‚Äîall this while training your models with more data then you‚Äôve ever been able to before. Prepare to leave Las Vegas equipped to incorporate machine learning in your organization‚Äôs security detections and jump from reactive to proactive. Mischief managed! ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2129.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2129.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2179 - Dude, Where‚Äôs My Log- The Unknown Logging Gaps in Your Environment, Why You Didn't Detect that Pentest, and How Splunk Can Help ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": "Kevin Kaminski , Threat Management R&D Lead, ReliaQuest",
    "Industry": "Not industry specific",
    "Description": "Failure to log everything needed for maximum visibility in your environment can leave huge gaps in your ability to remediate threats. But running an enterprise-level logging program can be difficult: how do you know if you're logging everything necessary to detect threats? Are all of your technologies configured to send the right logs? Are they all logging to Splunk? In this session we will help you answer these and other critical questions of your logging program, which will ultimately help you remediate issues and better use log analysis to mitigate threats.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2179.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2179.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2186 - Pull up your SOCs 2.0",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Dimitri McKay , Staff Security Architect | Jedi Master, Splunk",
    "Industry": "Not industry specific",
    "Description": "Last year, after our outrageously successful talk 'Pull Up Your SOCs: A Splunk Primer on Building or Rebuilding your Security Operations', we wanted to revisit this topic to cover changes in Security Operations that have taken place over the last 12 months. Whether you‚Äôre starting from scratch or rebuilding your security program, the first twelve months of standing up your security operations is absolutely critical to success. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2186.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2186.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2187 - Tackle AWS Security Automatically with Splunk Phantom",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Phantom",
    "Speakers": "Matt Tichenor , Product Manager, Splunk",
    "Industry": "Not industry specific",
    "Description": "This session will give you a comprehensive look into automating the investigation and remediation of AWS security events using Splunk Phantom. The session will start with an overview and then progress to a live technical walkthrough of setting up Phantom to remediate an AWS security event. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2187.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2187.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2189 - Build a Successful Vulnerability Management Program on Splunk",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Industry": "Not industry specific",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2189.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/summit/SEC2189.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2203 - Use Deception, Automated Response and Threat Emulation to Make Your Defense Proactive",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "AI/ML",
      "Phantom",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Vincent Urias , Researcher, Sandia National Laboratories",
      "Will Stout , Researcher, Sandia National Laboratories"
    ],
    "Industry": "Aerospace & Defense",
    "Description": "Deception, automation, and real-time data exploitation help security organizations go on offense vs attackers. In this session we will discuss how to use a variety of deception techniques to gather threat intelligence, how to create an automated response, and how to test response playbooks to validate that responses work as expected. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2203.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2203.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2205 - Beyond Tier 1 Automation- The Hidden Value of Splunk Phantom Automation for Security Operations ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise"],
    "Speakers": [
      "Chris Decker , Enterprise Security Manager, Penn State University",
      "Craig Vincent , Lead Technologist,SLED, Splunk"
    ],
    "Industry": "Higher Education",
    "Description": "You've probably heard examples of Splunk Phantom automating 90% of Tier 1 processes, but did you know that Phantom improves human-lead processes too? Come learn about the hidden value of validation and utility playbooks from Penn State University‚Äôs Enterprise Security Manager and Splunk‚Äôs Lead Technologist for Higher Education. Validation playbooks are automated tests run to validate a human judgement or request. Utility playbooks are short easy-to-create playbooks in Phantom that an analyst ¬†runs during an investigation. ¬†We‚Äôll cover when to use validation and utility playbooks, how to get started creating them, and ideas for other playbooks you can use to improve your daily operations. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2205.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2205.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2233 - Deploying Splunk Enterprise Security and Splunk Phantom At Scale",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Ankit Bhagat , Forward Deployed Software Engineer, Splunk",
      "Mayur Pipaliya , Forward Deployed Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Ever wondered how to integrate or scale Splunk Enterprise Security (ES) and Splunk Phantom?  Join us as we explore best practices involved in setting up clustered environments for ES and Phantom that yield a highly available and scalable security platform. You will leave this session better able to create scalable ES and Phantom deployments, tools, commands, cheat sheets, and troubleshooting methods at your own organizations.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2233.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2233.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2253 - Transforming Intel‚Äôs Security Posture with Innovations in Data Intelligence",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Speakers": [
      "Aubrey Sharwarko , Data Scientist, Intel",
      "Jac Noel , Security Solutions Architect, Intel ",
      "Jerome Swanson , Security Data Scientist, Intel"
    ],
    "Industry": "Not industry specific",
    "Description": "Intel is transforming its approach to security by deploying a new Cyber Intelligence Platform (CIP) based on Splunk, Kafka, and other leading-edge technologies. Our new platform ingests data from hundreds of data sources and security tools, providing context-rich visibility and a common work surface, and improving the efficiency of our entire information security organization. This session will address how we partnered with Splunk architects to deploy and realize benefits from this solution in just five weeks. We will detail how our solution uses real-time data, streams processing, machine learning tools and consistent data models to decrease time to detect and respond to sophisticated threats. This session will cover everything from our platform's business value to its solution architecture.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2253.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2253.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2274 - Enterprise Security for an Internet Service Provider- How Splunk Enterprise Security Changed the Way We Work and Changed the Organization",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk Machine Learning Toolkit"
    ],
    "Speakers": [
      "Daesoo Choi , Senior Sales Engineer, Splunk",
      "Kyoung Geun Lee , SoC Senior Manager, SK Broadband"
    ],
    "Industry": "Communications",
    "Description": "20+ million subscribers, 290PB network traffic daily, and tens of millions of IoT, IPTV and ICT devices‚Äîa bigger network means more attacks from all over the world. Learn how SK Broadband, the biggest telco/ISP provider in South Korea, leverages Splunk Enterprise Security (ES) to protect their subscribers from countless DDoS and malware attacks. We will cover detailed use cases for analyzing a high volume of data‚Äî500 million security events over 7 billion logs per day‚Äîas well as how we met a high bar of operational efficiency by customizing our ES deployment.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2274.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2274.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2280 - Break Down Silos By Ingesting Multi-Purpose Data Sources into Splunk",
    "SkillLevel": "Beginner",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": "Ben Marcus , Sr. Staff IT Engineer, Qualcomm",
    "Industry": "Not industry specific",
    "Description": "We use Splunk data to help previously siloed groups at Qualcomm work better together. We will discuss specific high value, multipurpose data sources that we ingest, and how we use them to foster collaboration across teams. You will leave this session with a better sense of data sources that you analyze for security that can also help you work better with everyone from developers, to help desk staff, to executive management.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2280.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2280.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2286 - Attacking and Defending Kubernetes- A Purple Team Approach to Improving Detection Using Splunk Enterprise Security, Splunk Phantom and Peirates",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise Security"],
    "Speakers": [
      "Brian Genz , Senior Manager, Threat & Vulnerability Mgmt., Splunk",
      "Jay Beale , CTO, InGuardians"
    ],
    "Industry": "Not industry specific",
    "Description": "Would you be able to detect a sophisticated adversary targeting your Kubernetes clusters and workloads tonight? How do busy teams with stacked backlogs find time to learn how to attack Kubernetes clusters, detect those attacks, and build defenses to reduce the attack surface? We will demonstrate an effective purple team methodology that 'uses every part of the buffalo' by 1) executing attacks on Kubernetes using the open source tool Peirates, 2) tracking the attack artifacts from the adversary simulation in Splunk, 3) teaching the defenders how the attack was performed and where to look for forensic artifacts, and 4) working together in the purple-est way possible to improve detection and response capabilities using Splunk Enterprise Security, Splunk Phantom, and Peirates.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2286.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2286.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2294 - Splunk Mission Control Deep Dive Session",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Speakers": [
      "Allison Drake , UX Design Manager, Splunk",
      "Chris Simmons , Director of Product Marketing, Splunk",
      "Daniel Trenkner , UX Designer, Splunk",
      "Rob Truesdell , Sr Director, Product Management, Splunk",
      "Timur Catakli , Sr. Software Engineer, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you a security analyst? Do you like bright and shiny new things? Do you want to get a deep dive look into a new Splunk product months before it becomes Generally Available? Well then, this session is for you! Join us for this 2-hour session where you‚Äôll get the inside scoop on the latest and greatest coming out of our security product and engineering teams.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2294.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2295 - Introducing Splunk Mission Control",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Speakers": [
      "Chris Simmons , Director of Product Marketing, Splunk",
      "Rob Truesdell , Sr Director, Product Management, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you a security analyst? Do you like bright and shiny new things? Attend this session to get the inside scoop on the latest and greatest coming out of our security product and engineering teams.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2295.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2295.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2366 - What's New in Splunk for Security",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Phantom",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": [
      "Chris Simmons , Director of Product Marketing, Splunk",
      "Koulick Ghosh , Product Manager, Splunk",
      "Kyle Champlin , Senior Product Manager, Splunk",
      "Patriz Regalado , Sr. Product Marketing Manager, Splunk",
      "Rob Truesdell , Sr Director, Product Management, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Our security research, engineering and product teams have been hard at work building new capabilities to bolster your Splunk security stack. Find out what they‚Äôve been up to since .conf18, and watch a demonstration of the latest innovations in Splunk Enterprise Security, Splunk User Behavior Analytics, and Splunk Phantom. There are other awesome developments that we can‚Äôt share now but are excited to share with you at .conf. Our security research, engineering and product teams have been hard at work building new capabilities to bolster your Splunk security stack. Find out what they‚Äôve been up to since .conf18, and watch a demonstration of the latest innovations in Splunk Enterprise Security, Splunk User Behavior Analytics, and Splunk Phantom. There are other awesome developments that we can‚Äôt share now but are excited to share with you at .conf.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2366.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2366.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2371 - Introducing Splunk Mission Control",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Speakers": [
      "Chris Simmons , Director of Product Marketing, Splunk",
      "Rob Truesdell , Sr Director, Product Management, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Are you a security analyst? Do you like bright and shiny new things? Attend this session to get the inside scoop on the latest and greatest coming out of our security product and engineering teams.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2371.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2371.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2372 - Make Your Security Tools Work Better Together Using Splunk's Adaptive Operations Framework",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Alexa Araneta , Product Marketing Manager, Splunk",
      "John Dominguez , Product Marketing Director, Splunk"
    ],
    "Industry": "Not industry specific",
    "Description": "Security architectures typically involve many layers of tools and products that are not designed to work together, leaving gaps in how security teams bridge multiple domains to coordinate defense. The Splunk Adaptive Operations Framework (AOF) addresses these gaps by connecting security products and technologies from our partners with Splunk security solutions including Splunk Enterprise Security (ES) and Splunk Phantom. Join this session to learn how the Splunk AOF benefits both users and security technology providers by enabling rich context for all security decisions, collaborative decision-making, and orchestrated actions across diverse security technologies. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2372.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2372.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2638 - Protecting your Data- The 2020 Decennial Census and Data Security",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": [
      "Atri Kalluri , Senior Advocate, Response Security and Data Integrity, U.S. Census Bureau",
      "Zack Scwhartz , IT Program Manager, U.S. Census Bureau"
    ],
    "Industry": "Public Sector",
    "Description": "The Census is the nation‚Äôs largest peacetime mobilization effort and determines congressional representation. Census data is used by businesses, governments and civic organizations to inform decision-making and this year the Census is going mobile and online for the first time. This means that security is a top priority in ensuring the success of the 2020 Decennial. This segment of the conference will explore security related topics to include vulnerabilities, scalability and performance, with a special focus on Data Privacy, Compliance and Reputational Threat Management. If all things data and IT Security excite you, then this session is for you. Census executives Atri Kalluri and Zack Schwartz will provide a behind the scenes overview of the systems supporting the 2020 Decennial, including Splunk, and real world case studies on how the Census Bureau is adopting best practices across IT security and social media monitoring to ensure the security of respondent data. ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2638.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2638.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC2887 - The CISO‚Äôs Guide to Shutting Down Attacks Using the Dark Web + Live Dark Web Tour",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "Nick Hayes , IntSights",
    "Industry": "Not industry specific",
    "Description": "Nick Hayes, VP of Strategy at IntSights, will take you on a tour of the dark web and explain how CISOs can successfully implement a dark web intelligence strategy to neutralize threats outside the wire and at the earliest stages of the cyber kill chain. Now equipped with IntSights External Threat Intelligence, learn how you can take advantage of it through seamless integrations with your Splunk SIEM and Phantom toolsets. Enrich your threat data with internal network security observables, expedite incident reviews and prioritization, and automate your threat prevention and response with SOAR and integrated playbooks.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2887.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2887.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SEC3334 - How to redesign Security Operations powered by Splunk-Phantom",
    "Track": "Security, Compliance and Fraud"
  },
  {
    "Event": ".conf19",
    "Title": "SECD2004 - Walking the Talk for Diversity and Inclusion in Cybersecurity",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": [
      "Kelly  Kitagawa , Customer Success Manager, Splunk",
      "Lily Lee , Staff Security Specialist, Splunk"
    ],
    "Industry": ["Diversity & Inclusion", "Not industry specific"],
    "Description": "We believe that to best defend against global security threats, an organization needs defenders who represent the diverse world that we live in. Every business will benefit greatly by bringing more people to the table with varying skills, backgrounds, leadership and views to combat the diverse adversaries out there. Here at Splunk, we have created initiatives like the 'Developing Superwomen in Cybersecurity' program that works to diversify and equalize the cybersecurity workforce to women and other underrepresented groups. Come hear how we are taking action by making cybersecurity accessible to all with this program and some practical advice on how you can do the same when you go back to your organization! You'll receive tips on how to make information security inclusive to all with ways of engaging your staff at various levels and receive a blueprint for running your own gamified security experiences, allowing you to up-level staff while embracing their unique talents and backgrounds.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECD2004.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECD2004.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2534 - Security visibility through Windows endpoint analytics",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise",
    "Speakers": "Helge Klein , Managing director, vast limits GmbH",
    "Industry": "Not industry specific",
    "Description": "Security requires visibility. uberAgent ESA provides just that. Built on top of the existing uberAgent User Experience Monitoring product, uberAgent Endpoint Security Analytics tags risky processes, detects potential threats resulting from configuration changes and provides deep insights into application and even script activity.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECS2534.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2534.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2589 - Using Machine Learning to Unlock the Potential of Your Security Data",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Speakers": "Kevin Sheu , Vectra",
    "Industry": "Not industry specific",
    "Description": "Vectra customers and security researchers respond to some of the world‚Äôs most consequential threats. And they tell us that there‚Äôs a consistent set of questions they must answer when investigating any attack scenario.n  n Yet, security data today is broken and unable to effectively answer those questions. It is either incomplete or storage and performance intensive.  Most teams don‚Äôt have the information necessary to properly answer the questions required to support their use cases; whether it be for threat hunting, investigations or supporting custom tools and models.n  n In this session, hear about real-world use cases where security teams use machine learning engines to derive unique security attributes and how it is embedded into security workflows.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2589.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2589.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2655 - Fast, Forward and Focused ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Cloud", "Splunk Enterprise Security"],
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2656 - Inside the Shark Tank with Herjavec Group ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Cloud",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2758 - Shift Identity Left- Using Splunk and Okta to Secure Automated Infrastructure Fleets",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Cloud", "Splunk Enterprise"],
    "Industry": "Not industry specific",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2758.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2797 - Building threat-driven use cases for the real world with iDefense intelligence",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Splunk Enterprise", "Splunk Enterprise Security"],
    "Speakers": "John Rubey , Accenture",
    "Industry": "Not industry specific",
    "Description": "Where did you come up with the idea for your last use case? Traditional approaches to use case ideation focus on identifying new use cases based on the data already available to the security operations center. However, the threat landscape is constantly changing, and attackers are constantly getting more sophisticated. To detect these advanced threats, our use cases must be based on both business and threat context. In this session, we will share our approach to building innovative use cases based on real-world threats. Starting with industry-specific threat intelligence, we identify the threat actors and their specific tactics, techniques, and procedures. With these insights, we identify use cases relevant to the business, map them to both existing and new data sources, and prioritize implementation based on the specific threats.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECS2797.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2797.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2831 - Couples Therapy- Real-World Mistakes and Lessons Learned in Business Relationships",
    "Track": "Security, Compliance and Fraud"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2839 - The SOC of the Future",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Splunk Enterprise",
      "Splunk Enterprise Security",
      "Splunk User Behavior Analytics"
    ],
    "Speakers": "Brad Taylor , Proficio",
    "Industry": "Not industry specific",
    "Description": "This presentation will discuss how Security Operation Centers (SOCs) will need to change to meet the cybersecurity challenges of the 2020s. n n The speaker will draw on his experience as a founder of the first SOC-as-a-Service company that delivers managed security services using Splunk. n n Most industry analysts envision that the next generation of SOCs will leverage AI, Big Data, and the Cloud, but how far can automation take us and is the concept of an autonomous SOC really practical? How will the SOC of the Future address the global shortage of cyber professionals? How will the role of security analysts need to change? Will the SOC of the Future still need to be housed in dedicated physical facilities? n n The speaker will provide a blueprint of Proficio‚Äôs vision of the SOC of the Future using Splunk and provide a playbook for IT leaders and aspiring IT leaders on how to drive continuous improvement in productivity and measurable outcomes.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECS2839.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2839.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2841 - Best Practices for Rapid Containment of Incidents",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Enterprise"],
    "Speakers": "Noam Syrkin , Sr. Technical Marketing Engineer, RedSeal",
    "Industry": "Not industry specific",
    "Description": "Prevention and detection solutions are vital to maintain a healthy network but not sufficient.n n When a security incident occurs, the ability to investigate rapidly and recover is crucial but is manually intensive, especially when dealing with networks spanning on premise, public, and private cloud environments.n n Once an incident is detected, then what?n n Learn how RedSeal integrates within Splunk Enterprise Security and Phantom framework to provide you with immediate answers to burning questions.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECS2841.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2841.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2856 - Securing the Intelligent Enterprise with SAP Enterprise Threat Detection and Splunk",
    "Track": "Security, Compliance and Fraud",
    "Speakers": [
      "Anne Marie Colombo , Cybersecurity Solution Advisor, SAP",
      "Carl Yestrau , Director of Architecture for Partners, Splunk",
      "Claw Clawson , SplunkYoda, Splunk"
    ],
    "Description": "Looking to¬†eliminate¬†blind spots across¬†your¬†SAP environment and¬†take¬†proactive action to¬†detect and¬†mitigate attacks¬†before¬†mission-critical ERP applications are compromised?¬†n n SAP recently teamed with Splunk to help a leading manufacturer¬†build and¬†validate a first-of-it‚Äôs-kind bi-directional integration between SAP Enterprise Threat Detection and Splunk. See a demo of how Enterprise Threat Detection‚Äôs open, extensible framework enables an exchange of alerts with Splunk to facilitate real-time attack investigations from either platform plus the ability to rapidly take action within the SAP landscape or broader heterogenous infrastructure.n n SAP Enterprise Threat Detection is a powerful native SAP HANA application that quickly identifies suspicious patterns at the application server and database level. When a potential SAP software-specific threat is identified, Enterprise Threat Detection¬†can send¬†an alert to Splunk to correlate with other application and infrastructure data for deeper investigation or trigger immediate action. Conversely, InfoSec teams using¬†Splunk to rapidly identify anomalies across the broader security infrastructure can send alerts to Enterprise Threat Detection for¬†forensics¬†or to trigger appropriate actions in the SAP environment. The combination of Enterprise Threat Detection and Splunk enables¬†organizations¬†to more effectively combat security issues across the enterprise spanning applications and infrastructure.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC2856.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SEC2856.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2899 - Solving Endpoint Security & Perimeter Blindness with Splunk ‚Äì Lessons from Cisco‚Äôs Internal InfoSec Deployment ",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Cloud", "Splunk Enterprise Security"],
    "Speakers": "Scott Pope , Cisco",
    "Industry": "Not industry specific",
    "Description": "Endpoint security is more than detecting malware.¬† Most insider threats, however, don‚Äôt involve malware, but other security issues associated with the user and endpoint.¬† Learn how Cisco‚Äôs own InfoSec team uses Cisco Endpoint Security Analytics Built on Splunk and Cisco NGFW integration to increase its endpoint security and threat visibility.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECS2899.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2899.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2917 - Differentiating Evil from Benign in the Normally Abnormal World",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": [
      "Phantom",
      "Splunk Enterprise Security",
      "Splunk IT Service Intelligence"
    ],
    "Speakers": "Rick  McElroy , Principal Security Strategist , Carbon Black",
    "Industry": "Not industry specific",
    "Description": "Have you ever been positive you had found evil, only to realize it was normal after hours of triage and work? We have all heard and love 'KNOW NORMAL FIND EVIL,' but how hard is it to actually know normal? The MITRE ATT&CK Framework gives defenders a better map to 'find evil,' but how can this framework be used to 'know normal'?n n Rick will discuss how knowing normal in a world of abnormal is harder than one thinks, and how addressing the actual root cause of evil can improve the technology industry as a whole.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECS2917.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS2917.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS2979 - AWS and Splunk 'Take Action' Playbook-  Identify & Resolve Security Incidents with Splunk, Phantom, AWS Security Hub and AWS Services",
    "SkillLevel": "Good for all skill levels",
    "Track": "Security, Compliance and Fraud",
    "Products": ["Phantom", "Splunk Cloud", "Splunk Enterprise Security"],
    "Speakers": "Scott Ward , Amazon Web Services",
    "Industry": "Not industry specific",
    "Description": "Learn how AWS and Splunk have 'better together' solutions for Security risk identification and response. See the demo showing how to identify disparate security risks, aggregate them, and send them to Splunk Phantom to remediate. n n The Splunk platform provides real-time, end-to-end visibility into your AWS environment to help you organize, display, and take action on your security alerts. AWS Security Hub makes this possible by aggregating security findings from AWS and third-party sources and exporting them to Splunk through a single point of integration‚Äîeven as you continue to add new data sources. n n Security findings can then be sent to Splunk Phantom to automate responses, handling repetitive tasks to focus your attention on mission-critical decisions.  The integration between AWS and Splunk makes it easy for you to head off future security threats and free up your security personnel for higher value activities.",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SECS2979.pdf"
  },
  {
    "Event": ".conf19",
    "Title": "SECS3014 - Anatomy of an Attack",
    "Track": "Security, Compliance and Fraud",
    "Speakers": "Mark Stanford , Cisco Systems",
    "Description": "This session covers how an actual phishing attack from APT29 came together. We will discuss how incident responders can learn more about the attack and build out a timeline of key events. We will also explain how DNS based security plays an important role in proactively blocking threats and how integrations with Splunk can help you with effective threat hunting.n ",
    "SlidesUrl": "https://conf.splunk.com/files/2019/slides/SEC3014.pdf",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS3014.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS3057 - The Hunt Myth to Reality ",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "SECS3058 - An Information Security Approach to Feature Engineering",
    "SkillLevel": "Advanced",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "SECS3061 - High-Impact Strategies to Close the Visibility Gap in Security",
    "SkillLevel": "Intermediate",
    "Track": "Security, Compliance and Fraud",
    "Products": "Splunk Enterprise Security",
    "Industry": "Not industry specific"
  },
  {
    "Event": ".conf19",
    "Title": "SECS3100 - The Hunt for Splunk in October",
    "Track": "Security, Compliance and Fraud",
    "VideoUrl": "https://conf.splunk.com/files/2019/recordings/SECS3100.mp4"
  },
  {
    "Event": ".conf19",
    "Title": "SECS3101 - Power Up Your SOC- Using threat intelligence to bring your SOC ecosystem to the next level",
    "Track": "Security, Compliance and Fraud"
  }
]
